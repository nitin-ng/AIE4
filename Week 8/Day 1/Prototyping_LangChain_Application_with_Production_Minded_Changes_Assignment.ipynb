{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/nitin-ng/AIE4/blob/main/Week%208/Day%201/Prototyping_LangChain_Application_with_Production_Minded_Changes_Assignment.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8ZsP-j7w3zcL"
      },
      "source": [
        "# Prototyping LangChain Application with Production Minded Changes\n",
        "\n",
        "For our first breakout room we'll be exploring how to set-up a LangChain LCEL chain in a way that takes advantage of all of the amazing out of the box production ready features it offers.\n",
        "\n",
        "We'll also explore `Caching` and what makes it an invaluable tool when transitioning to production environments.\n",
        "\n",
        "ü§ù BREAKOUT ROOM #1:\n",
        "  - Task 1: Depends and Set-Up\n",
        "  - Task 2: Setting up RAG With Production in Mind\n",
        "  - Task 3: RAG LCEL Chain\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PpeN9ND0HKa0"
      },
      "source": [
        "## Task 1: Depends and Set-Up\n",
        "\n",
        "Let's get everything we need - we're going to use very specific versioning today to try to mitigate potential env. issues!\n",
        "\n",
        "> NOTE: Dependency issues are a large portion of what you're going to be tackling as you integrate new technology into your work - please keep in mind that one of the things you should be passively learning throughout this course is ways to mitigate dependency issues."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0P4IJUQF27jW",
        "outputId": "2f02f69d-3da1-4fad-865a-197fc4ac8d83"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "langgraph 0.2.16 requires langchain-core<0.3,>=0.2.27, but you have langchain-core 0.3.2 which is incompatible.\n",
            "ragas 0.1.20 requires langchain-core<0.3, but you have langchain-core 0.3.2 which is incompatible.\n",
            "langchain-experimental 0.3.2 requires langchain-core<0.4.0,>=0.3.6, but you have langchain-core 0.3.2 which is incompatible.\n",
            "langgraph-checkpoint 1.0.6 requires langchain-core<0.3,>=0.2.22, but you have langchain-core 0.3.2 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0m"
          ]
        }
      ],
      "source": [
        "!pip install -qU langchain_openai==0.2.0 langchain_community==0.3.0 langchain==0.3.0 pymupdf==1.24.10 qdrant-client==1.11.2 langchain_qdrant==0.1.4 langsmith==0.1.121"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYcWLzrmHgDb"
      },
      "source": [
        "We'll need an OpenAI API Key:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GZ8qfrFh_6ed",
        "outputId": "b4758d8f-e5dc-42cb-bb04-10f7903e6537"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import dotenv\n",
        "\n",
        "dotenv.load_dotenv()\n",
        "\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "piz2DUDuHiSO"
      },
      "source": [
        "And the LangSmith set-up:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wLZX5zowCh-q",
        "outputId": "bf10d8e6-4d1f-4eea-d7af-2e4e4645c443"
      },
      "outputs": [],
      "source": [
        "import uuid\n",
        "\n",
        "langchainapikey = os.environ.get(\"LANGCHAIN_API_KEY\")\n",
        "\n",
        "os.environ[\"LANGCHAIN_PROJECT\"] = f\"AIM Week 8 Assignment 1 - {uuid.uuid4().hex[0:8]}\"\n",
        "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
        "os.environ[\"LANGCHAIN_ENDPOINT\"] = \"https://api.smith.langchain.com\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WmwNTziKHrQm"
      },
      "source": [
        "Let's verify our project so we can leverage it in LangSmith later."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T6GZmkVkFcHq",
        "outputId": "5d5c580a-b3ce-46e0-93b6-65ab57fae92a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "AIM Week 8 Assignment 1 - f56a659b\n"
          ]
        }
      ],
      "source": [
        "print(os.environ[\"LANGCHAIN_PROJECT\"])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "un_ppfaAHv1J"
      },
      "source": [
        "## Task 2: Setting up RAG With Production in Mind\n",
        "\n",
        "This is the most crucial step in the process - in order to take advantage of:\n",
        "\n",
        "- Asyncronous requests\n",
        "- Parallel Execution in Chains\n",
        "- And more...\n",
        "\n",
        "You must...use LCEL. These benefits are provided out of the box and largely optimized behind the scenes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vGi-db23JMAL"
      },
      "source": [
        "### Building our RAG Components: Retriever\n",
        "\n",
        "We'll start by building some familiar components - and showcase how they automatically scale to production features."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zvbT3HSDJemE"
      },
      "source": [
        "Please upload a PDF file to use in this example!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {},
      "outputs": [],
      "source": [
        "from ipywidgets import FileUpload\n",
        "from IPython.display import display\n",
        "import tempfile\n",
        "import os\n",
        "from langchain_community.document_loaders import PyMuPDFLoader\n",
        "from langchain_text_splitters import RecursiveCharacterTextSplitter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {},
      "outputs": [],
      "source": [
        "def process_uploaded_file(change):\n",
        "    global docs  # Make docs a global variable\n",
        "    if uploader.value:\n",
        "        # Get the uploaded file\n",
        "        uploaded_file = uploader.value[0]  # Access the first item of the tuple\n",
        "        file_content = uploaded_file.content\n",
        "        \n",
        "        # Save the content to a temporary file\n",
        "        with tempfile.NamedTemporaryFile(delete=False, suffix='.pdf', mode='wb') as temp_file:\n",
        "            temp_file.write(file_content)\n",
        "            temp_file_path = temp_file.name\n",
        "        \n",
        "        print(f\"Temporary file created at: {temp_file_path}\")\n",
        "        print(f\"File size: {os.path.getsize(temp_file_path)} bytes\")\n",
        "        \n",
        "        # Check if the file is not empty\n",
        "        if os.path.getsize(temp_file_path) > 0:\n",
        "            try:\n",
        "                # Load and process the PDF\n",
        "                loader = PyMuPDFLoader(temp_file_path)\n",
        "                documents = loader.load()\n",
        "                \n",
        "                # Initialize the text splitter\n",
        "                text_splitter = RecursiveCharacterTextSplitter(\n",
        "                    chunk_size=1000,\n",
        "                    chunk_overlap=200,\n",
        "                    length_function=len,\n",
        "                )\n",
        "                \n",
        "                # Split the documents into chunks\n",
        "                docs = text_splitter.split_documents(documents)\n",
        "                \n",
        "                print(f\"Document split into {len(docs)} chunks.\")\n",
        "            except Exception as e:\n",
        "                print(f\"Error processing the PDF: {str(e)}\")\n",
        "        else:\n",
        "            print(\"Error: The uploaded file is empty.\")\n",
        "        \n",
        "        # Clean up the temporary file\n",
        "        os.unlink(temp_file_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "239ff1e896f9445b8a4545446949d53c",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "FileUpload(value=(), accept='.pdf', description='Upload')"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Temporary file created at: /var/folders/jr/_qkyxp313390z32jmym7j9sm0000gp/T/tmp5z11sk93.pdf\n",
            "File size: 6394463 bytes\n",
            "Document split into 129 chunks.\n"
          ]
        }
      ],
      "source": [
        "# Create and display the file uploader\n",
        "uploader = FileUpload(accept='.pdf', multiple=False)\n",
        "display(uploader)\n",
        "\n",
        "# Attach the process_uploaded_file function to the uploader\n",
        "uploader.observe(process_uploaded_file, names='value')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Vector store set up successfully.\n"
          ]
        }
      ],
      "source": [
        "if 'docs' in globals():\n",
        "    vectorstore = QdrantVectorStore(\n",
        "        client=client,\n",
        "        collection_name=collection_name,\n",
        "        embedding=cached_embedder)\n",
        "    vectorstore.add_documents(docs)\n",
        "    retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})\n",
        "    print(\"Vector store set up successfully.\")\n",
        "else:\n",
        "    print(\"Error: 'docs' not defined. Please ensure the file is uploaded and processed.\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {},
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='1. The document is titled \"Use and Care Manual SPE68C75UC | Bosch.\"\\n2. It is authored by BSH Hausger√§te GmbH, located in Munich, Germany.\\n3. The document serves as a user manual for the Bosch Dishwasher model SPE68C75UC.\\n4. It contains a total of 60 pages.\\n5. The document was created on October 10, 2023.\\n6. It is formatted as a PDF version 1.4.\\n7. The manual includes troubleshooting tips for the dishwasher.\\n8. It covers topics related to transportation, storage, and disposal of the appliance.\\n9. The document provides guidance on customer service contacts.\\n10. It details technical specifications of the dishwasher.\\n11. There is a section on the warranty for the appliance.\\n12. The document addresses the AquaStop¬Æ Plus Pledge for leak prevention.\\n13. It includes information about the model number (E-Nr.) and production number (FD).\\n14. Safety instructions are prominently featured.\\n15. The manual emphasizes the importance of reading all instructions before use.\\n16. It advises users to keep the manual for future reference.\\n17. There are sections dedicated to cleaning and maintaining the dishwasher.\\n18. The manual discusses the formation of discolorations on plastic parts.\\n19. It explains how to remove coatings that may form inside the appliance.\\n20. The document includes a list of colored coatings that may appear on dishware.\\n21. It mentions that some coatings are harmless to health.\\n22. The manual outlines steps for mechanical cleaning of the appliance.\\n23. It provides information on warranty exclusions.\\n24. There is guidance on what to do if the appliance is damaged in transit.\\n25. The document is produced by ST4 PDF Engine.\\n26. It is categorized under usage instructions and care for kitchen appliances.\\n27. The manual contains a section on extended warranty options.\\n28. It suggests remedies for out-of-warranty products.\\n29. The manual is structured with clear headings and numbered sections.\\n30. It includes technical information regarding free and open-source software used in the appliance.\\n31. The document has a table of contents for easy navigation.\\n32. It emphasizes the importance of regular maintenance.\\n33. There are instructions for vacation and storage of the appliance.\\n34. The manual includes steps for transporting the appliance safely.\\n35. It addresses customer service options for assistance.\\n36. The document is intended for consumers who own the Bosch dishwasher model SPE68C75UC.\\n37. It provides detailed cleaning instructions for optimal performance.\\n38. The manual outlines the warranty duration and coverage.\\n39. It includes visual aids or diagrams (implied by sections).\\n40. The document references specific pages for additional information.\\n41. It mentions the potential for film formation due to food residues.\\n42. The manual stresses the importance of electrical safety.\\n43. It provides a contact method for customer service inquiries.\\n44. The document outlines how to handle appliance repairs.\\n45. It is part of a larger collection of user manuals for Bosch appliances.\\n46. The manual is designed to enhance user understanding and safety.\\n47. It may contain troubleshooting flowcharts (implied).\\n48. The document is accessible as a PDF for digital viewing.\\n49. It includes a statement of limited product warranty.\\n50. The manual promotes responsible disposal of old appliances.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 670, 'prompt_tokens': 1586, 'total_tokens': 2256, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-4o-mini-2024-07-18', 'system_fingerprint': 'fp_f85bea6784', 'finish_reason': 'stop', 'logprobs': None}, id='run-9006c01d-55bc-476e-af37-6195df8c8fc2-0', usage_metadata={'input_tokens': 1586, 'output_tokens': 670, 'total_tokens': 2256})"
            ]
          },
          "execution_count": 11,
          "metadata": {},
          "output_type": "execute_result"
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): api.smith.langchain.com:443\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/batch HTTP/11\" 202 33\n"
          ]
        }
      ],
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain.storage import LocalFileStore\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "\n",
        "# Typical Embedding Model\n",
        "core_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# Typical QDrant Client Set-up\n",
        "collection_name = f\"pdf_to_parse_{uuid.uuid4()}\"\n",
        "client = QdrantClient(\":memory:\")\n",
        "client.create_collection(\n",
        "    collection_name=collection_name,\n",
        "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
        ")\n",
        "\n",
        "# Adding cache!\n",
        "store = LocalFileStore(\"./cache/\")\n",
        "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    core_embeddings, store, namespace=core_embeddings.model\n",
        ")\n",
        "\n",
        "# Typical QDrant Vector Store Set-up\n",
        "vectorstore = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=collection_name,\n",
        "    embedding=cached_embedder)\n",
        "vectorstore.add_documents(docs)\n",
        "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})\n",
        "\n",
        "# RAG Prompt setup\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "rag_system_prompt_template = \"\"\"\\\n",
        "You are a helpful assistant that uses the provided context to answer questions. Never reference this prompt, or the existance of context.\n",
        "\"\"\"\n",
        "\n",
        "rag_message_list = [\n",
        "    {\"role\" : \"system\", \"content\" : rag_system_prompt_template},\n",
        "]\n",
        "\n",
        "rag_user_prompt_template = \"\"\"\\\n",
        "Question:\n",
        "{question}\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", rag_system_prompt_template),\n",
        "    (\"human\", rag_user_prompt_template)\n",
        "])\n",
        "\n",
        "# Generation setup\n",
        "from langchain_core.globals import set_llm_cache\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")\n",
        "\n",
        "# Setting up the cache\n",
        "from langchain_core.caches import InMemoryCache\n",
        "\n",
        "set_llm_cache(InMemoryCache())\n",
        "\n",
        "# RAG LCEL Chain\n",
        "from operator import itemgetter\n",
        "from langchain_core.runnables.passthrough import RunnablePassthrough\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "        {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "        | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "        | chat_prompt | chat_model\n",
        "    )\n",
        "\n",
        "# Test the chain\n",
        "retrieval_augmented_qa_chain.invoke({\"question\" : \"Write 50 things about this document!\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kucGy3f0Jhdi"
      },
      "source": [
        "We'll define our chunking strategy."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3_zRRNcLKCZh"
      },
      "source": [
        "We'll chunk our uploaded PDF file."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U4XLeqJMKGdQ"
      },
      "source": [
        "#### QDrant Vector Database - Cache Backed Embeddings\n",
        "\n",
        "The process of embedding is typically a very time consuming one - we must, for ever single vector in our VDB as well as query:\n",
        "\n",
        "1. Send the text to an API endpoint (self-hosted, OpenAI, etc)\n",
        "2. Wait for processing\n",
        "3. Receive response\n",
        "\n",
        "This process costs time, and money - and occurs *every single time a document gets converted into a vector representation*.\n",
        "\n",
        "Instead, what if we:\n",
        "\n",
        "1. Set up a cache that can hold our vectors and embeddings (similar to, or in some cases literally a vector database)\n",
        "2. Send the text to an API endpoint (self-hosted, OpenAI, etc)\n",
        "3. Check the cache to see if we've already converted this text before.\n",
        "  - If we have: Return the vector representation\n",
        "  - Else: Wait for processing and proceed\n",
        "4. Store the text that was converted alongside its vector representation in a cache of some kind.\n",
        "5. Return the vector representation\n",
        "\n",
        "Notice that we can shortcut some instances of \"Wait for processing and proceed\".\n",
        "\n",
        "Let's see how this is implemented in the code."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "dzPUTCua98b2"
      },
      "outputs": [],
      "source": [
        "from qdrant_client import QdrantClient\n",
        "from qdrant_client.http.models import Distance, VectorParams\n",
        "from langchain_openai.embeddings import OpenAIEmbeddings\n",
        "from langchain.storage import LocalFileStore\n",
        "from langchain_qdrant import QdrantVectorStore\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "\n",
        "# Typical Embedding Model\n",
        "core_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "\n",
        "# Typical QDrant Client Set-up\n",
        "collection_name = f\"pdf_to_parse_{uuid.uuid4()}\"\n",
        "client = QdrantClient(\":memory:\")\n",
        "client.create_collection(\n",
        "    collection_name=collection_name,\n",
        "    vectors_config=VectorParams(size=1536, distance=Distance.COSINE),\n",
        ")\n",
        "\n",
        "# Adding cache!\n",
        "store = LocalFileStore(\"./cache/\")\n",
        "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    core_embeddings, store, namespace=core_embeddings.model\n",
        ")\n",
        "\n",
        "# Typical QDrant Vector Store Set-up\n",
        "vectorstore = QdrantVectorStore(\n",
        "    client=client,\n",
        "    collection_name=collection_name,\n",
        "    embedding=cached_embedder)\n",
        "vectorstore.add_documents(docs)\n",
        "retriever = vectorstore.as_retriever(search_type=\"mmr\", search_kwargs={\"k\": 3})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QVZGvmNYLomp"
      },
      "source": [
        "##### ‚ùì Question #1:\n",
        "\n",
        "What are some limitations you can see with this approach? When is this most/least useful. Discuss with your group!\n",
        "\n",
        "Based on the context provided in the document, here are some suggested answers for Questions 1 and 2:\n",
        "\n",
        "Question #1: Limitations and usefulness of cache-backed embeddings\n",
        "\n",
        "Limitations:\n",
        "1. Storage requirements: Caching embeddings requires additional storage space, which could become significant for large datasets.\n",
        "2. Staleness: If the underlying embedding model is updated, cached embeddings may become outdated.\n",
        "3. Initial overhead: The first-time embedding process still incurs the full cost and time.\n",
        "4. Cache management: Implementing and maintaining the cache adds complexity to the system.\n",
        "\n",
        "Most useful:\n",
        "1. For frequently accessed documents or queries, reducing API calls and processing time.\n",
        "2. In applications with limited bandwidth or high latency to embedding services.\n",
        "3. When working with static datasets that don't change frequently."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vZAOhyb3L9iD"
      },
      "source": [
        "##### üèóÔ∏è Activity #1:\n",
        "\n",
        "Create a simple experiment that tests the cache-backed embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M_Mekif6MDqe",
        "outputId": "f8014241-e787-4d39-a61c-e41485cb6676"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First embedding (not cached):\n",
            "Time taken: 0.2249 seconds\n",
            "\n",
            "Second embedding (should be cached):\n",
            "Time taken: 0.3181 seconds\n",
            "\n",
            "Speedup: -41.47%\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from langchain_openai import OpenAIEmbeddings\n",
        "from langchain.storage import LocalFileStore\n",
        "from langchain.embeddings import CacheBackedEmbeddings\n",
        "\n",
        "# Set up the embeddings and cache\n",
        "core_embeddings = OpenAIEmbeddings(model=\"text-embedding-3-small\")\n",
        "store = LocalFileStore(\"./cache/\")\n",
        "cached_embedder = CacheBackedEmbeddings.from_bytes_store(\n",
        "    core_embeddings, store, namespace=core_embeddings.model\n",
        ")\n",
        "\n",
        "# Test text\n",
        "test_text = \"This is a sample text to test cache-backed embeddings.\"\n",
        "\n",
        "# Function to measure embedding time\n",
        "def time_embedding(embedder, text):\n",
        "    start_time = time.time()\n",
        "    _ = embedder.embed_query(text)\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time\n",
        "\n",
        "# First embedding (should take longer as it's not cached)\n",
        "print(\"First embedding (not cached):\")\n",
        "first_time = time_embedding(cached_embedder, test_text)\n",
        "print(f\"Time taken: {first_time:.4f} seconds\")\n",
        "\n",
        "# Second embedding (should be faster due to cache)\n",
        "print(\"\\nSecond embedding (should be cached):\")\n",
        "second_time = time_embedding(cached_embedder, test_text)\n",
        "print(f\"Time taken: {second_time:.4f} seconds\")\n",
        "\n",
        "# Calculate and print the speedup\n",
        "speedup = (first_time - second_time) / first_time * 100\n",
        "print(f\"\\nSpeedup: {speedup:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DH0i-YovL8kZ"
      },
      "source": [
        "### Augmentation\n",
        "\n",
        "We'll create the classic RAG Prompt and create our `ChatPromptTemplates` as per usual."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "WchaoMEx9j69"
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "\n",
        "rag_system_prompt_template = \"\"\"\\\n",
        "You are a helpful assistant that uses the provided context to answer questions. Never reference this prompt, or the existance of context.\n",
        "\"\"\"\n",
        "\n",
        "rag_message_list = [\n",
        "    {\"role\" : \"system\", \"content\" : rag_system_prompt_template},\n",
        "]\n",
        "\n",
        "rag_user_prompt_template = \"\"\"\\\n",
        "Question:\n",
        "{question}\n",
        "Context:\n",
        "{context}\n",
        "\"\"\"\n",
        "\n",
        "chat_prompt = ChatPromptTemplate.from_messages([\n",
        "    (\"system\", rag_system_prompt_template),\n",
        "    (\"human\", rag_user_prompt_template)\n",
        "])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UQKnByVWMpiK"
      },
      "source": [
        "### Generation\n",
        "\n",
        "Like usual, we'll set-up a `ChatOpenAI` model - and we'll use the fan favourite `gpt-4o-mini` for today.\n",
        "\n",
        "However, we'll also implement...a PROMPT CACHE!\n",
        "\n",
        "In essence, this works in a very similar way to the embedding cache - if we've seen this prompt before, we just use the stored response."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "fOXKkaY7ABab"
      },
      "outputs": [],
      "source": [
        "from langchain_core.globals import set_llm_cache\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "chat_model = ChatOpenAI(model=\"gpt-4o-mini\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mhv8IqZoM9cY"
      },
      "source": [
        "Setting up the cache can be done as follows:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "id": "thqam26gAyzN"
      },
      "outputs": [],
      "source": [
        "from langchain_core.caches import InMemoryCache\n",
        "\n",
        "set_llm_cache(InMemoryCache())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CvxEovcEM_oA"
      },
      "source": [
        "##### ‚ùì Question #2:\n",
        "\n",
        "What are some limitations you can see with this approach? When is this most/least useful. Discuss with your group!\n",
        "\n",
        "Limitations:\n",
        "1. Lack of context sensitivity: Cached responses may not account for subtle changes in context or user intent.\n",
        "2. Potential for outdated information: If the LLM is updated or fine-tuned, cached responses may become obsolete.\n",
        "3. Storage requirements: Storing a large number of prompt-response pairs can be memory-intensive.\n",
        "4. Reduced adaptability: Relying heavily on cached responses may limit the system's ability to provide novel or adaptive answers.\n",
        "\n",
        "Most useful:\n",
        "1. For frequently asked questions or common queries with stable answers.\n",
        "2. In applications requiring quick response times, such as customer service chatbots.\n",
        "3. To reduce costs associated with repeated API calls to language models.\n",
        "4. For providing consistent answers to standard queries across multiple users."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3iCMjVYKNEeV"
      },
      "source": [
        "##### üèóÔ∏è Activity #2:\n",
        "\n",
        "Create a simple experiment that tests the cache-backed embeddings."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QT5GfmsHNFqP",
        "outputId": "4b994cff-f508-4de7-da36-b2b56878c626"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First response (not cached):\n",
            "Time taken: 0.4625 seconds\n",
            "\n",
            "Second response (should be cached):\n",
            "Time taken: 0.0010 seconds\n",
            "\n",
            "Speedup: 99.79%\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.caches import InMemoryCache\n",
        "from langchain_core.globals import set_llm_cache\n",
        "\n",
        "# Set up the LLM and cache\n",
        "chat_model = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "set_llm_cache(InMemoryCache())\n",
        "\n",
        "# Test prompt\n",
        "test_prompt = \"What is the capital of France?\"\n",
        "\n",
        "# Function to measure response time\n",
        "def time_llm_response(model, prompt):\n",
        "    start_time = time.time()\n",
        "    _ = model.invoke(prompt)\n",
        "    end_time = time.time()\n",
        "    return end_time - start_time\n",
        "\n",
        "# First response (should take longer as it's not cached)\n",
        "print(\"First response (not cached):\")\n",
        "first_time = time_llm_response(chat_model, test_prompt)\n",
        "print(f\"Time taken: {first_time:.4f} seconds\")\n",
        "\n",
        "# Second response (should be faster due to cache)\n",
        "print(\"\\nSecond response (should be cached):\")\n",
        "second_time = time_llm_response(chat_model, test_prompt)\n",
        "print(f\"Time taken: {second_time:.4f} seconds\")\n",
        "\n",
        "# Calculate and print the speedup\n",
        "speedup = (first_time - second_time) / first_time * 100\n",
        "print(f\"\\nSpeedup: {speedup:.2f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zyPnNWb9NH7W"
      },
      "source": [
        "## Task 3: RAG LCEL Chain\n",
        "\n",
        "We'll also set-up our typical RAG chain using LCEL.\n",
        "\n",
        "However, this time: We'll specifically call out that the `context` and `question` halves of the first \"link\" in the chain are executed *in parallel* by default!\n",
        "\n",
        "Thanks, LCEL!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "3JNvSsx_CEtI"
      },
      "outputs": [],
      "source": [
        "from operator import itemgetter\n",
        "from langchain_core.runnables.passthrough import RunnablePassthrough\n",
        "\n",
        "retrieval_augmented_qa_chain = (\n",
        "        {\"context\": itemgetter(\"question\") | retriever, \"question\": itemgetter(\"question\")}\n",
        "        | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
        "        | chat_prompt | chat_model\n",
        "    )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sx--wVctNdGa"
      },
      "source": [
        "Let's test it out!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "43uQegbnDQKP",
        "outputId": "7f0b9ab2-3dfd-461b-90a1-a159a0975edc"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "AIMessage(content='1. The document is a Use and Care Manual for a Bosch dishwasher model SPE68C75UC.\\n2. The document contains troubleshooting information on page 16.\\n3. Transportation, storage, and disposal instructions are on page 17.\\n4. Customer service details are provided on page 18.\\n5. Technical specifications are listed on page 19.\\n6. The document includes a statement of limited product warranty on page 20.\\n7. Information about the warranty coverage and duration is outlined.\\n8. There is a section on extended warranty options.\\n9. Repair and replacement options are discussed as exclusive remedies.\\n10. The document mentions out-of-warranty products.\\n11. Colored coatings inside the dishwasher are mentioned on page 45.\\n12. The difficulty of removing coatings from stainless steel dishware is highlighted.\\n13. The formation of films in the dishwasher is attributed to substances in vegetables and tap water.\\n14. Instructions for cleaning the appliance to remove coatings are provided.\\n15. The document mentions the discoloration of plastic parts inside the dishwasher.\\n16. General information is provided in the document.\\n17. Safety instructions are emphasized to reduce the risk of fire, electrical shock, or injury.\\n18. Installation instructions are included with the appliance.\\n19. Users are advised to read and understand all instructions before using the appliance.\\n20. Keeping the manual and product information for future reference is recommended.\\n21. The document warns against connecting a damaged appliance.\\n22. The manual provides important safety instructions.\\n23. Users are instructed to read and save the safety instructions.\\n24. The document includes a section on models numbers and production details.\\n25. AquaStop¬Æ Plus Pledge details are mentioned in the manual.\\n26. Information regarding Free and Open Source Software is outlined.\\n27. The document covers warranty exclusions.\\n28. The manual mentions the creation date as \"D:20231010160506+02\\'00\".\\n29. The produced date is also mentioned as \"D:20231010160506+02\\'00\".\\n30. The PDF format used is version 1.4.\\n31. The author of the document is BSH Hausger√§te GmbH from Germany.\\n32. The page content includes information about cleaning and maintenance.\\n33. The document has a total of 60 pages.\\n34. The format of the document is a PDF.\\n35. The document is created using SCHEMA ST4.\\n36. The document is produced by ST4 PDF Engine (Build 12.0.4.0).\\n37. The document provides instructions on removing the appliance for transportation.\\n38. It also includes guidance on storing the appliance.\\n39. The manual discusses the disposal of the old appliance.\\n40. The model number (E-Nr.) and production number (FD) are mentioned in the document.\\n41. Technical specifications for the dishwasher are detailed.\\n42. The document explains what the warranty covers and who it applies to.\\n43. The warranty duration is specified in the manual.\\n44. The manual mentions an exclusive remedy of repair or replacement.\\n45. The document includes details about warranty exclusions.\\n46. The document mentions the use of machine cleaning products.\\n47. It highlights that coatings on dishware may not always be completely removed.\\n48. The manual assures that the coatings are harmless to health.\\n49. The document provides guidance on cleaning metal components on dishware.\\n50. The document emphasizes the importance of safety and proper maintenance of the dishwasher.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 696, 'prompt_tokens': 1600, 'total_tokens': 2296, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-853b6719-ed9e-44de-9c2a-44fca76836bb-0', usage_metadata={'input_tokens': 1600, 'output_tokens': 696, 'total_tokens': 2296})"
            ]
          },
          "execution_count": 19,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "retrieval_augmented_qa_chain.invoke({\"question\" : \"Write 50 things about this document!\"})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0tYAvHrJNecy"
      },
      "source": [
        "##### üèóÔ∏è Activity #3:\n",
        "\n",
        "Show, through LangSmith, the different between a trace that is leveraging cache-backed embeddings and LLM calls - and one that isn't.\n",
        "\n",
        "Post screenshots in the notebook!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "First run (not cached):\n",
            "Time taken: 0.2019 seconds\n",
            "\n",
            "Second run (should be cached):\n",
            "Time taken: 0.1976 seconds\n",
            "\n",
            "Speedup: 2.16%\n",
            "\n",
            "Results comparison:\n",
            "First run result:\n",
            "content='1. The document is a Use and Care Manual for a Bosch dishwasher model SPE68C75UC.\\n2. The document contains troubleshooting information on page 16.\\n3. Transportation, storage, and disposal instructions are on page 17.\\n4. Customer service details are provided on page 18.\\n5. Technical specifications are listed on page 19.\\n6. The document includes a statement of limited product warranty on page 20.\\n7. Information about the warranty coverage and duration is outlined.\\n8. There is a section on extended warranty options.\\n9. Repair and replacement options are discussed as exclusive remedies.\\n10. The document mentions out-of-warranty products.\\n11. Colored coatings inside the dishwasher are mentioned on page 45.\\n12. The difficulty of removing coatings from stainless steel dishware is highlighted.\\n13. The formation of films in the dishwasher is attributed to substances in vegetables and tap water.\\n14. Instructions for cleaning the appliance to remove coatings are provided.\\n15. The document mentions the discoloration of plastic parts inside the dishwasher.\\n16. General information is provided in the document.\\n17. Safety instructions are emphasized to reduce the risk of fire, electrical shock, or injury.\\n18. Installation instructions are included with the appliance.\\n19. Users are advised to read and understand all instructions before using the appliance.\\n20. Keeping the manual and product information for future reference is recommended.\\n21. The document warns against connecting a damaged appliance.\\n22. The manual provides important safety instructions.\\n23. Users are instructed to read and save the safety instructions.\\n24. The document includes a section on models numbers and production details.\\n25. AquaStop¬Æ Plus Pledge details are mentioned in the manual.\\n26. Information regarding Free and Open Source Software is outlined.\\n27. The document covers warranty exclusions.\\n28. The manual mentions the creation date as \"D:20231010160506+02\\'00\".\\n29. The produced date is also mentioned as \"D:20231010160506+02\\'00\".\\n30. The PDF format used is version 1.4.\\n31. The author of the document is BSH Hausger√§te GmbH from Germany.\\n32. The page content includes information about cleaning and maintenance.\\n33. The document has a total of 60 pages.\\n34. The format of the document is a PDF.\\n35. The document is created using SCHEMA ST4.\\n36. The document is produced by ST4 PDF Engine (Build 12.0.4.0).\\n37. The document provides instructions on removing the appliance for transportation.\\n38. It also includes guidance on storing the appliance.\\n39. The manual discusses the disposal of the old appliance.\\n40. The model number (E-Nr.) and production number (FD) are mentioned in the document.\\n41. Technical specifications for the dishwasher are detailed.\\n42. The document explains what the warranty covers and who it applies to.\\n43. The warranty duration is specified in the manual.\\n44. The manual mentions an exclusive remedy of repair or replacement.\\n45. The document includes details about warranty exclusions.\\n46. The document mentions the use of machine cleaning products.\\n47. It highlights that coatings on dishware may not always be completely removed.\\n48. The manual assures that the coatings are harmless to health.\\n49. The document provides guidance on cleaning metal components on dishware.\\n50. The document emphasizes the importance of safety and proper maintenance of the dishwasher.' additional_kwargs={'refusal': None} response_metadata={'token_usage': {'completion_tokens': 696, 'prompt_tokens': 1600, 'total_tokens': 2296, 'completion_tokens_details': {'reasoning_tokens': 0}, 'prompt_tokens_details': {'cached_tokens': 0}}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None} id='run-853b6719-ed9e-44de-9c2a-44fca76836bb-0' usage_metadata={'input_tokens': 1600, 'output_tokens': 696, 'total_tokens': 2296}\n",
            "\n",
            "Second run result:\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Set up the cache\n",
        "cache = InMemoryCache()\n",
        "\n",
        "# Add cache to the chain\n",
        "cached_chain = retrieval_augmented_qa_chain.with_config(configurable={\"cache\": cache})\n",
        "\n",
        "# Function to measure response time\n",
        "def time_chain_response(chain, input_data):\n",
        "    start_time = time.time()\n",
        "    result = chain.invoke(input_data)\n",
        "    end_time = time.time()\n",
        "    return result, end_time - start_time\n",
        "\n",
        "# Test input\n",
        "test_input = {\"question\": \"Write 50 things about this document!\"}\n",
        "\n",
        "# First run (not cached)\n",
        "print(\"First run (not cached):\")\n",
        "first_result, first_time = time_chain_response(cached_chain, test_input)\n",
        "print(f\"Time taken: {first_time:.4f} seconds\")\n",
        "\n",
        "# Second run (should be cached)\n",
        "print(\"\\nSecond run (should be cached):\")\n",
        "second_result, second_time = time_chain_response(cached_chain, test_input)\n",
        "print(f\"Time taken: {second_time:.4f} seconds\")\n",
        "\n",
        "# Calculate and print the speedup\n",
        "speedup = (first_time - second_time) / first_time * 100\n",
        "print(f\"\\nSpeedup: {speedup:.2f}%\")\n",
        "\n",
        "# Compare results\n",
        "print(\"\\nResults comparison:\")\n",
        "print(\"First run result:\")\n",
        "print(first_result)\n",
        "print(\"\\nSecond run result:\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Successfully created new project: Test_Project_20241004_080054_535737 with ID: 66025f6a-3525-4452-9821-01cfc61400c2\n"
          ]
        }
      ],
      "source": [
        "import uuid\n",
        "from datetime import datetime\n",
        "\n",
        "new_project_name = f\"Test_Project_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:6]}\"\n",
        "try:\n",
        "    new_project = client.create_project(new_project_name)\n",
        "    print(f\"Successfully created new project: {new_project_name} with ID: {new_project.id}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating project: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "create_run returned None\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    test_run = client.create_run(\n",
        "        project_name=new_project_name,\n",
        "        name=\"Test Run\",\n",
        "        run_type=\"chain\",\n",
        "        inputs={\"question\": \"Test question\"}\n",
        "    )\n",
        "    if test_run is None:\n",
        "        print(\"create_run returned None\")\n",
        "    else:\n",
        "        print(f\"Successfully created run with ID: {test_run.id}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating run: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 1 runs in the project\n",
            "Run ID: 693760f5-5093-40cc-b5a5-4c3f929d4b41, Name: Test Run\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    runs = list(client.list_runs(project_name=new_project_name, limit=10))\n",
        "    print(f\"Found {len(runs)} runs in the project\")\n",
        "    for run in runs:\n",
        "        print(f\"Run ID: {run.id}, Name: {run.name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error listing runs: {e}\")\n",
        "    raise"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run Details: id=UUID('693760f5-5093-40cc-b5a5-4c3f929d4b41') name='Test Run' start_time=datetime.datetime(2024, 10, 4, 12, 1, 7, 826029) run_type='chain' end_time=None extra={'runtime': {'sdk': 'langsmith-py', 'sdk_version': '0.1.121', 'library': 'langsmith', 'platform': 'macOS-14.6.1-arm64-arm-64bit', 'runtime': 'python', 'py_implementation': 'CPython', 'runtime_version': '3.11.9', 'langchain_version': '0.3.0', 'langchain_core_version': '0.3.2'}, 'metadata': {'revision_id': '2ad5c21'}} error=None serialized=None events=[] inputs={'question': 'Test question'} outputs=None reference_example_id=None parent_run_id=None tags=[] session_id=UUID('66025f6a-3525-4452-9821-01cfc61400c2') child_run_ids=None child_runs=None feedback_stats=None app_path='/o/8fd26bf9-f5de-54a5-9d40-07bb2733eb7c/projects/p/66025f6a-3525-4452-9821-01cfc61400c2/r/693760f5-5093-40cc-b5a5-4c3f929d4b41?trace_id=693760f5-5093-40cc-b5a5-4c3f929d4b41&start_time=2024-10-04T12:01:07.826029' manifest_id=None status='pending' prompt_tokens=0 completion_tokens=0 total_tokens=0 first_token_time=None total_cost=None prompt_cost=None completion_cost=None parent_run_ids=[] trace_id=UUID('693760f5-5093-40cc-b5a5-4c3f929d4b41') dotted_order='20241004T120107826029Z693760f5-5093-40cc-b5a5-4c3f929d4b41' in_dataset=False\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    run_id = \"693760f5-5093-40cc-b5a5-4c3f929d4b41\"\n",
        "    run_details = client.read_run(run_id)\n",
        "    print(f\"Run Details: {run_details}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error fetching run details: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 28,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "New run creation result: None\n",
            "Found 2 runs in the project after new creation\n",
            "Run ID: c3adacb9-f223-482c-8a03-13f13e57de2b, Name: New Test Run\n",
            "Run ID: 693760f5-5093-40cc-b5a5-4c3f929d4b41, Name: Test Run\n"
          ]
        }
      ],
      "source": [
        "import time\n",
        "\n",
        "try:\n",
        "    new_run = client.create_run(\n",
        "        project_name=\"Test_Project_20241004_080054_535737\",\n",
        "        name=\"New Test Run\",\n",
        "        run_type=\"chain\",\n",
        "        inputs={\"question\": \"New test question\"}\n",
        "    )\n",
        "    print(f\"New run creation result: {new_run}\")\n",
        "    \n",
        "    # Wait a moment to allow for any potential lag\n",
        "    time.sleep(2)\n",
        "    \n",
        "    # List runs again\n",
        "    runs = list(client.list_runs(project_name=\"Test_Project_20241004_080054_535737\", limit=10))\n",
        "    print(f\"Found {len(runs)} runs in the project after new creation\")\n",
        "    for run in runs:\n",
        "        print(f\"Run ID: {run.id}, Name: {run.name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error in create and list process: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "for example in examples:\n",
        "    try:\n",
        "        run = client.create_run(\n",
        "            project_name=project_name,\n",
        "            name=\"QA Evaluation\",\n",
        "            run_type=\"chain\",\n",
        "            inputs=example.inputs\n",
        "        )\n",
        "        if run is None:\n",
        "            print(f\"create_run returned None for input: {example.inputs}\")\n",
        "            # List runs to get the most recent run\n",
        "            recent_runs = list(client.list_runs(project_name=project_name, limit=1))\n",
        "            if recent_runs:\n",
        "                run = recent_runs[0]\n",
        "                print(f\"Using most recent run with ID: {run.id}\")\n",
        "            else:\n",
        "                print(\"No recent runs found, skipping this example\")\n",
        "                continue\n",
        "        \n",
        "        # Proceed with your evaluation using 'run'\n",
        "        # ...\n",
        "\n",
        "    except Exception as e:\n",
        "        print(f\"Error processing example: {e}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 57,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "import logging\n",
        "from datetime import datetime, timezone\n",
        "from langsmith import Client\n",
        "from tenacity import retry, stop_after_attempt, wait_fixed\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.evaluation import CriteriaEvalChain, StringEvaluator\n",
        "from langchain.smith import RunEvalConfig"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 60,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.smith.langchain.com:443\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): api.smith.langchain.com:443\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /info HTTP/11\" 200 485\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /datasets?limit=1&name=qa_eval_dataset HTTP/11\" 200 435\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1 HTTP/11\" 200 733\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /examples?offset=0&inline_s3_urls=True&limit=100&dataset=c992bfb8-4a05-4d62-b44b-76a67620b4b6 HTTP/11\" 200 20287\n",
            "INFO:__main__:Processing 51 examples\n",
            "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
            "DEBUG:httpx:load_verify_locations cafile='/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/certifi/cacert.pem'\n",
            "DEBUG:httpx:load_ssl_context verify=True cert=None trust_env=True http2=False\n",
            "DEBUG:httpx:load_verify_locations cafile='/opt/anaconda3/envs/llmops-course/lib/python3.11/site-packages/certifi/cacert.pem'\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 271d6ec0-433c-476d-8eaf-75352f82f7ce\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322202d40>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14abb6710>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x174cc9a10>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'22'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_b201a22729b2202b9bb884ae78a208ec'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd750a80e5bc44a-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '22', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_b201a22729b2202b9bb884ae78a208ec', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd750a80e5bc44a-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_b201a22729b2202b9bb884ae78a208ec\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/271d6ec0-433c-476d-8eaf-75352f82f7ce HTTP/11\" 404 26\n",
            "WARNING:__main__:Error checking run status: Resource not found for /runs/271d6ec0-433c-476d-8eaf-75352f82f7ce. HTTPError('404 Client Error: Not Found for url: https://api.smith.langchain.com/runs/271d6ec0-433c-476d-8eaf-75352f82f7ce', '{\"detail\":\"Run not found\"}')\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/271d6ec0-433c-476d-8eaf-75352f82f7ce HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 202 1797\n",
            "INFO:__main__:Completed evaluation for run 271d6ec0-433c-476d-8eaf-75352f82f7ce\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: f2223ad9-f973-4c23-b8a7-3f2392bc1f43\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322202f20>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:04 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'20'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_574877991d990b5f5b84821aaa86e077'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd750c1cc2dc44a-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:04 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '20', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_574877991d990b5f5b84821aaa86e077', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd750c1cc2dc44a-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_574877991d990b5f5b84821aaa86e077\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/f2223ad9-f973-4c23-b8a7-3f2392bc1f43 HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/f2223ad9-f973-4c23-b8a7-3f2392bc1f43 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run f2223ad9-f973-4c23-b8a7-3f2392bc1f43\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: b10ed506-c739-4968-8322-7f2300522769\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221daa20>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x322169450>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x177d9a850>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'41'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_519bff13a9646d994bd24784e363f9ae'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd750e4094b43ca-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '41', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_519bff13a9646d994bd24784e363f9ae', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd750e4094b43ca-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_519bff13a9646d994bd24784e363f9ae\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/b10ed506-c739-4968-8322-7f2300522769 HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/b10ed506-c739-4968-8322-7f2300522769 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run b10ed506-c739-4968-8322-7f2300522769\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 5bc25e40-2cdc-4dd3-b49e-e0c57e8e195d\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221dad40>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'19'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_0c558725baccfc391f1be52aebb7a5b8'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd750ffbfe743ca-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '19', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_0c558725baccfc391f1be52aebb7a5b8', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd750ffbfe743ca-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_0c558725baccfc391f1be52aebb7a5b8\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/5bc25e40-2cdc-4dd3-b49e-e0c57e8e195d HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/5bc25e40-2cdc-4dd3-b49e-e0c57e8e195d HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run 5bc25e40-2cdc-4dd3-b49e-e0c57e8e195d\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: ed58dd89-1159-4aeb-b8ef-56b0c90f41da\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322202d40>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x174ca2450>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x174c90dd0>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'18'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_fd93e856e66011ba22532da2218427db'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd751249c5142de-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '18', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_fd93e856e66011ba22532da2218427db', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd751249c5142de-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_fd93e856e66011ba22532da2218427db\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/ed58dd89-1159-4aeb-b8ef-56b0c90f41da HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/ed58dd89-1159-4aeb-b8ef-56b0c90f41da HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run ed58dd89-1159-4aeb-b8ef-56b0c90f41da\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 63430948-b052-4039-a04f-e2cf2875adba\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322292de0>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x169f26290>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x3221ff190>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'18'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_89087363c6ca944ed1bc0bbb398a2007'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd751457bb54396-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '18', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_89087363c6ca944ed1bc0bbb398a2007', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd751457bb54396-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_89087363c6ca944ed1bc0bbb398a2007\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/63430948-b052-4039-a04f-e2cf2875adba HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/63430948-b052-4039-a04f-e2cf2875adba HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run 63430948-b052-4039-a04f-e2cf2875adba\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 1346f35c-0e80-4781-9c3e-9845493ca363\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14a93d620>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'18'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_e0c726abae130bd6903b7de04bcc1022'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd7515d2b504396-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '18', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_e0c726abae130bd6903b7de04bcc1022', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd7515d2b504396-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_e0c726abae130bd6903b7de04bcc1022\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/1346f35c-0e80-4781-9c3e-9845493ca363 HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/1346f35c-0e80-4781-9c3e-9845493ca363 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run 1346f35c-0e80-4781-9c3e-9845493ca363\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 790\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 1e16fee0-98dd-431d-8bce-19d85cf21d6c\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14a93d620>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:33 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'41'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_4de06a0beb836022f0249d5022a2cbb0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd751767ddc4396-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:33 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '41', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_4de06a0beb836022f0249d5022a2cbb0', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd751767ddc4396-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_4de06a0beb836022f0249d5022a2cbb0\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/1e16fee0-98dd-431d-8bce-19d85cf21d6c HTTP/11\" 404 26\n",
            "WARNING:__main__:Error checking run status: Resource not found for /runs/1e16fee0-98dd-431d-8bce-19d85cf21d6c. HTTPError('404 Client Error: Not Found for url: https://api.smith.langchain.com/runs/1e16fee0-98dd-431d-8bce-19d85cf21d6c', '{\"detail\":\"Run not found\"}')\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/1e16fee0-98dd-431d-8bce-19d85cf21d6c HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 202 1361\n",
            "INFO:__main__:Completed evaluation for run 1e16fee0-98dd-431d-8bce-19d85cf21d6c\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 2b2a3f15-939f-4a6c-b862-7fd36e1f2566\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x177df6980>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:37 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'23'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_2ca3437e8411a6723be3da47850f1dbf'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd7518cdba84396-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:37 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '23', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_2ca3437e8411a6723be3da47850f1dbf', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd7518cdba84396-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_2ca3437e8411a6723be3da47850f1dbf\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/2b2a3f15-939f-4a6c-b862-7fd36e1f2566 HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/2b2a3f15-939f-4a6c-b862-7fd36e1f2566 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run 2b2a3f15-939f-4a6c-b862-7fd36e1f2566\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 792\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: e2a78380-bb02-4d8c-9bb1-40f1848e7787\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322292b60>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'22'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_405d93ba02b1debdc8d460268e7310fe'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd751ac6d184396-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '22', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_405d93ba02b1debdc8d460268e7310fe', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd751ac6d184396-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_405d93ba02b1debdc8d460268e7310fe\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/e2a78380-bb02-4d8c-9bb1-40f1848e7787 HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/e2a78380-bb02-4d8c-9bb1-40f1848e7787 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run e2a78380-bb02-4d8c-9bb1-40f1848e7787\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 5a36bd17-56d0-428a-81a1-c0b6df8a217c\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x177df6160>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x14ac081d0>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x1745d2ed0>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'36'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_59f3de897b103b0bf13cd6557b596971'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd751d108f542a6-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '36', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_59f3de897b103b0bf13cd6557b596971', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd751d108f542a6-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_59f3de897b103b0bf13cd6557b596971\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/5a36bd17-56d0-428a-81a1-c0b6df8a217c HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/5a36bd17-56d0-428a-81a1-c0b6df8a217c HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run 5a36bd17-56d0-428a-81a1-c0b6df8a217c\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 791\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: b7ce2a55-abe6-4518-b7db-4ee71bcc7f87\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322293f60>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'288'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_a864785fe01f1c321ebd12e222908410'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd751ee9cc542a6-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '288', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_a864785fe01f1c321ebd12e222908410', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd751ee9cc542a6-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_a864785fe01f1c321ebd12e222908410\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/b7ce2a55-abe6-4518-b7db-4ee71bcc7f87 HTTP/11\" 404 26\n",
            "WARNING:__main__:Error checking run status: Resource not found for /runs/b7ce2a55-abe6-4518-b7db-4ee71bcc7f87. HTTPError('404 Client Error: Not Found for url: https://api.smith.langchain.com/runs/b7ce2a55-abe6-4518-b7db-4ee71bcc7f87', '{\"detail\":\"Run not found\"}')\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/b7ce2a55-abe6-4518-b7db-4ee71bcc7f87 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 202 1820\n",
            "INFO:__main__:Completed evaluation for run b7ce2a55-abe6-4518-b7db-4ee71bcc7f87\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 28a6c51e-6858-4015-90d9-df96ca4bd2e0\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174ca51c0>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:43:56 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'19'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_05eeaff77126c6366fcdfe1243893345'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd75203ecc342a6-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:43:56 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '19', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_05eeaff77126c6366fcdfe1243893345', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd75203ecc342a6-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_05eeaff77126c6366fcdfe1243893345\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/28a6c51e-6858-4015-90d9-df96ca4bd2e0 HTTP/11\" 404 26\n",
            "WARNING:__main__:Error checking run status: Resource not found for /runs/28a6c51e-6858-4015-90d9-df96ca4bd2e0. HTTPError('404 Client Error: Not Found for url: https://api.smith.langchain.com/runs/28a6c51e-6858-4015-90d9-df96ca4bd2e0', '{\"detail\":\"Run not found\"}')\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/28a6c51e-6858-4015-90d9-df96ca4bd2e0 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run 28a6c51e-6858-4015-90d9-df96ca4bd2e0\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: c1797fac-e660-4e11-8392-6da89f649a14\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14a93d620>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'22'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_304ee569bfbe5f0150386e8c0bcc1d82'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd7521fddf542a6-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '22', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_304ee569bfbe5f0150386e8c0bcc1d82', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd7521fddf542a6-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_304ee569bfbe5f0150386e8c0bcc1d82\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/c1797fac-e660-4e11-8392-6da89f649a14 HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/c1797fac-e660-4e11-8392-6da89f649a14 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run c1797fac-e660-4e11-8392-6da89f649a14\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 792\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 950a3ab7-5826-40b1-8a47-a89aa6ba0363\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174ca51c0>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'18'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_08006c34d0afae5bfb08338f7c439914'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd7523c5f7842a6-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '18', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_08006c34d0afae5bfb08338f7c439914', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd7523c5f7842a6-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_08006c34d0afae5bfb08338f7c439914\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/950a3ab7-5826-40b1-8a47-a89aa6ba0363 HTTP/11\" 404 26\n",
            "WARNING:__main__:Error checking run status: Resource not found for /runs/950a3ab7-5826-40b1-8a47-a89aa6ba0363. HTTPError('404 Client Error: Not Found for url: https://api.smith.langchain.com/runs/950a3ab7-5826-40b1-8a47-a89aa6ba0363', '{\"detail\":\"Run not found\"}')\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/950a3ab7-5826-40b1-8a47-a89aa6ba0363 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 202 1820\n",
            "INFO:__main__:Completed evaluation for run 950a3ab7-5826-40b1-8a47-a89aa6ba0363\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 791\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 568385c2-ea42-4983-9173-c2d1601293bf\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x14a93d620>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'18'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_86efad260548b9d815949fa4b7d4114a'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd75254794942a6-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '18', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_86efad260548b9d815949fa4b7d4114a', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd75254794942a6-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_86efad260548b9d815949fa4b7d4114a\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/568385c2-ea42-4983-9173-c2d1601293bf HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/568385c2-ea42-4983-9173-c2d1601293bf HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run 568385c2-ea42-4983-9173-c2d1601293bf\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 568385c2-ea42-4983-9173-c2d1601293bf\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174b868e0>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x322139690>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x174ccad90>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'25'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_a4df02ccdce15ca452fe26f3ae89bc08'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd7528cefae429b-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '25', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_a4df02ccdce15ca452fe26f3ae89bc08', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd7528cefae429b-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_a4df02ccdce15ca452fe26f3ae89bc08\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/568385c2-ea42-4983-9173-c2d1601293bf HTTP/11\" 200 2743\n",
            "INFO:__main__:Run 568385c2-ea42-4983-9173-c2d1601293bf has already been completed. Skipping update.\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: d3ae31e6-c5f3-423f-a081-da988bf98df1\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322202b60>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:21 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'20'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_103857fbd07e18a05633ed64df4f2f00'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd752a0fbda429b-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:21 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '20', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_103857fbd07e18a05633ed64df4f2f00', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd752a0fbda429b-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_103857fbd07e18a05633ed64df4f2f00\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/d3ae31e6-c5f3-423f-a081-da988bf98df1 HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/d3ae31e6-c5f3-423f-a081-da988bf98df1 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run d3ae31e6-c5f3-423f-a081-da988bf98df1\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 7a3caff0-aa74-4df7-a98e-071663eb09fa\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174ca51c0>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:25 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_2e2bd13e0db57334ec2f906a06bcad68'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd752bb1d06429b-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:25 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '21', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_2e2bd13e0db57334ec2f906a06bcad68', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd752bb1d06429b-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_2e2bd13e0db57334ec2f906a06bcad68\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/7a3caff0-aa74-4df7-a98e-071663eb09fa HTTP/11\" 404 26\n",
            "WARNING:__main__:Error checking run status: Resource not found for /runs/7a3caff0-aa74-4df7-a98e-071663eb09fa. HTTPError('404 Client Error: Not Found for url: https://api.smith.langchain.com/runs/7a3caff0-aa74-4df7-a98e-071663eb09fa', '{\"detail\":\"Run not found\"}')\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/7a3caff0-aa74-4df7-a98e-071663eb09fa HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 202 1797\n",
            "INFO:__main__:Completed evaluation for run 7a3caff0-aa74-4df7-a98e-071663eb09fa\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: ae7e8405-a912-4f8f-b755-4927b9db4216\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174b868e0>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:29 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'28'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_7d2c5c33a6e0143d440c4dddcc2942bb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd752d01913429b-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:29 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '28', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_7d2c5c33a6e0143d440c4dddcc2942bb', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd752d01913429b-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_7d2c5c33a6e0143d440c4dddcc2942bb\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/ae7e8405-a912-4f8f-b755-4927b9db4216 HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/ae7e8405-a912-4f8f-b755-4927b9db4216 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run ae7e8405-a912-4f8f-b755-4927b9db4216\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 791\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 242a9c62-cb14-445f-855b-5594481273fe\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174b868e0>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x322232910>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x174a971d0>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'23'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_3866f1ff82fd341d9a8bf0527ec8d21e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd752f2786f43cb-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:34 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '23', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_3866f1ff82fd341d9a8bf0527ec8d21e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd752f2786f43cb-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_3866f1ff82fd341d9a8bf0527ec8d21e\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/242a9c62-cb14-445f-855b-5594481273fe HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/242a9c62-cb14-445f-855b-5594481273fe HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run 242a9c62-cb14-445f-855b-5594481273fe\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 791\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 97e9210d-049a-41b3-88f9-12b249abf6dd\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174b868e0>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'20'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_0ef994af41a10a788170dfea67030c77'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd7530dae4e43cb-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '20', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_0ef994af41a10a788170dfea67030c77', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd7530dae4e43cb-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_0ef994af41a10a788170dfea67030c77\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/97e9210d-049a-41b3-88f9-12b249abf6dd HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/97e9210d-049a-41b3-88f9-12b249abf6dd HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run 97e9210d-049a-41b3-88f9-12b249abf6dd\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 792\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: ad4df582-c8ca-48ae-b9f2-9677a02f61e4\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174ca51c0>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:42 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'23'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_14d4a875af66b06f9b38f81fdf095ff0'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd75326dbd843cb-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:42 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '23', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_14d4a875af66b06f9b38f81fdf095ff0', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd75326dbd843cb-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_14d4a875af66b06f9b38f81fdf095ff0\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/ad4df582-c8ca-48ae-b9f2-9677a02f61e4 HTTP/11\" 404 26\n",
            "WARNING:__main__:Error checking run status: Resource not found for /runs/ad4df582-c8ca-48ae-b9f2-9677a02f61e4. HTTPError('404 Client Error: Not Found for url: https://api.smith.langchain.com/runs/ad4df582-c8ca-48ae-b9f2-9677a02f61e4', '{\"detail\":\"Run not found\"}')\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/ad4df582-c8ca-48ae-b9f2-9677a02f61e4 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run ad4df582-c8ca-48ae-b9f2-9677a02f61e4\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 792\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: c1ffea25-3dd1-4778-b31e-a63044b219f3\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221dac00>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:47 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'23'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_88f3448a832d8d25e191d477787e790d'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd75342dfb643cb-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:47 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '23', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_88f3448a832d8d25e191d477787e790d', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd75342dfb643cb-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_88f3448a832d8d25e191d477787e790d\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/c1ffea25-3dd1-4778-b31e-a63044b219f3 HTTP/11\" 404 26\n",
            "WARNING:__main__:Error checking run status: Resource not found for /runs/c1ffea25-3dd1-4778-b31e-a63044b219f3. HTTPError('404 Client Error: Not Found for url: https://api.smith.langchain.com/runs/c1ffea25-3dd1-4778-b31e-a63044b219f3', '{\"detail\":\"Run not found\"}')\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/c1ffea25-3dd1-4778-b31e-a63044b219f3 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 202 1820\n",
            "INFO:__main__:Completed evaluation for run c1ffea25-3dd1-4778-b31e-a63044b219f3\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: b1ccb462-b230-44d6-8ce2-481585030ac8\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174ca51c0>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:50 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_1d0ac31e43ffbf51b3c6604b07fd8dc2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd75356089143cb-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:50 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '21', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_1d0ac31e43ffbf51b3c6604b07fd8dc2', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd75356089143cb-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_1d0ac31e43ffbf51b3c6604b07fd8dc2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/b1ccb462-b230-44d6-8ce2-481585030ac8 HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/b1ccb462-b230-44d6-8ce2-481585030ac8 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run b1ccb462-b230-44d6-8ce2-481585030ac8\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 3e3716d2-eb11-43b6-a810-98dd9216dfda\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174b868e0>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:44:55 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_6f0bcd9d75a05147e2c620a94c62f1e3'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd75377ede743cb-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:44:55 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '21', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_6f0bcd9d75a05147e2c620a94c62f1e3', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd75377ede743cb-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_6f0bcd9d75a05147e2c620a94c62f1e3\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/3e3716d2-eb11-43b6-a810-98dd9216dfda HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/3e3716d2-eb11-43b6-a810-98dd9216dfda HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run 3e3716d2-eb11-43b6-a810-98dd9216dfda\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 792\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 05a82945-6302-45c4-b6e4-8179b08306be\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174ca51c0>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:00 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'25'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_5f2e76cb810f414922e03d56a915a364'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd753930a1f43cb-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:00 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '25', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_5f2e76cb810f414922e03d56a915a364', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd753930a1f43cb-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_5f2e76cb810f414922e03d56a915a364\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/05a82945-6302-45c4-b6e4-8179b08306be HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/05a82945-6302-45c4-b6e4-8179b08306be HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run 05a82945-6302-45c4-b6e4-8179b08306be\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 21563347-7fb4-4171-9cf7-0ab6483fd0a0\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322203100>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:03 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'22'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_ed2956892529f516d31c0c923ed13301'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd753ab2abb43cb-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:03 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '22', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_ed2956892529f516d31c0c923ed13301', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd753ab2abb43cb-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_ed2956892529f516d31c0c923ed13301\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/21563347-7fb4-4171-9cf7-0ab6483fd0a0 HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/21563347-7fb4-4171-9cf7-0ab6483fd0a0 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run 21563347-7fb4-4171-9cf7-0ab6483fd0a0\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 791\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 84e23f6b-7e13-4fe2-8510-5c1c2c4211ef\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322203100>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x173aa2150>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x173cbd410>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:09 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'679'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_8f669e7fe7f342110e1030a8f6fab70c'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd753cbfd4a1a03-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:09 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '679', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_8f669e7fe7f342110e1030a8f6fab70c', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd753cbfd4a1a03-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_8f669e7fe7f342110e1030a8f6fab70c\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/84e23f6b-7e13-4fe2-8510-5c1c2c4211ef HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/84e23f6b-7e13-4fe2-8510-5c1c2c4211ef HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run 84e23f6b-7e13-4fe2-8510-5c1c2c4211ef\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 3017da9a-f19c-480f-80f1-6623a2ac914e\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221da980>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:14 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'48'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_5f1d315ffb0c75f19bd356338c44fdd9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd753ec0d841a03-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:14 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '48', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_5f1d315ffb0c75f19bd356338c44fdd9', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd753ec0d841a03-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_5f1d315ffb0c75f19bd356338c44fdd9\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/3017da9a-f19c-480f-80f1-6623a2ac914e HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/3017da9a-f19c-480f-80f1-6623a2ac914e HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run 3017da9a-f19c-480f-80f1-6623a2ac914e\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 792\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 3017da9a-f19c-480f-80f1-6623a2ac914e\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322203100>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x174caedd0>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x177d8f990>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:20 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'45'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_964c02a4fea805205a738765f5b926eb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd754100df4433f-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:20 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '45', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_964c02a4fea805205a738765f5b926eb', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd754100df4433f-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_964c02a4fea805205a738765f5b926eb\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/3017da9a-f19c-480f-80f1-6623a2ac914e HTTP/11\" 200 5925\n",
            "INFO:__main__:Run 3017da9a-f19c-480f-80f1-6623a2ac914e has already been completed. Skipping update.\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 792\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: eddc953c-718f-4f37-8366-9c588934129b\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174b868e0>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:24 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'23'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_bcecc63285830d75c9e31d2344b1bda2'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd7542b0cdc433f-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:24 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '23', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_bcecc63285830d75c9e31d2344b1bda2', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd7542b0cdc433f-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_bcecc63285830d75c9e31d2344b1bda2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/eddc953c-718f-4f37-8366-9c588934129b HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/eddc953c-718f-4f37-8366-9c588934129b HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run eddc953c-718f-4f37-8366-9c588934129b\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 792\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 6404a319-4fa8-4368-a8e2-c595d246c3c4\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221db420>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x174a96f90>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x3221471d0>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'18'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_8251c6febd2179ed7d2881053e93bcee'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd754508bc715bb-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '18', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_8251c6febd2179ed7d2881053e93bcee', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd754508bc715bb-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_8251c6febd2179ed7d2881053e93bcee\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/6404a319-4fa8-4368-a8e2-c595d246c3c4 HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/6404a319-4fa8-4368-a8e2-c595d246c3c4 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run 6404a319-4fa8-4368-a8e2-c595d246c3c4\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: ed5861e3-5bf4-46d9-875a-35cb509bf21d\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221db100>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:35 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'41'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_ed35b983d4e408ccfed5babb0ef6dc09'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd7546c3ee515bb-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:35 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '41', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_ed35b983d4e408ccfed5babb0ef6dc09', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd7546c3ee515bb-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_ed35b983d4e408ccfed5babb0ef6dc09\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/ed5861e3-5bf4-46d9-875a-35cb509bf21d HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/ed5861e3-5bf4-46d9-875a-35cb509bf21d HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run ed5861e3-5bf4-46d9-875a-35cb509bf21d\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 792\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 10c15eed-fe50-4850-a10c-dfbf4a8052ba\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322293ce0>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:39 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'20'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_c04cbe68e18a3719f9ae792f7b687f29'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd75488bb0f15bb-EWR'), (b'Content-Encoding', b'br'), (b'alt-svc', b'h3=\":443\"; ma=86400')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:39 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '20', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_c04cbe68e18a3719f9ae792f7b687f29', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd75488bb0f15bb-EWR', 'content-encoding': 'br', 'alt-svc': 'h3=\":443\"; ma=86400'})\n",
            "DEBUG:openai._base_client:request_id: req_c04cbe68e18a3719f9ae792f7b687f29\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/10c15eed-fe50-4850-a10c-dfbf4a8052ba HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/10c15eed-fe50-4850-a10c-dfbf4a8052ba HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run 10c15eed-fe50-4850-a10c-dfbf4a8052ba\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: aaa814c1-a434-4d83-a9b1-a483905a1bb6\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221db560>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x174a0c590>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x3222979d0>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:44 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_64f31f713bb25e0baeb8fe02e4fd12bd'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd754a9e8d943a7-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:44 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '21', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_64f31f713bb25e0baeb8fe02e4fd12bd', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd754a9e8d943a7-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_64f31f713bb25e0baeb8fe02e4fd12bd\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/aaa814c1-a434-4d83-a9b1-a483905a1bb6 HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/aaa814c1-a434-4d83-a9b1-a483905a1bb6 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run aaa814c1-a434-4d83-a9b1-a483905a1bb6\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 43745932-a368-467e-a3a2-bcc74c409841\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322202f20>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:49 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'20'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_35a1d4edeb5717378f40f7ec1a6d99f6'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd754c5af7e43a7-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:49 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '20', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_35a1d4edeb5717378f40f7ec1a6d99f6', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd754c5af7e43a7-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_35a1d4edeb5717378f40f7ec1a6d99f6\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/43745932-a368-467e-a3a2-bcc74c409841 HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/43745932-a368-467e-a3a2-bcc74c409841 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run 43745932-a368-467e-a3a2-bcc74c409841\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 8595bda3-4a84-4c48-bdc7-bf66670fa79b\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221d9e40>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:53 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_bb0f62a64d49d04c51d6b4a16f3a2020'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd754dfedbc43a7-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:53 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '21', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_bb0f62a64d49d04c51d6b4a16f3a2020', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd754dfedbc43a7-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_bb0f62a64d49d04c51d6b4a16f3a2020\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/8595bda3-4a84-4c48-bdc7-bf66670fa79b HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/8595bda3-4a84-4c48-bdc7-bf66670fa79b HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run 8595bda3-4a84-4c48-bdc7-bf66670fa79b\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 0068815f-8f9c-4d37-88ae-e96f141701da\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x177df6160>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:45:57 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'21'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_8e4b5706b86b38aee599deea2f0dd75e'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd754f7aee743a7-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:45:57 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '21', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_8e4b5706b86b38aee599deea2f0dd75e', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd754f7aee743a7-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_8e4b5706b86b38aee599deea2f0dd75e\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/0068815f-8f9c-4d37-88ae-e96f141701da HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/0068815f-8f9c-4d37-88ae-e96f141701da HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run 0068815f-8f9c-4d37-88ae-e96f141701da\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: f0797b70-8a1d-4236-ba35-a078f5b34ddc\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322203100>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:46:01 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'45'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_1d76713be3527d590f6cb8b7c2a7c531'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd7550fbf3743a7-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:46:01 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '45', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_1d76713be3527d590f6cb8b7c2a7c531', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd7550fbf3743a7-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_1d76713be3527d590f6cb8b7c2a7c531\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/f0797b70-8a1d-4236-ba35-a078f5b34ddc HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/f0797b70-8a1d-4236-ba35-a078f5b34ddc HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run f0797b70-8a1d-4236-ba35-a078f5b34ddc\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 858584a0-97bf-4cfb-8113-df6b847c716a\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x174b868e0>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:46:05 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'18'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_8da30725869f01660e7628e785fed678'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd7552e9bd543a7-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:46:05 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '18', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_8da30725869f01660e7628e785fed678', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd7552e9bd543a7-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_8da30725869f01660e7628e785fed678\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/858584a0-97bf-4cfb-8113-df6b847c716a HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/858584a0-97bf-4cfb-8113-df6b847c716a HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run 858584a0-97bf-4cfb-8113-df6b847c716a\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: ff1728f8-7b85-4c29-b09c-fac865d410c3\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x322293560>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:46:10 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'19'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_e2a150302345b0b78f76ce1ca10ac439'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd75549d9de43a7-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:46:10 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '19', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_e2a150302345b0b78f76ce1ca10ac439', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd75549d9de43a7-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_e2a150302345b0b78f76ce1ca10ac439\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/ff1728f8-7b85-4c29-b09c-fac865d410c3 HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/ff1728f8-7b85-4c29-b09c-fac865d410c3 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run ff1728f8-7b85-4c29-b09c-fac865d410c3\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 86f41c1b-f7ac-4bf9-b546-055929bdb3b9\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221db7e0>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x173876950>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x322254150>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:46:18 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'22'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_a3a0a401d31dc4df75285278ec7bc9de'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd7557cf94717bd-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:46:18 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '22', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_a3a0a401d31dc4df75285278ec7bc9de', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd7557cf94717bd-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_a3a0a401d31dc4df75285278ec7bc9de\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/86f41c1b-f7ac-4bf9-b546-055929bdb3b9 HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/86f41c1b-f7ac-4bf9-b546-055929bdb3b9 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run 86f41c1b-f7ac-4bf9-b546-055929bdb3b9\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 5aca01a9-c384-4294-90d8-b72dd29a94b1\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221d9e40>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x3221574d0>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x32223dfd0>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:46:23 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'22'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_7d5faab9fc01941786e1fba1b6a24aab'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd7559df97141ec-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:46:23 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '22', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_7d5faab9fc01941786e1fba1b6a24aab', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd7559df97141ec-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_7d5faab9fc01941786e1fba1b6a24aab\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/5aca01a9-c384-4294-90d8-b72dd29a94b1 HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/5aca01a9-c384-4294-90d8-b72dd29a94b1 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run 5aca01a9-c384-4294-90d8-b72dd29a94b1\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 793\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 5aca01a9-c384-4294-90d8-b72dd29a94b1\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221daca0>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x177dc9690>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x17349aa90>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:46:30 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'94'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_b96c81cb757c63f4b46dbad2be57d0cb'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd755c5cd4842be-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:46:30 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '94', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_b96c81cb757c63f4b46dbad2be57d0cb', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd755c5cd4842be-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_b96c81cb757c63f4b46dbad2be57d0cb\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/5aca01a9-c384-4294-90d8-b72dd29a94b1 HTTP/11\" 200 2840\n",
            "INFO:__main__:Run 5aca01a9-c384-4294-90d8-b72dd29a94b1 has already been completed. Skipping update.\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: d29a5b3d-76e4-48aa-b312-5d2c9cc21c6c\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x177df7ba0>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:46:34 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'22'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_b5342a53903b4eab4bf45d316539d817'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd755e0695742be-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:46:34 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '22', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_b5342a53903b4eab4bf45d316539d817', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd755e0695742be-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_b5342a53903b4eab4bf45d316539d817\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/d29a5b3d-76e4-48aa-b312-5d2c9cc21c6c HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/d29a5b3d-76e4-48aa-b312-5d2c9cc21c6c HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run d29a5b3d-76e4-48aa-b312-5d2c9cc21c6c\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: ab598092-495f-48ad-b304-43f7de04c7d8\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x177df7ba0>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:46:38 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'20'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_b255182c6919fdac1f898041943363c1'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd755fb9a7042be-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:46:38 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '20', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_b255182c6919fdac1f898041943363c1', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd755fb9a7042be-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_b255182c6919fdac1f898041943363c1\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/ab598092-495f-48ad-b304-43f7de04c7d8 HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/ab598092-495f-48ad-b304-43f7de04c7d8 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run ab598092-495f-48ad-b304-43f7de04c7d8\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: ff378e64-55c4-4180-aa03-c4f76df0e2d3\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x177df7ba0>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:46:43 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'590'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_04f39a1082fd1ad8d98a0e55900b0881'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd756163a5442be-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:46:43 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '590', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_04f39a1082fd1ad8d98a0e55900b0881', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd756163a5442be-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_04f39a1082fd1ad8d98a0e55900b0881\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/ff378e64-55c4-4180-aa03-c4f76df0e2d3 HTTP/11\" 200 1718\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/ff378e64-55c4-4180-aa03-c4f76df0e2d3 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run ff378e64-55c4-4180-aa03-c4f76df0e2d3\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: d6c5c503-5024-4d2f-8c8e-d237ecd2ad56\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221dbb00>, 'json_data': {'input': [[3923, 527, 279, 1401, 13650, 14407, 304, 420, 2246, 30]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:46:48 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'19'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999989'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_cfcef423f7a0fe20e817fb5244072e98'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd756358c4a42be-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:46:48 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '19', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999989', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_cfcef423f7a0fe20e817fb5244072e98', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd756358c4a42be-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_cfcef423f7a0fe20e817fb5244072e98\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/d6c5c503-5024-4d2f-8c8e-d237ecd2ad56 HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/d6c5c503-5024-4d2f-8c8e-d237ecd2ad56 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1797\n",
            "INFO:__main__:Completed evaluation for run d6c5c503-5024-4d2f-8c8e-d237ecd2ad56\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 795\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 991f92b1-72e5-4eec-a23e-ff6672b8a3af\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221dbb00>, 'json_data': {'input': [[9370, 5730, 553, 279, 1925, 3585, 315, 279, 2246, 13]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:46:52 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'24'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999990'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_2cd2c6d482a1b1730264d2fef247bb85'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd756514e3d42be-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:46:52 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '24', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999990', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_2cd2c6d482a1b1730264d2fef247bb85', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd756514e3d42be-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_2cd2c6d482a1b1730264d2fef247bb85\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/991f92b1-72e5-4eec-a23e-ff6672b8a3af HTTP/11\" 200 1688\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/991f92b1-72e5-4eec-a23e-ff6672b8a3af HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1361\n",
            "INFO:__main__:Completed evaluation for run 991f92b1-72e5-4eec-a23e-ff6672b8a3af\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs HTTP/11\" 202 25\n",
            "INFO:__main__:Run created, but returned None. Attempting to fetch...\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "INFO:__main__:Retrieved run with ID: 0ae0a575-8541-4f2e-ab84-207cf5153bd8\n",
            "DEBUG:openai._base_client:Request options: {'method': 'post', 'url': '/embeddings', 'files': None, 'post_parser': <function Embeddings.create.<locals>.parser at 0x3221db880>, 'json_data': {'input': [[8144, 220, 1135, 2574, 922, 420, 2246, 0]], 'model': 'text-embedding-3-small', 'encoding_format': 'base64'}}\n",
            "DEBUG:openai._base_client:Sending HTTP Request: POST https://api.openai.com/v1/embeddings\n",
            "DEBUG:httpcore.connection:close.started\n",
            "DEBUG:httpcore.connection:close.complete\n",
            "DEBUG:httpcore.connection:connect_tcp.started host='api.openai.com' port=443 local_address=None timeout=None socket_options=None\n",
            "DEBUG:httpcore.connection:connect_tcp.complete return_value=<httpcore._backends.sync.SyncStream object at 0x322169650>\n",
            "DEBUG:httpcore.connection:start_tls.started ssl_context=<ssl.SSLContext object at 0x12ff43890> server_hostname='api.openai.com' timeout=None\n",
            "DEBUG:httpcore.connection:start_tls.complete return_value=<httpcore._backends.sync.SyncStream object at 0x32216b150>\n",
            "DEBUG:httpcore.http11:send_request_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_headers.complete\n",
            "DEBUG:httpcore.http11:send_request_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:send_request_body.complete\n",
            "DEBUG:httpcore.http11:receive_response_headers.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_headers.complete return_value=(b'HTTP/1.1', 200, b'OK', [(b'Date', b'Fri, 04 Oct 2024 18:46:58 GMT'), (b'Content-Type', b'application/json'), (b'Transfer-Encoding', b'chunked'), (b'Connection', b'keep-alive'), (b'access-control-allow-origin', b'*'), (b'access-control-expose-headers', b'X-Request-ID'), (b'openai-model', b'text-embedding-3-small'), (b'openai-organization', b'user-qefqoupq9vya90czttuk8u5e'), (b'openai-processing-ms', b'20'), (b'openai-version', b'2020-10-01'), (b'strict-transport-security', b'max-age=31536000; includeSubDomains; preload'), (b'x-ratelimit-limit-requests', b'5000'), (b'x-ratelimit-limit-tokens', b'5000000'), (b'x-ratelimit-remaining-requests', b'4999'), (b'x-ratelimit-remaining-tokens', b'4999992'), (b'x-ratelimit-reset-requests', b'12ms'), (b'x-ratelimit-reset-tokens', b'0s'), (b'x-request-id', b'req_616b0cb2d30f1fa3ee72728385cfc7e9'), (b'CF-Cache-Status', b'DYNAMIC'), (b'X-Content-Type-Options', b'nosniff'), (b'Server', b'cloudflare'), (b'CF-RAY', b'8cd75675df848c4d-EWR'), (b'Content-Encoding', b'br')])\n",
            "INFO:httpx:HTTP Request: POST https://api.openai.com/v1/embeddings \"HTTP/1.1 200 OK\"\n",
            "DEBUG:httpcore.http11:receive_response_body.started request=<Request [b'POST']>\n",
            "DEBUG:httpcore.http11:receive_response_body.complete\n",
            "DEBUG:httpcore.http11:response_closed.started\n",
            "DEBUG:httpcore.http11:response_closed.complete\n",
            "DEBUG:openai._base_client:HTTP Response: POST https://api.openai.com/v1/embeddings \"200 OK\" Headers({'date': 'Fri, 04 Oct 2024 18:46:58 GMT', 'content-type': 'application/json', 'transfer-encoding': 'chunked', 'connection': 'keep-alive', 'access-control-allow-origin': '*', 'access-control-expose-headers': 'X-Request-ID', 'openai-model': 'text-embedding-3-small', 'openai-organization': 'user-qefqoupq9vya90czttuk8u5e', 'openai-processing-ms': '20', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=31536000; includeSubDomains; preload', 'x-ratelimit-limit-requests': '5000', 'x-ratelimit-limit-tokens': '5000000', 'x-ratelimit-remaining-requests': '4999', 'x-ratelimit-remaining-tokens': '4999992', 'x-ratelimit-reset-requests': '12ms', 'x-ratelimit-reset-tokens': '0s', 'x-request-id': 'req_616b0cb2d30f1fa3ee72728385cfc7e9', 'cf-cache-status': 'DYNAMIC', 'x-content-type-options': 'nosniff', 'server': 'cloudflare', 'cf-ray': '8cd75675df848c4d-EWR', 'content-encoding': 'br'})\n",
            "DEBUG:openai._base_client:request_id: req_616b0cb2d30f1fa3ee72728385cfc7e9\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /runs/0ae0a575-8541-4f2e-ab84-207cf5153bd8 HTTP/11\" 200 1700\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"PATCH /runs/0ae0a575-8541-4f2e-ab84-207cf5153bd8 HTTP/11\" 202 25\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /feedback HTTP/11\" 200 1820\n",
            "INFO:__main__:Completed evaluation for run 0ae0a575-8541-4f2e-ab84-207cf5153bd8\n"
          ]
        }
      ],
      "source": [
        "logging.basicConfig(level=logging.DEBUG)\n",
        "logger = logging.getLogger(__name__)\n",
        "\n",
        "client = Client()\n",
        "\n",
        "@retry(stop=stop_after_attempt(3), wait=wait_fixed(2))\n",
        "def create_and_get_run(project_name, inputs):\n",
        "    try:\n",
        "        run = client.create_run(\n",
        "            project_name=project_name,\n",
        "            name=\"QA Evaluation\",\n",
        "            run_type=\"chain\",\n",
        "            inputs=inputs\n",
        "        )\n",
        "        if run is None:\n",
        "            logger.info(\"Run created, but returned None. Attempting to fetch...\")\n",
        "            time.sleep(1)  # Wait a bit before trying to fetch\n",
        "            runs = list(client.list_runs(project_name=project_name, limit=1))\n",
        "            if runs:\n",
        "                run = runs[0]\n",
        "                logger.info(f\"Retrieved run with ID: {run.id}\")\n",
        "            else:\n",
        "                raise Exception(\"Failed to retrieve the created run\")\n",
        "        return run\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error in run creation/retrieval: {e}\", exc_info=True)\n",
        "        raise\n",
        "\n",
        "def setup_evaluators():\n",
        "    eval_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "    \n",
        "    criteria = {\n",
        "        \"relevance\": \"The response should be highly relevant to the question asked.\",\n",
        "        \"completeness\": \"The response should fully address all aspects of the question.\",\n",
        "        \"accuracy\": \"The information provided in the response should be accurate and factual.\",\n",
        "        \"clarity\": \"The response should be clear, well-structured, and easy to understand.\"\n",
        "    }\n",
        "    \n",
        "    criteria_evaluator = CriteriaEvalChain.from_llm(\n",
        "        llm=eval_llm,\n",
        "        criteria=criteria\n",
        "    )\n",
        "    \n",
        "    eval_config = RunEvalConfig(\n",
        "        evaluators=[criteria_evaluator],\n",
        "        custom_evaluators=[],\n",
        "    )\n",
        "    \n",
        "    return eval_config\n",
        "\n",
        "from datetime import datetime, timezone\n",
        "\n",
        "def process_example(project_name, example, cached_chain, eval_config):\n",
        "    run = create_and_get_run(project_name, example.inputs)\n",
        "    if run is None:\n",
        "        logger.warning(f\"Failed to create or retrieve run for input: {example.inputs}\")\n",
        "        return\n",
        "\n",
        "    try:\n",
        "        # Execute the chain\n",
        "        result = cached_chain.invoke(example.inputs)\n",
        "        \n",
        "        # Check if the run still exists and hasn't been completed\n",
        "        try:\n",
        "            existing_run = client.read_run(run.id)\n",
        "            if existing_run.end_time:\n",
        "                logger.info(f\"Run {run.id} has already been completed. Skipping update.\")\n",
        "                return\n",
        "        except Exception as e:\n",
        "            logger.warning(f\"Error checking run status: {e}\")\n",
        "            # If we can't check the status, we'll attempt to update anyway\n",
        "\n",
        "        # Update the run with the result\n",
        "        client.update_run(\n",
        "            run.id,\n",
        "            outputs=result,\n",
        "            end_time=datetime.now(timezone.utc),\n",
        "        )\n",
        "        \n",
        "        # Run evaluators\n",
        "        for evaluator in eval_config.evaluators:\n",
        "            if isinstance(evaluator, StringEvaluator):\n",
        "                eval_result = evaluator.evaluate_strings(\n",
        "                    prediction=result['text'] if isinstance(result, dict) else str(result),\n",
        "                    input=example.inputs[\"question\"],\n",
        "                )\n",
        "                client.create_feedback(\n",
        "                    run.id,\n",
        "                    evaluator.__class__.__name__,\n",
        "                    score=eval_result.get(\"score\"),\n",
        "                    comment=eval_result.get(\"reasoning\"),\n",
        "                )\n",
        "        \n",
        "        logger.info(f\"Completed evaluation for run {run.id}\")\n",
        "    except Exception as e:\n",
        "        logger.error(f\"Error processing run {run.id}: {e}\", exc_info=True)\n",
        "        try:\n",
        "            client.update_run(\n",
        "                run.id,\n",
        "                error=str(e),\n",
        "                end_time=datetime.now(timezone.utc),\n",
        "            )\n",
        "        except Exception as update_error:\n",
        "            logger.error(f\"Failed to update run {run.id} with error: {update_error}\", exc_info=True)\n",
        "\n",
        "def process_examples_in_batches(project_name, examples, cached_chain, eval_config, batch_size=5):\n",
        "    for i in range(0, len(examples), batch_size):\n",
        "        batch = examples[i:i+batch_size]\n",
        "        for example in batch:\n",
        "            process_example(project_name, example, cached_chain, eval_config)\n",
        "        time.sleep(1)  # Add a small delay between batches\n",
        "\n",
        "def main():\n",
        "    project_name = \"Test_Project_20241004_080054_535737\"  # Your project name\n",
        "    dataset_name = \"qa_eval_dataset\"  # Your dataset name\n",
        "    \n",
        "    examples = list(client.list_examples(dataset_name=dataset_name))\n",
        "    logger.info(f\"Processing {len(examples)} examples\")\n",
        "    \n",
        "    eval_config = setup_evaluators()\n",
        "    \n",
        "    # Assuming cached_chain is your existing chain\n",
        "    # If not, you'll need to set it up here\n",
        "    \n",
        "    process_examples_in_batches(project_name, examples, cached_chain, eval_config)\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 63,
      "metadata": {},
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): api.smith.langchain.com:443\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (2): api.smith.langchain.com:443\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /info HTTP/11\" 200 485\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /sessions?limit=1&name=Test_Project_20241004_080054_535737&include_stats=False HTTP/11\" 200 794\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=43e683f9-5767-4d69-8de6-8949dac127a2&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=0ae0a575-8541-4f2e-ab84-207cf5153bd8&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=3397a4c6-4607-4abb-9447-4b47f60f050d&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=991f92b1-72e5-4eec-a23e-ff6672b8a3af&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=d6c5c503-5024-4d2f-8c8e-d237ecd2ad56&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ff378e64-55c4-4180-aa03-c4f76df0e2d3&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ab598092-495f-48ad-b304-43f7de04c7d8&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=d29a5b3d-76e4-48aa-b312-5d2c9cc21c6c&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=5aca01a9-c384-4294-90d8-b72dd29a94b1&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=86f41c1b-f7ac-4bf9-b546-055929bdb3b9&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ff1728f8-7b85-4c29-b09c-fac865d410c3&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=858584a0-97bf-4cfb-8113-df6b847c716a&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=f0797b70-8a1d-4236-ba35-a078f5b34ddc&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=0068815f-8f9c-4d37-88ae-e96f141701da&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=8595bda3-4a84-4c48-bdc7-bf66670fa79b&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=43745932-a368-467e-a3a2-bcc74c409841&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=aaa814c1-a434-4d83-a9b1-a483905a1bb6&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=10c15eed-fe50-4850-a10c-dfbf4a8052ba&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ed5861e3-5bf4-46d9-875a-35cb509bf21d&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=6404a319-4fa8-4368-a8e2-c595d246c3c4&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=eddc953c-718f-4f37-8366-9c588934129b&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=3017da9a-f19c-480f-80f1-6623a2ac914e&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=84e23f6b-7e13-4fe2-8510-5c1c2c4211ef&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=21563347-7fb4-4171-9cf7-0ab6483fd0a0&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=05a82945-6302-45c4-b6e4-8179b08306be&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=3e3716d2-eb11-43b6-a810-98dd9216dfda&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=b1ccb462-b230-44d6-8ce2-481585030ac8&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=c1ffea25-3dd1-4778-b31e-a63044b219f3&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ad4df582-c8ca-48ae-b9f2-9677a02f61e4&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=97e9210d-049a-41b3-88f9-12b249abf6dd&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=242a9c62-cb14-445f-855b-5594481273fe&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ae7e8405-a912-4f8f-b755-4927b9db4216&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=7a3caff0-aa74-4df7-a98e-071663eb09fa&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=d3ae31e6-c5f3-423f-a081-da988bf98df1&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=2769fff4-b84f-47ba-9b85-8db27a6bfc91&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=568385c2-ea42-4983-9173-c2d1601293bf&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=950a3ab7-5826-40b1-8a47-a89aa6ba0363&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=c1797fac-e660-4e11-8392-6da89f649a14&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=28a6c51e-6858-4015-90d9-df96ca4bd2e0&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=b7ce2a55-abe6-4518-b7db-4ee71bcc7f87&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=5a36bd17-56d0-428a-81a1-c0b6df8a217c&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=e2a78380-bb02-4d8c-9bb1-40f1848e7787&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=2b2a3f15-939f-4a6c-b862-7fd36e1f2566&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1e16fee0-98dd-431d-8bce-19d85cf21d6c&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1346f35c-0e80-4781-9c3e-9845493ca363&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=63430948-b052-4039-a04f-e2cf2875adba&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ed58dd89-1159-4aeb-b8ef-56b0c90f41da&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=5bc25e40-2cdc-4dd3-b49e-e0c57e8e195d&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=b10ed506-c739-4968-8322-7f2300522769&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=f2223ad9-f973-4c23-b8a7-3f2392bc1f43&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=271d6ec0-433c-476d-8eaf-75352f82f7ce&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=d6c895be-5f8f-468a-8c66-a4e07abe42d9&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=5ae495dc-12df-40f7-b148-55b178937639&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=6114b564-32b5-45cf-987e-0d72d5a22c98&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=b6ff8345-b692-41af-ac1a-396b5ff4029b&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1564ecf5-5a4c-4d98-84f2-188525718675&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=3b77d841-a26c-49cf-8465-2a3e4d799599&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=8e7f364d-b325-4fa0-ab4e-8cd790b43a15&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=fb0ba507-65e8-43bd-a714-f5f38c56da8e&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=5e0cb001-f6c6-4dfc-b234-361f6d28f5ea&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=285f5953-c3bf-4c13-9167-bf70bf578c8d&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=b506f7e9-3f16-4f28-b72d-143dab7407f7&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=9873db3c-3951-4404-86f8-6a26ecbd7a9f&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=911f1564-f484-4c7b-a9aa-a5fbfd83da51&limit=100&offset=0 HTTP/11\" 200 1880\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=cd91893e-9bed-4e60-9d1d-a1692b754978&limit=100&offset=0 HTTP/11\" 200 1421\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ca0345be-1b15-4724-81f3-c923fc877d44&limit=100&offset=0 HTTP/11\" 200 1857\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=99e3a5fa-5ef2-42d9-97a9-08a26763fad3&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=e34996e9-4aef-45d4-9360-9f4bb93350f5&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=2632dbb1-d3fe-45ea-aa81-ed9c9131f9ec&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=e42ea13b-3fe0-4ea2-bc08-beafe44ae1d3&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=f7ed97b9-fdd4-4ec2-a456-8ca307d4df62&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=9626a2f0-50af-4f7b-afa3-20a578796797&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=997c4afb-93b9-469c-8fea-95de2891bcb8&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=23f8c067-1be9-45f5-bc82-1f665e9d046c&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=a93fb583-0710-4122-a14c-66823476072d&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=f09c3827-71a4-4bfe-912b-84d1cae81cf5&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=8a2701b2-4a5f-4434-8df0-3a56593a6f1d&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=3c445070-0e63-4d67-a517-1db1a73f260e&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=567ac02a-61c1-4279-ab59-c9931871fede&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=02f03621-a06c-4e23-8738-54fc48ab0b7b&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=be1f6830-188e-4586-9621-0ab981c4d096&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1ee1372f-242d-461a-aeff-5d31ac8dda90&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=577746c8-73bb-47fb-a16b-59e0613ac6ea&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=e6262053-2b5c-4057-8807-b123f4dcaaf3&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=88c98923-a052-40ef-a1cf-503c0879ff84&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=75285122-9f2c-4bd6-a0e6-e48c21e7cc87&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=c7e0d094-67b8-4790-b685-3d9d6f7efc9b&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=097de594-740d-4a18-851a-b887a84ffd14&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=eca848ef-bd94-49d1-959e-bce56fda4967&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1afc7101-5215-4147-9400-7e4dddb3c10a&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=d1c64eba-02f1-4694-baba-322584ca4ca9&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=c170e871-6a41-408b-b5fa-72e2edcabf3b&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1d4eb45b-4294-47b5-a4fb-6e174d910b5a&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=91f89b76-d96e-41b3-96b5-a80d2acc79ec&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=32a0f007-4fdc-4792-b73a-75d4846c2bf0&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=30be3906-231f-4424-915a-5a9b55c2350c&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=0165df1d-8626-43df-b7b8-b4568c8a5cee&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=073ef3c1-f422-456a-8f1a-cc2ead616afd&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=9f324c66-2b58-40ea-bf4a-504039454039&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=9309475f-5174-4e3c-8c18-8aaebd8f931f&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ef23a55b-a717-4e75-b2f6-a69e79c0492f&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=d44b3fbd-4092-41c5-b034-17aaf7dc70b4&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=e05677be-3e6b-4f47-881f-b3dce936bd6d&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=41b66c9f-fed1-4264-b23c-fd4773d439d6&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=667fa1de-afcc-4ab6-b840-edf0bf284a44&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=e0ec75d7-1fda-412e-9dc9-30655955180f&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=fbed33be-1c89-44e0-837b-00f29f4eadf3&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=82edf426-e335-4dad-9ca2-1da18c93ef66&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=fa472696-0d69-4c22-9ef1-285f4824e0f7&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=a9e8f576-096e-4e7a-b1a8-6bce17b50e7b&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=bea39ce6-f3d4-4c08-a83c-92ccd12476f3&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=09b8a022-a409-46a3-9dc5-adb0b2bc3430&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=03b90207-0b07-40a6-a0cf-cffbe28845f9&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=7f48f8ea-f8d1-42ca-a0b5-638c52b4de71&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=9dce3fcb-dde7-46d9-b9b4-b7cf711691e2&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=93d2dbbd-120b-4069-9e57-b6be9c638aef&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=7c0a81e7-e74d-4f89-955f-cce4d9451903&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1ca2ba30-3c93-4266-a8d9-24306d5aecee&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=51f68505-9bc9-4d3a-a144-d48393ff4b5b&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=6970ba7f-a4ae-429a-a188-4de9e0655a63&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=018e995e-cea8-4b69-ae46-af0cbdb9295d&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=d9f7cdf6-3169-4378-bcc0-72a51f33f5f1&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=c9f0f474-faae-4c48-9cc1-16b03ac92591&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=7dd41356-30d0-49fb-8919-cab0ca36b758&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=9c0a0fd2-772a-4191-ab19-04b102273594&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=3b5ccdd8-d419-41ef-a705-125d5fcf5b69&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=d7d006d2-80cc-4873-905e-562138d51fb8&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=de57c97a-8cf7-4b2d-9031-4d48fca1147b&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=57c8adbd-bfbd-42d2-b071-6d1cef5f2423&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=f7b4bf4f-c107-45b0-85c0-ed9192989542&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=6f2b3e18-2dde-4e92-9c75-be89a8c51da8&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=c95e537c-d0ab-48d3-8e5b-92bcf4792143&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=270f102d-e47d-4375-b318-5247cf0869f1&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=05d24722-76fb-4356-8c71-68748ab44d62&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=9b56d6a0-1d69-47d0-b4b3-594a9a15d2dc&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=742f172a-69b7-4f5b-baf5-120ad648362b&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=9759060f-5f1f-4d30-b178-eeccc45226fd&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=713d1554-3031-4783-9531-def4b52a69af&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=8056a286-5d20-4719-8102-fa6143f39ecf&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ea28858b-1cd4-4dda-be77-498f3295d623&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1c42d063-3fe9-4369-85ed-9c91839b8f90&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=b45d9d71-57e9-4ada-8c24-f9570d9b8bf4&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=e15af554-c95d-4c99-b5ba-8d832c2eb6d6&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=45699ee3-683e-44a3-9208-43ee079038e7&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=f98613ce-3f16-41d4-8c0b-629ad082c6b2&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1c4efa5c-b11d-48ca-ac32-2436aa2e5e07&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=979fe880-120a-4876-b444-7e9a355190b2&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=7871f4d6-a2e2-43f2-820f-3493d230a73c&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=c418dd94-c693-41cd-a00f-1d1a0f69ff3e&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=97f61029-7e7c-41ad-adf3-8c587a2e129b&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=0f83a094-49aa-48e3-9275-7ebc0ae014b8&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=7fb735e3-8ac9-4648-bf27-9b0cdc63099b&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=2a475034-f8b1-48ce-9858-8e0a2503a948&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=efb849e4-60c8-497f-be41-6358077dd951&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=20f030f5-4f4f-4b45-9fc5-ecfb6889153d&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=59ea925e-ed71-47fe-8c10-6b378ae9b485&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=0675d694-b77a-423e-ac79-f07eabb55227&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=2e792399-d56a-4073-acd6-140b7f466e3c&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=992e29fc-458f-4a83-9580-64bf0b40db7f&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1066e92c-5b78-4c2a-a057-d7c54235d5da&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=6baaa31d-e913-44e6-814d-77b1b462f582&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ee665ab5-8523-43aa-be62-93c8c2f52ca0&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1d09a58b-f10b-4082-a2c6-2b810dcbc655&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=f14eb88c-1894-461f-a354-2709cd93b05c&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=2a6a888f-2aa4-402e-b68f-3e2c760cd42e&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=d483d43e-c88f-49d3-97bd-cedfad4b67ca&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1755a82a-b493-4cb7-887a-83b0fd735697&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=93a7f7c0-ae32-43ed-9a8a-c0d3295318b5&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=5f225867-92d7-4ec5-a084-92b8fffae6b7&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=8e4bb967-25c1-4931-8e49-ce8aca5140fd&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=6cce0cd0-c359-4f33-a0c0-ba555e2bd1d6&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=78c39319-2121-4f97-82e1-9b1409691433&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=b4fd28da-44e5-4f7d-ba78-e9d9d7e8ab83&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ff17b382-43da-489e-a5d0-da556ce23d44&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=56c1a125-066b-45bc-aeb5-62501fa8b69f&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=14c57c00-7a47-427f-b810-4e6d4944e27f&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=e464229b-f08e-40cf-a76b-a53055d5972f&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=77490d7b-3a99-48fd-af71-9e2641dbe9a5&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ea407db4-5da2-4e8e-bbd4-f14670692ea0&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=0a2e709c-a687-4967-8260-7cf876577a8c&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=c4ef6a2c-2092-4b07-96e9-37059f93c2c4&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=2258e36a-30fb-4c1d-8143-f5ecc3b5155a&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=bcc8d35f-7cd7-4220-8368-188ef52858dc&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=6aa9cfa2-8225-4661-94f3-67174ab9306f&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=6ed1f84d-d7ba-4b74-9381-8d83036b089e&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ff3ab97a-16ff-46b4-9fd9-a4894ef56b8e&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=2bc72dc9-8f67-4642-9d06-870a41e3ee67&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=3f6bef16-aa13-4041-888e-0f4bf1186032&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=d794c94e-5547-4290-8d22-536a4a7b6eb0&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"POST /runs/query HTTP/11\" 200 None\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=a82bfdeb-1edb-4ea9-99c9-b95e25d60222&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=496f0943-2393-41be-8517-ae1666daf643&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=b061efde-be19-4a4c-9185-3f1e222d2433&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=5c228cd8-c988-4f0c-b7a0-dcef235fc026&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=cbc1dc82-bf05-420b-be2b-8a2535616e7d&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=adde447b-83b1-4190-88c0-937b6f63aa6a&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=11dbecee-db2b-4aae-b6ba-5c1b82c0b2cb&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=5756de21-6e88-49d1-b960-fd9ba68a1725&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=5f8154cc-8152-4034-b3fb-ab86bb044f11&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=f8a3c110-aa70-4221-ba4d-9dc2abfaaf7e&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ca8b65d9-38cd-496e-8d4b-dd99bca095f8&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=b3d66f2b-171e-4387-8a55-b18913c8a150&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=e7e1968f-ff5d-4b7d-8078-0a030e7e75ad&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=2ce1521a-f5e3-46e6-97ea-269fefc157f7&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=7a8a9f44-4591-4b6e-af37-4a580be64dd0&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=8a580f02-97d2-4056-9d0c-5b1ec1b8b8ae&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=2319a54e-3a5b-4814-8307-45b78102e8bf&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=7ee612bd-c32f-4e6f-902f-3ddc6be6c534&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=ba83caa4-0b93-4727-a944-d5415c6b1a8b&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=c3ffd3a1-3c39-4991-b94d-06a50f9c49fc&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=1b3d7bb4-a019-4a6b-aeba-ace2324e4d6b&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=546afffc-57d0-45a5-9acd-e47553546394&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=f3fc6360-4f16-4df4-9a08-4ee3b529f607&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=c3adacb9-f223-482c-8a03-13f13e57de2b&limit=100&offset=0 HTTP/11\" 200 2\n",
            "DEBUG:urllib3.connectionpool:https://api.smith.langchain.com:443 \"GET /feedback?run=693760f5-5093-40cc-b5a5-4c3f929d4b41&limit=100&offset=0 HTTP/11\" 200 2\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Run 0ae0a575-8541-4f2e-ab84-207cf5153bd8: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 991f92b1-72e5-4eec-a23e-ff6672b8a3af: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run d6c5c503-5024-4d2f-8c8e-d237ecd2ad56: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run ff378e64-55c4-4180-aa03-c4f76df0e2d3: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run ab598092-495f-48ad-b304-43f7de04c7d8: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run d29a5b3d-76e4-48aa-b312-5d2c9cc21c6c: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 5aca01a9-c384-4294-90d8-b72dd29a94b1: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 86f41c1b-f7ac-4bf9-b546-055929bdb3b9: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run ff1728f8-7b85-4c29-b09c-fac865d410c3: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 858584a0-97bf-4cfb-8113-df6b847c716a: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run f0797b70-8a1d-4236-ba35-a078f5b34ddc: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 0068815f-8f9c-4d37-88ae-e96f141701da: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 8595bda3-4a84-4c48-bdc7-bf66670fa79b: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 43745932-a368-467e-a3a2-bcc74c409841: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run aaa814c1-a434-4d83-a9b1-a483905a1bb6: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 10c15eed-fe50-4850-a10c-dfbf4a8052ba: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run ed5861e3-5bf4-46d9-875a-35cb509bf21d: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 6404a319-4fa8-4368-a8e2-c595d246c3c4: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run eddc953c-718f-4f37-8366-9c588934129b: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 3017da9a-f19c-480f-80f1-6623a2ac914e: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 84e23f6b-7e13-4fe2-8510-5c1c2c4211ef: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 21563347-7fb4-4171-9cf7-0ab6483fd0a0: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 05a82945-6302-45c4-b6e4-8179b08306be: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 3e3716d2-eb11-43b6-a810-98dd9216dfda: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run b1ccb462-b230-44d6-8ce2-481585030ac8: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run c1ffea25-3dd1-4778-b31e-a63044b219f3: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run ad4df582-c8ca-48ae-b9f2-9677a02f61e4: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 97e9210d-049a-41b3-88f9-12b249abf6dd: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 242a9c62-cb14-445f-855b-5594481273fe: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run ae7e8405-a912-4f8f-b755-4927b9db4216: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 7a3caff0-aa74-4df7-a98e-071663eb09fa: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run d3ae31e6-c5f3-423f-a081-da988bf98df1: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 568385c2-ea42-4983-9173-c2d1601293bf: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 950a3ab7-5826-40b1-8a47-a89aa6ba0363: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run c1797fac-e660-4e11-8392-6da89f649a14: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 28a6c51e-6858-4015-90d9-df96ca4bd2e0: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run b7ce2a55-abe6-4518-b7db-4ee71bcc7f87: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 5a36bd17-56d0-428a-81a1-c0b6df8a217c: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run e2a78380-bb02-4d8c-9bb1-40f1848e7787: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 2b2a3f15-939f-4a6c-b862-7fd36e1f2566: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 1e16fee0-98dd-431d-8bce-19d85cf21d6c: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 1346f35c-0e80-4781-9c3e-9845493ca363: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 63430948-b052-4039-a04f-e2cf2875adba: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run ed58dd89-1159-4aeb-b8ef-56b0c90f41da: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 5bc25e40-2cdc-4dd3-b49e-e0c57e8e195d: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run b10ed506-c739-4968-8322-7f2300522769: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run f2223ad9-f973-4c23-b8a7-3f2392bc1f43: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 271d6ec0-433c-476d-8eaf-75352f82f7ce: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 5ae495dc-12df-40f7-b148-55b178937639: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 6114b564-32b5-45cf-987e-0d72d5a22c98: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run b6ff8345-b692-41af-ac1a-396b5ff4029b: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 1564ecf5-5a4c-4d98-84f2-188525718675: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 3b77d841-a26c-49cf-8465-2a3e4d799599: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 8e7f364d-b325-4fa0-ab4e-8cd790b43a15: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run fb0ba507-65e8-43bd-a714-f5f38c56da8e: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 5e0cb001-f6c6-4dfc-b234-361f6d28f5ea: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 285f5953-c3bf-4c13-9167-bf70bf578c8d: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run b506f7e9-3f16-4f28-b72d-143dab7407f7: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 9873db3c-3951-4404-86f8-6a26ecbd7a9f: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run 911f1564-f484-4c7b-a9aa-a5fbfd83da51: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run cd91893e-9bed-4e60-9d1d-a1692b754978: Score: 1.0, Criteria: criteriaevalchain\n",
            "Run ca0345be-1b15-4724-81f3-c923fc877d44: Score: 1.0, Criteria: criteriaevalchain\n",
            "Average Score: 1.00\n",
            "Number of runs: 0\n"
          ]
        }
      ],
      "source": [
        "from langsmith import Client\n",
        "\n",
        "client = Client()\n",
        "project_name = \"Test_Project_20241004_080054_535737\"\n",
        "\n",
        "# Fetch all runs for the project\n",
        "runs = client.list_runs(project_name=project_name)\n",
        "\n",
        "# Aggregate results\n",
        "results = []\n",
        "for run in runs:\n",
        "    feedbacks = client.list_feedback(run_ids=[run.id])\n",
        "    for feedback in feedbacks:\n",
        "        results.append({\n",
        "            \"run_id\": run.id,\n",
        "            \"score\": feedback.score,\n",
        "            \"comment\": feedback.comment,\n",
        "            \"criteria\": feedback.key  # Assuming the criteria is stored in the key\n",
        "        })\n",
        "\n",
        "# Print or process results\n",
        "for result in results:\n",
        "    print(f\"Run {result['run_id']}: Score: {result['score']}, Criteria: {result['criteria']}\")\n",
        "\n",
        "# Optional: Calculate average score\n",
        "if results:\n",
        "    avg_score = sum(result['score'] for result in results if result['score'] is not None) / len(results)\n",
        "    print(f\"Average Score: {avg_score:.2f}\")\n",
        "\n",
        "# Print additional information for debugging\n",
        "print(f\"Number of runs: {len(list(runs))}\")\n",
        "for run in runs:\n",
        "    print(f\"Run ID: {run.id}\")\n",
        "    feedbacks = list(client.list_feedback(run_ids=[run.id]))\n",
        "    print(f\"  Number of feedbacks: {len(feedbacks)}\")\n",
        "    for feedback in feedbacks:\n",
        "        print(f\"    Feedback: Score={feedback.score}, Key={feedback.key}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import time\n",
        "from langchain_core.caches import InMemoryCache\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "from langsmith import Client\n",
        "from langchain.smith import RunEvalConfig\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain.evaluation import CriteriaEvalChain\n",
        "import uuid\n",
        "from datetime import datetime\n",
        "\n",
        "# Set up the cache\n",
        "cache = InMemoryCache()\n",
        "\n",
        "# Add cache to the chain\n",
        "cached_chain = retrieval_augmented_qa_chain.with_config(configurable={\"cache\": cache})\n",
        "\n",
        "# Set up LangSmith client\n",
        "client = Client()\n",
        "\n",
        "# Create a small dataset for evaluation\n",
        "eval_questions = [\n",
        "    {\"question\": \"Write 50 things about this document!\"},\n",
        "    {\"question\": \"Summarize the main points of the document.\"},\n",
        "    {\"question\": \"What are the key topics discussed in this document?\"}\n",
        "]\n",
        "\n",
        "dataset_name = \"qa_eval_dataset\"\n",
        "\n",
        "# Check if the dataset exists\n",
        "try:\n",
        "    existing_dataset = client.read_dataset(dataset_name=dataset_name)\n",
        "    print(f\"Using existing dataset: {dataset_name}\")\n",
        "except Exception:\n",
        "    # If the dataset doesn't exist, create it\n",
        "    try:\n",
        "        client.create_dataset(dataset_name, description=\"QA evaluation dataset\")\n",
        "        print(f\"Created new dataset: {dataset_name}\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error creating dataset: {e}\")\n",
        "        raise\n",
        "\n",
        "# Add examples to the dataset\n",
        "for item in eval_questions:\n",
        "    try:\n",
        "        client.create_example(inputs=item, dataset_name=dataset_name)\n",
        "    except Exception as e:\n",
        "        print(f\"Error adding example to dataset: {e}\")\n",
        "\n",
        "# Create a ChatOpenAI instance for evaluation\n",
        "eval_llm = ChatOpenAI(model=\"gpt-3.5-turbo\")\n",
        "\n",
        "# Define custom criteria\n",
        "criteria = {\n",
        "    \"relevance\": \"The response should be highly relevant to the question asked.\",\n",
        "    \"completeness\": \"The response should fully address all aspects of the question.\",\n",
        "    \"accuracy\": \"The information provided in the response should be accurate and factual.\",\n",
        "    \"clarity\": \"The response should be clear, well-structured, and easy to understand.\"\n",
        "}\n",
        "\n",
        "# Create a CriteriaEvalChain\n",
        "criteria_eval = CriteriaEvalChain.from_llm(\n",
        "    llm=eval_llm,\n",
        "    criteria=criteria\n",
        ")\n",
        "\n",
        "# Define evaluation config\n",
        "eval_config = RunEvalConfig(\n",
        "    evaluators=[criteria_eval],\n",
        "    custom_evaluators=[],\n",
        ")\n",
        "\n",
        "# Create a unique project name\n",
        "project_name = f\"QA_Eval_{datetime.now().strftime('%Y%m%d_%H%M%S')}_{uuid.uuid4().hex[:6]}\"\n",
        "\n",
        "# Create a new project\n",
        "try:\n",
        "    project = client.create_project(project_name)\n",
        "    print(f\"Created new project: {project_name}\")\n",
        "except Exception as e:\n",
        "    print(f\"Error creating project: {e}\")\n",
        "    raise\n",
        "\n",
        "# Run evaluation on the dataset\n",
        "try:\n",
        "    # Get the examples from the dataset\n",
        "    examples = list(client.list_examples(dataset_name=dataset_name))\n",
        "    \n",
        "    for example in examples:\n",
        "        # Start a run\n",
        "        try:\n",
        "            run = client.create_run(\n",
        "                project_name=project_name,\n",
        "                name=\"QA Evaluation\",\n",
        "                run_type=\"chain\",\n",
        "                inputs=example.inputs\n",
        "            )\n",
        "            \n",
        "            if run is None:\n",
        "                print(f\"Warning: create_run returned None for input: {example.inputs}\")\n",
        "                continue\n",
        "            \n",
        "            print(f\"Created run with ID: {run.id}\")\n",
        "            \n",
        "            # Manually execute the chain\n",
        "            result = cached_chain.invoke(example.inputs)\n",
        "            \n",
        "            # Update the run with the result\n",
        "            client.update_run(\n",
        "                run.id,\n",
        "                outputs=result,\n",
        "                end_time=datetime.utcnow(),\n",
        "                error=None,\n",
        "            )\n",
        "            \n",
        "            print(f\"Updated run {run.id} with result\")\n",
        "            \n",
        "            # Run evaluators\n",
        "            for evaluator in eval_config.evaluators:\n",
        "                eval_result = evaluator.evaluate_strings(\n",
        "                    prediction=result['text'] if isinstance(result, dict) else str(result),\n",
        "                    input=example.inputs[\"question\"],\n",
        "                )\n",
        "                client.create_feedback(\n",
        "                    run.id,\n",
        "                    evaluator.__class__.__name__,\n",
        "                    score=eval_result.get(\"score\"),\n",
        "                    comment=eval_result.get(\"reasoning\"),\n",
        "                )\n",
        "            \n",
        "            print(f\"Added feedback for run {run.id}\")\n",
        "            \n",
        "        except Exception as e:\n",
        "            print(f\"Error processing example: {e}\")\n",
        "            if 'run' in locals() and run is not None:\n",
        "                client.update_run(\n",
        "                    run.id,\n",
        "                    error=str(e),\n",
        "                    end_time=datetime.utcnow(),\n",
        "                )\n",
        "    \n",
        "    print(\"Evaluation completed.\")\n",
        "    print(f\"Project Name: {project_name}\")\n",
        "    print(f\"Dataset Name: {dataset_name}\")\n",
        "    print(f\"Number of examples processed: {len(examples)}\")\n",
        "    print(\"\\nFor detailed results, check the LangSmith UI.\")\n",
        "    \n",
        "except Exception as e:\n",
        "    print(f\"Error running evaluation: {e}\")\n",
        "    import traceback\n",
        "    traceback.print_exc()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
