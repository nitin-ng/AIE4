{"questions": {"2b63e9da-5eb2-4515-a608-5e7786f084d1_1": "What are the key principles outlined in the AI Bill of Rights aimed at ensuring automated systems benefit the American people?  ", "2b63e9da-5eb2-4515-a608-5e7786f084d1_2": "How does the AI Bill of Rights address potential ethical concerns related to automated systems?", "7ed5d69a-bcd6-4656-8b22-c949fcca3c7f_1": "What is the purpose of the Blueprint for an AI Bill of Rights published by the White House Office of Science and Technology Policy?  ", "7ed5d69a-bcd6-4656-8b22-c949fcca3c7f_2": "How does the development of an AI Bill of Rights reflect public engagement in shaping AI ethics?", "9044b75d-90c9-48b5-928e-7bcd84671a28_1": "How does the Policy, Organization, and Priorities Act of 1976 influence ethical decision-making in AI development within the Executive Office of the President?  ", "9044b75d-90c9-48b5-928e-7bcd84671a28_2": "In what ways might the advice provided under the Policy, Organization, and Priorities Act of 1976 impact the ethical considerations of AI technologies in government policy?", "3645e5f9-8926-491d-b191-ba5112b25c49_1": "How does the Blueprint for an AI Bill of Rights aim to address ethical concerns in the deployment of automated systems?  ", "3645e5f9-8926-491d-b191-ba5112b25c49_2": "What role does the OSTP play in ensuring that AI technologies align with federal policies on ethics and public welfare?", "39993687-916c-4671-8d4b-4732af201b16_1": "How can policies ensure the protection of civil rights in the deployment of automated systems?  ", "39993687-916c-4671-8d4b-4732af201b16_2": "What role do democratic values play in the governance of AI technologies?", "d19fb894-9e8d-4d18-a94d-1f01bdd33c56_1": "What is the nature of the Blueprint for an AI Bill of Rights in relation to U.S. government policy?  ", "d19fb894-9e8d-4d18-a94d-1f01bdd33c56_2": "Does the Blueprint for an AI Bill of Rights impose any binding obligations on federal agencies or the public?", "ff3ab363-0163-4dbd-955a-293ff6025248_1": "How do the principles outlined for Federal agencies ensure ethical compliance in AI applications related to law enforcement and national security?  ", "ff3ab363-0163-4dbd-955a-293ff6025248_2": "What implications do the principles have for the ethical use of AI in intelligence activities by government agencies?", "57277e82-772d-4954-bee1-78a723ef113a_1": "How does the context of automated systems influence the application of ethical principles in AI usage?  ", "57277e82-772d-4954-bee1-78a723ef113a_2": "Why might future sector-specific guidance be necessary for the ethical use of AI in sensitive areas like school security and health diagnostics?", "761f6036-77a2-4998-81de-7eb2b6330c04_1": "How can the principle of notice be balanced with the need to protect sensitive law enforcement information in AI applications?  ", "761f6036-77a2-4998-81de-7eb2b6330c04_2": "What ethical considerations arise when adjusting notice requirements to safeguard sources and methods in law enforcement contexts?", "cb21e5d1-397e-4884-bf14-e22de8225d10_1": "How do judicial, privacy, and civil liberties oversight impact the use of AI in law enforcement?", "cb21e5d1-397e-4884-bf14-e22de8225d10_2": "What role does Executive Order 13960 play in promoting trustworthy AI within federal agencies?", "b69096bb-dfe0-440f-8dbe-963d97850aff_1": "What are the special requirements that govern the use of AI in activities involving adversaries?  ", "b69096bb-dfe0-440f-8dbe-963d97850aff_2": "How do the Department of Defense (DOD) AI Ethical Principles relate to the safeguarding of classified information?", "43070dc6-452b-4896-9642-d71f2c7decee_1": "How does the Blueprint for an AI Bill of Rights inform the implementation of AI ethics principles in national security and defense activities?  ", "43070dc6-452b-4896-9642-d71f2c7decee_2": "What limitations does the Blueprint for an AI Bill of Rights have regarding legal enforceability?", "d15b0f49-6066-4f4b-b930-9f0d907c9eff_1": "What implications does the public domain status of government documents have for the ethical use of AI in research and development?  ", "d15b0f49-6066-4f4b-b930-9f0d907c9eff_2": "How does the accessibility of public domain works influence the ethical considerations surrounding AI-generated content?", "9eee00fb-1d02-43fa-801e-7f68e9690cfa_1": "How do automated systems threaten the rights of the American public according to the context provided?  ", "9eee00fb-1d02-43fa-801e-7f68e9690cfa_2": "What are some documented issues with algorithms used in hiring and credit decisions?", "cae51451-45cb-4f73-a0f8-f76e0e6fd5ef_1": "How can automated systems be designed to protect user privacy and ensure informed consent?  ", "cae51451-45cb-4f73-a0f8-f76e0e6fd5ef_2": "What are the potential harms of pervasive tracking by AI systems on individual autonomy?", "4ef57090-9555-4422-8147-7c76ed92a7d5_1": "How can the use of AI in decision-making processes be balanced with the protection of civil rights and democratic values?  ", "4ef57090-9555-4422-8147-7c76ed92a7d5_2": "What ethical considerations should be taken into account when deploying AI technologies in sectors that impact public health and safety?", "66a4ed20-14b1-45f1-84df-37f09b52e569_1": "How does the President's order to embed fairness in decision-making processes relate to AI ethics?  ", "66a4ed20-14b1-45f1-84df-37f09b52e569_2": "In what ways can AI contribute to affirmatively advancing civil rights and racial justice as outlined by the President?", "d4921251-b4d5-47bd-933b-3bc479317063_1": "What is the significance of the right to privacy in the context of AI ethics as mentioned in the provided context?  ", "d4921251-b4d5-47bd-933b-3bc479317063_2": "How do the five principles identified by the White House Office of Science and Technology Policy aim to protect civil rights in the age of artificial intelligence?", "2394e9b3-81e2-4b54-8f03-a8a15add6484_1": "How does the framework aim to address the ethical concerns of the American public regarding AI?  ", "2394e9b3-81e2-4b54-8f03-a8a15add6484_2": "What role do researchers and policymakers play in shaping the ethical guidelines for AI as outlined in the framework?", "85928e54-ae18-4a1d-8650-42edd0b4ff5d_1": "What role do ethical principles play in the design of automated systems that affect public rights and access?  ", "85928e54-ae18-4a1d-8650-42edd0b4ff5d_2": "How can the implementation of ethical principles in technology design impact opportunities for marginalized communities?", "0214b542-d262-47df-b694-561355ee341d_1": "What are the main objectives of the Blueprint for an AI Bill of Rights?", "0214b542-d262-47df-b694-561355ee341d_2": "How does the Blueprint for an AI Bill of Rights aim to protect civil rights and liberties in the context of AI?", "d8289c72-842b-4dde-a3d5-fd17a45632c1_1": "What are some concrete steps organizations can take to uphold ethical values in AI development and deployment?  ", "d8289c72-842b-4dde-a3d5-fd17a45632c1_2": "How can collaboration between the private sector and governments enhance AI ethics?", "c175618a-4c65-4090-bfd8-69c6bbe61d5b_1": "What role do consortia play in guiding the responsible use of automated systems according to the provided context?  ", "c175618a-4c65-4090-bfd8-69c6bbe61d5b_2": "How does the Blueprint for an AI Bill of Rights contribute to policy decisions in the absence of existing laws or policies?", "2d3b4509-9b83-450f-b319-4d8fc1293751_1": "What are the potential remedies for algorithmic and data-driven harms discussed by experts and policymakers?  ", "2d3b4509-9b83-450f-b319-4d8fc1293751_2": "How do panel discussions contribute to addressing AI ethics concerns related to algorithmic harms?", "2f43deab-8be2-4cd3-9dc5-4a63947b2ae1_1": "What are the key concerns raised by the public regarding the potential harms of AI technologies?  ", "2f43deab-8be2-4cd3-9dc5-4a63947b2ae1_2": "How does the Blueprint for an AI Bill of Rights aim to balance the transformative potential of AI with the need to prevent its harms?", "f70ec23e-99af-48fd-9e17-ece2eaee3d16_1": "What measures should be taken to ensure that automated systems are safe and effective before deployment?", "f70ec23e-99af-48fd-9e17-ece2eaee3d16_2": "How should the design of automated systems address the potential for unintended uses that could endanger safety?", "b59fa977-0d2b-4bb7-8583-13bbe3338f39_1": "What are the key considerations for identifying and mitigating risks associated with AI systems?  ", "b59fa977-0d2b-4bb7-8583-13bbe3338f39_2": "How can ongoing monitoring contribute to the ethical deployment of AI systems?", "facfa226-5df2-4fa8-9cda-a0f1674fa12e_1": "What measures should be taken to ensure that automated systems do not contribute to algorithmic discrimination?  ", "facfa226-5df2-4fa8-9cda-a0f1674fa12e_2": "Why is independent evaluation and public reporting important in the context of automated systems and their potential harms?", "8cc2a2d9-2eed-45ad-af65-538324fcefb1_1": "How can AI systems be designed to prevent discrimination based on race, color, or ethnicity?  ", "8cc2a2d9-2eed-45ad-af65-538324fcefb1_2": "What ethical considerations should be taken into account to ensure fair treatment of individuals regardless of their sex or gender identity in AI applications?", "3bc51cf4-d565-46b0-8e09-508b2041824d_1": "What measures should designers and developers take to prevent algorithmic discrimination in automated systems?  ", "3bc51cf4-d565-46b0-8e09-508b2041824d_2": "Why is it important to conduct proactive equity assessments during the design of automated systems?", "6c2a16cc-9fd1-46be-9fce-59ee4dfba44a_1": "What role does independent evaluation play in ensuring ethical AI deployment?  ", "6c2a16cc-9fd1-46be-9fce-59ee4dfba44a_2": "How can plain language reporting contribute to transparency in algorithmic impact assessments?", "bca32085-cc69-4be5-9c8a-1c5cf12ae532_1": "How can disparity testing contribute to ensuring ethical AI practices?  ", "bca32085-cc69-4be5-9c8a-1c5cf12ae532_2": "Why is it important for mitigation information related to AI disparities to be made public?", "ec22a03b-6e3a-43ad-b92f-09231cf270ed_1": "What are the key principles that should guide the design of automated systems to protect data privacy?  ", "ec22a03b-6e3a-43ad-b92f-09231cf270ed_2": "How should designers and developers ensure that data collection aligns with users' reasonable expectations?", "f458c57d-9ef9-448a-b325-4e7fde633c9f_1": "What are the implications of using user experience design that obfuscates user choice in AI systems?  ", "f458c57d-9ef9-448a-b325-4e7fde633c9f_2": "Why is it important to avoid privacy-invasive defaults in AI systems?", "498eb8a3-1798-44fe-a1bb-ee5972a931a6_1": "What are the key principles that should guide consent requests for data collection in sensitive domains?", "498eb8a3-1798-44fe-a1bb-ee5972a931a6_2": "Why is it important to have enhanced protections for data related to sensitive domains such as health and education?", "08130ab3-8809-41f9-a10c-c9c7080b67a6_1": "What measures should be implemented to ensure that surveillance technologies do not infringe on privacy and civil liberties?  ", "08130ab3-8809-41f9-a10c-c9c7080b67a6_2": "Why is heightened oversight necessary for the deployment of surveillance technologies?", "2d7dabaf-155c-4036-a458-59b8119c1a03_1": "What are the potential ethical implications of using surveillance technologies in education and work environments?", "2d7dabaf-155c-4036-a458-59b8119c1a03_2": "Why is it important for individuals to have access to reporting that confirms their data decisions have been respected?", "0827d937-883e-4b60-9b04-7e83cca84940_1": "What is the importance of transparency in the functioning of automated systems?  ", "0827d937-883e-4b60-9b04-7e83cca84940_2": "How does accountability relate to the outcomes produced by AI systems?", "2e1c7072-d11c-4832-ba82-f2fd3a0e309e_1": "What are the ethical implications of not notifying individuals about significant changes in automated systems that impact them?  ", "2e1c7072-d11c-4832-ba82-f2fd3a0e309e_2": "How important is it for automated systems to provide clear and meaningful explanations of their outcomes to ensure accountability?", "42da6bfa-8628-49ed-b638-a2b9be70becc_1": "What are the ethical implications of allowing individuals to opt out of automated systems in favor of human alternatives?", "42da6bfa-8628-49ed-b638-a2b9be70becc_2": "How does the requirement for human alternatives in automated systems contribute to protecting the public from harmful impacts?", "586ae00e-8427-491b-a0a6-94a21394af7c_1": "What are the key principles that should guide human consideration and fallback in AI systems?  ", "586ae00e-8427-491b-a0a6-94a21394af7c_2": "Why is operator training important in the context of AI ethics?", "337ca019-42c2-4790-ba4f-36dfb745dc11_1": "What are the key considerations for implementing automated systems in sensitive domains according to AI ethics?  ", "337ca019-42c2-4790-ba4f-36dfb745dc11_2": "Why is it important to provide meaningful access for oversight in automated systems used in high-risk decisions?", "40d48902-c91a-408f-91e6-4034893da786_1": "What are the key terms defined in The Blueprint for an AI Bill of Rights?  ", "40d48902-c91a-408f-91e6-4034893da786_2": "How can the principles of the AI Bill of Rights be actualized according to the Technical Companion?", "b1c0f3a6-07a7-4a9a-b753-9a50a3c277f3_1": "What criteria does the framework use to determine which automated systems are in scope for the AI Bill of Rights?  ", "b1c0f3a6-07a7-4a9a-b753-9a50a3c277f3_2": "How does the framework address the potential harms of AI systems that may not be technologically sophisticated?", "53d396a2-66c4-4977-90e7-0bb3a2484e16_1": "What protections should be applied to automated systems to ensure equal enjoyment and full protection for all individuals?  ", "53d396a2-66c4-4977-90e7-0bb3a2484e16_2": "How does the changing role of automated systems impact ethical considerations in AI?", "e3f5ac23-ad36-4454-8a57-3cd4c0dd9283_1": "How can AI systems impact individuals' civil rights and liberties in the context of unlawful surveillance?  ", "e3f5ac23-ad36-4454-8a57-3cd4c0dd9283_2": "In what ways might AI influence equitable access to education and employment opportunities?", "6181a68a-0654-4b9f-9fbe-e7f224ee42cc_1": "What principles should be considered when creating or deploying automated systems?  ", "6181a68a-0654-4b9f-9fbe-e7f224ee42cc_2": "Who can benefit from the guidance provided in the Technical Companion regarding automated systems?", "b8e5f957-237b-4204-9b9a-a45cc9535d88_1": "What are the five principles outlined in the Blueprint for an AI Bill of Rights aimed at protecting the public from harm?", "b8e5f957-237b-4204-9b9a-a45cc9535d88_2": "How should the measures taken to implement the Blueprint for an AI Bill of Rights relate to the potential risks to people's rights and opportunities?", "d47b9e1c-489a-4c71-a99b-c45894f40e39_1": "What principles are suggested to ensure protections against the potential harms of automated systems?  ", "d47b9e1c-489a-4c71-a99b-c45894f40e39_2": "How does the U.S. Constitution relate to the protections of individuals in the context of automated systems?", "2f4e355a-2898-4cc3-8ca1-50fb833163ab_1": "How do existing U.S. laws ensure ethical oversight in government surveillance and data search and seizure?  ", "2f4e355a-2898-4cc3-8ca1-50fb833163ab_2": "What role do civil rights laws play in protecting individuals from discrimination in the context of AI applications?", "1eb81643-0479-4669-b94c-1538bf03b398_1": "What are the implications of existing laws on the implementation of the AI Bill of Rights?", "1eb81643-0479-4669-b94c-1538bf03b398_2": "How might exceptions to the AI Bill of Rights principles be justified in specific use cases?", "95e72817-edc5-4037-8517-acf270aa38a1_1": "How can government actors ensure the protection of civil rights and liberties while implementing AI technologies?  ", "95e72817-edc5-4037-8517-acf270aa38a1_2": "What alternate mechanisms can be used to uphold privacy in AI enforcement and regulatory contexts?", "f876a0e6-2549-4dea-9bc7-16a5a0fbf3a0_1": "What is the purpose of the Blueprint for an AI Bill of Rights?", "f876a0e6-2549-4dea-9bc7-16a5a0fbf3a0_2": "How does the Technical Companion contribute to the implementation of AI ethics principles?", "b9a14487-6e9e-4423-99c1-9dd441b1a316_1": "How can the development and use of AI systems impact individual rights and opportunities?  ", "b9a14487-6e9e-4423-99c1-9dd441b1a316_2": "What considerations should be taken into account for public involvement in AI systems that affect access?", "f5d21644-a601-4747-bd5a-ffb8e242df95_1": "What are some examples of ethical principles proposed for the use of AI and automated systems?  ", "f5d21644-a601-4747-bd5a-ffb8e242df95_2": "How have recent legislative and regulatory efforts addressed the ethical concerns surrounding AI technologies?", "b4980938-40f7-491e-a986-6401a99cf198_1": "What principles for responsible stewardship of trustworthy AI are outlined in the OECD's 2019 Recommendation?  ", "b4980938-40f7-491e-a986-6401a99cf198_2": "How does Executive Order 13960 relate to the promotion of trustworthy artificial intelligence in the United States?", "b814145f-813e-48e7-a532-bb731bbda211_1": "How do the principles outlined in the Blueprint for an AI Bill of Rights align with the Fair Information Practice Principles (FIPPs)?", "b814145f-813e-48e7-a532-bb731bbda211_2": "In what ways does Executive Order 13985 influence the ethical considerations of AI use in relation to racial equity and underserved communities?", "1b61df3a-157c-4cb7-a504-9ce289071061_1": "How does the Blueprint for an AI Bill of Rights relate to the Fair Information Practice Principles (FIPPs)?  ", "1b61df3a-157c-4cb7-a504-9ce289071061_2": "What is the significance of incorporating elements of FIPPs in the context of automated systems?", "c0238690-f8df-4333-95b9-9d6ae1c9c584_1": "How does the Technical Companion aim to balance technological innovation with the protection of civil rights and liberties?  ", "c0238690-f8df-4333-95b9-9d6ae1c9c584_2": "What role does risk management play in the ethical considerations outlined in the Technical Companion?", "0b113d5f-1c35-4d6f-a0ec-4929f5852df4_1": "What constitutes algorithmic discrimination according to the Blueprint for an AI Bill of Rights?  ", "0b113d5f-1c35-4d6f-a0ec-4929f5852df4_2": "How can algorithmic discrimination potentially violate legal protections?", "632db52c-2137-4d81-8f38-50ba34866e02_1": "How does the definition of an \"automated system\" relate to the potential for discrimination in AI applications?  ", "632db52c-2137-4d81-8f38-50ba34866e02_2": "What ethical considerations arise from the use of automated systems in decision-making processes?", "fc0446c2-84a2-4f27-966b-f5d328a70f50_1": "What types of systems are excluded from the definition of automated systems in the context of AI ethics?  ", "fc0446c2-84a2-4f27-966b-f5d328a70f50_2": "How do automated systems interact with individuals and communities according to the provided context?", "eff9ff37-f61f-4420-9055-e2a218c7b41c_1": "What criteria determine whether an automated system is considered in scope for ethical evaluation?  ", "eff9ff37-f61f-4420-9055-e2a218c7b41c_2": "How does the potential impact of automated systems on individuals' rights influence AI ethics frameworks?", "98a604f9-3590-48ce-95e7-977f304548d0_1": "How can AI systems ensure they do not harm communities while collecting data on individuals?  ", "98a604f9-3590-48ce-95e7-977f304548d0_2": "In what ways does the concept of community influence the ethical considerations in the development of AI technologies?", "3d8070c4-6254-4b5c-8ba4-da2ccf2e0d00_1": "How does the Blueprint for an AI Bill of Rights address the challenges of protecting community-level rights in the context of AI?  ", "3d8070c4-6254-4b5c-8ba4-da2ccf2e0d00_2": "What are the potential shortcomings of existing legal frameworks in safeguarding individual rights against the harms of automated systems?", "522a2717-200a-4374-8fd5-d3abdfbc1226_1": "How should AI systems be evaluated to ensure they promote equity for underserved communities?  ", "522a2717-200a-4374-8fd5-d3abdfbc1226_2": "What measures can be taken to protect individuals from systemic bias in AI systems?", "75e202a1-d140-4f47-ab2b-e211e543a2c5_1": "How can AI be designed to ensure equitable access for older adults and persons with disabilities?  ", "75e202a1-d140-4f47-ab2b-e211e543a2c5_2": "What ethical considerations should be taken into account when deploying AI technologies in rural areas to address persistent poverty or inequality?", "041d2876-f023-40b1-b0f1-c6be2e3d1b74_1": "How do civil rights and liberties relate to the ethical use of AI in public and private sectors?  ", "041d2876-f023-40b1-b0f1-c6be2e3d1b74_2": "What role does equitable access to resources play in the ethical considerations of AI deployment?", "4a9174fe-7911-42c1-a501-1349cc643ff1_1": "What types of data are considered sensitive according to the AI Bill of Rights?", "4a9174fe-7911-42c1-a501-1349cc643ff1_2": "How can sensitive data potentially expose individuals to meaningful harm?", "8c9806de-cd1b-4da8-9191-64efcef9e09d_1": "What are the ethical implications of using data generated by minors in AI systems?  ", "8c9806de-cd1b-4da8-9191-64efcef9e09d_2": "How can organizations mitigate the risk of financial harm related to identity theft when handling sensitive data?", "3165553a-9b8f-480c-afa3-17192d6a2b6c_1": "What are some examples of sensitive domains that require enhanced data protections in AI ethics?  ", "3165553a-9b8f-480c-afa3-17192d6a2b6c_2": "How can activities in sensitive domains lead to material harms related to human rights?", "664037f2-7155-4df2-988e-78aabec95a6f_1": "How do societal norms influence the classification of sensitive data in the context of surveillance technology?  ", "664037f2-7155-4df2-988e-78aabec95a6f_2": "What legal considerations must be taken into account when implementing surveillance technology?", "5be54f63-786c-49fd-8126-f5bd288f8600_1": "How do surveillance technologies impact the rights and opportunities of underserved communities?", "5be54f63-786c-49fd-8126-f5bd288f8600_2": "What ethical considerations arise from the use of automated analysis in monitoring individuals or groups?", "f81943d9-e0a4-4e02-9518-58b1c430f446_1": "How does the concept of equity relate to the ethical deployment of AI technologies?  ", "f81943d9-e0a4-4e02-9518-58b1c430f446_2": "What are the implications of failing to consider equity in AI development and implementation?", "9020b6f0-1074-4064-82e9-95845d0b121e_1": "What are the key principles outlined in the AI Bill of Rights that guide ethical AI development?  ", "9020b6f0-1074-4064-82e9-95845d0b121e_2": "How can the technical companion to the AI Bill of Rights assist in implementing ethical AI practices?", "92a6cf51-caf8-4cc2-91bb-a966dbf400df_1": "How does the technical companion address algorithmic discrimination protections in AI systems?  ", "92a6cf51-caf8-4cc2-91bb-a966dbf400df_2": "What considerations are outlined for ensuring data privacy in the context of AI systems?", "b8b71f36-757d-495c-9719-e84c0a976606_1": "What are the five principles outlined in the Blueprint for an AI Bill of Rights?  ", "b8b71f36-757d-495c-9719-e84c0a976606_2": "How can communities implement the practices suggested in the technical companion to protect the rights of individuals in relation to AI?", "cc8c282e-d378-4571-980f-cc0ddf33a406_1": "What are some potential harms of AI that need to be guarded against?  ", "cc8c282e-d378-4571-980f-cc0ddf33a406_2": "Who are the stakeholders involved in identifying the harms of AI?", "99697ee1-707b-43e9-b4ae-722e0fec5901_1": "What is the purpose of the technical companion in relation to automated systems?  ", "99697ee1-707b-43e9-b4ae-722e0fec5901_2": "How do the principles outlined in the technical companion aim to address ethical concerns in the development and deployment of automated systems?", "7ad79f6c-d800-49dc-864b-b1deb43ea49f_1": "What practical steps are suggested to align AI development with the principles of the AI Bill of Rights?  ", "7ad79f6c-d800-49dc-864b-b1deb43ea49f_2": "How does the Blueprint for an AI Bill of Rights aim to address ethical concerns in AI deployment?", "edaf9e38-6479-48ef-ba9d-5d6c07ae6f09_1": "How do expectations for reporting on automated systems contribute to transparency in AI development?", "edaf9e38-6479-48ef-ba9d-5d6c07ae6f09_2": "What role do governance structures play in addressing unmet needs for change in technology development?", "81f3b7b1-3a02-44c8-8727-4e4b24c3a730_1": "What role do oversight bodies play in ensuring ethical considerations in AI when public reports cannot be released?  ", "81f3b7b1-3a02-44c8-8727-4e4b24c3a730_2": "How do privacy and civil liberties officers contribute to the ethical oversight of AI in the context of national security?", "4c6f7d89-da85-42d5-9489-fbdb8d8ef27e_1": "How do reporting expectations contribute to the protection of individuals' rights in the context of AI technologies?  ", "4c6f7d89-da85-42d5-9489-fbdb8d8ef27e_2": "What role do laws and policies play in ensuring transparency and respect for individuals' rights in AI practices?", "a9367afa-7030-48f2-ad57-a2f1b36648b4_1": "What role do industry and civil society play in the implementation of the AI Bill of Rights?  ", "a9367afa-7030-48f2-ad57-a2f1b36648b4_2": "How can collaboration among various stakeholders enhance the effectiveness of the AI Bill of Rights?", "3c6632b7-4be4-40c6-876b-e9050252fe27_1": "What measures should be taken to ensure that automated systems are safe and effective before deployment?  ", "3c6632b7-4be4-40c6-876b-e9050252fe27_2": "Why is it important to involve diverse communities and stakeholders in the development of automated systems?", "d3e92914-f693-4ffd-affc-73a1af5af922_1": "How can AI systems be designed to proactively protect individuals from potential harms?  ", "d3e92914-f693-4ffd-affc-73a1af5af922_2": "What are the ethical implications of AI technologies that may endanger community safety?", "ffe359b8-2946-4487-b123-167bcd402f5b_1": "What measures should be taken to protect individuals from inappropriate data use in automated systems?  ", "ffe359b8-2946-4487-b123-167bcd402f5b_2": "Why is independent evaluation and public reporting important in the context of automated systems?", "5b75b1af-b531-4af4-af70-39540fd42e54_1": "What are the potential risks associated with deploying unproven technologies in critical situations?  ", "5b75b1af-b531-4af4-af70-39540fd42e54_2": "How can reliance on historical data in automated systems lead to unjustified harm?", "1238d8f9-c2bd-42f8-88c2-a1288d42a98d_1": "How can AI technologies be designed to prevent intentional violations of safety, such as stalking?  ", "1238d8f9-c2bd-42f8-88c2-a1288d42a98d_2": "What measures can be taken to mitigate unintended harms caused by AI in decision-making processes?", "f9954383-4233-4888-af4d-037eed9ee778_1": "What measures are companies taking to prevent unintended harms from AI technologies?  ", "f9954383-4233-4888-af4d-037eed9ee778_2": "How do public consultation processes contribute to the ethical deployment of automated systems?", "87c6faa4-a0b0-49f7-93bf-8488edb84ac2_1": "What are the potential benefits of implementing expanded, proactive protections for automated systems in terms of public confidence?  ", "87c6faa4-a0b0-49f7-93bf-8488edb84ac2_2": "How might uneven deployment of ethical practices in AI affect the protection of the American public?", "29057260-21d6-4d98-8c94-563c7af4c2a6_1": "What ethical considerations arise from the use of proprietary models in predicting medical conditions like sepsis, especially when they underperform and cause alert fatigue?", "29057260-21d6-4d98-8c94-563c7af4c2a6_2": "How can automated systems in healthcare be designed to ensure they do not lead to unintended harmful outcomes for patients?", "1938b0e4-4263-45d4-8faa-c1d668a424c1_1": "How can automated moderation systems be improved to better differentiate between racist messages and counter speech from marginalized communities?  ", "1938b0e4-4263-45d4-8faa-c1d668a424c1_2": "What ethical implications arise from the silencing of Black voices in automated moderation systems on social media?", "280ee76b-a037-4e64-a5ef-b0a924563916_1": "What ethical considerations arise from the misuse of tracking devices originally designed for safety?", "280ee76b-a037-4e64-a5ef-b0a924563916_2": "How does the deployment of algorithms in policing raise concerns about bias and community safety?", "604e5eb5-6d9c-4b92-b747-aff4269bc558_1": "How can feedback loops in AI crime prediction systems contribute to ethical concerns in policing?  ", "604e5eb5-6d9c-4b92-b747-aff4269bc558_2": "What are the implications of using historical arrest data in AI algorithms for predicting crime in neighborhoods?", "43e9df7f-b104-488e-ade6-812ec0b85f76_1": "How does AI-enabled \"nudification\" technology contribute to image-based abuse, particularly against women?  ", "43e9df7f-b104-488e-ade6-812ec0b85f76_2": "What ethical concerns arise from the use of apps that allow non-technical users to create or alter images of individuals without their consent?", "3c449b5a-c2ea-40a6-b15c-c59ca58f6e40_1": "What are the ethical implications of using AI to create non-consensual intimate images?  ", "3c449b5a-c2ea-40a6-b15c-c59ca58f6e40_2": "How does the experience of harm from non-consensual intimate images challenge the notion of authenticity in AI-generated content?", "c3f37ade-3ffc-4098-857b-7f07e94ba162_1": "What ethical concerns arise from the use of AI-powered cameras that incorrectly penalize drivers for events beyond their control?  ", "c3f37ade-3ffc-4098-857b-7f07e94ba162_2": "How might the implementation of such an AI system impact driver morale and trust in the company?", "634d3e1e-b2ab-42dd-8ad8-57013d5f96bf_1": "What safeguards should be included in automated systems to protect the public from harm?  ", "634d3e1e-b2ab-42dd-8ad8-57013d5f96bf_2": "Why is it important to avoid the use of inappropriate or irrelevant data in automated systems?", "98564560-d952-479b-aa34-5020a64a3cf0_1": "Why is early-stage consultation with the public important in the development of automated systems?  ", "98564560-d952-479b-aa34-5020a64a3cf0_2": "What phases of automated system development should involve public consultation?", "acb01b35-7287-4e65-aa40-a9b96df85eb2_1": "Why is it important to engage diverse impacted communities when implementing a new automated system?", "acb01b35-7287-4e65-aa40-a9b96df85eb2_2": "What role do experts on civil rights, civil liberties, and privacy play in the consultation process for automated systems?", "6be2c786-aa9e-4a2b-848f-467ef69ab36c_1": "What ethical considerations arise from the need for confidentiality in AI applications related to law enforcement and national security?  ", "6be2c786-aa9e-4a2b-848f-467ef69ab36c_2": "How do preexisting oversight laws and structures impact the ethical deployment of AI in sensitive government applications?", "79abe2e9-b1f4-41a5-aea6-ad20a38685f5_1": "What role does extensive testing play in the ethical deployment of automated systems?", "79abe2e9-b1f4-41a5-aea6-ad20a38685f5_2": "Why is it important to consider human operators in the testing of automated systems?", "d7cfcc0d-953a-4818-b77e-a89206c8bee3_1": "What ethical considerations should be taken into account when comparing AI system performance to human-driven procedures?  ", "d7cfcc0d-953a-4818-b77e-a89206c8bee3_2": "How can the deployment conditions of an AI system impact its ethical implications?", "8d000301-fae4-46f2-9274-9a6263bd184c_1": "How should the performance baseline for an AI algorithm be determined in relation to existing human performance?  ", "8d000301-fae4-46f2-9274-9a6263bd184c_2": "What steps should be taken to identify and mitigate risks associated with the deployment of an automated system?", "8cebe0ab-1fe9-4d44-9e6b-ac207e5b8dec_1": "How should high impact risks associated with AI systems be prioritized in ethical assessments?  ", "8cebe0ab-1fe9-4d44-9e6b-ac207e5b8dec_2": "What role does stakeholder consultation play in identifying ethical concerns related to AI systems?", "84a037db-cea9-4f44-9971-d9c90396d636_1": "What should be done with automated systems that have unintended safety violations?  ", "84a037db-cea9-4f44-9971-d9c90396d636_2": "How should the development of automated systems be approached to ensure they do not violate the safety of others?", "2ed7e2e9-7c6f-401d-80ef-69c6eabf0cd6_1": "What role does ongoing monitoring play in ensuring the ethical deployment of automated systems?", "2ed7e2e9-7c6f-401d-80ef-69c6eabf0cd6_2": "How can recalibration procedures contribute to the effectiveness of automated systems in varying contexts?", "828a4a33-7ba1-4355-b495-bc896d3d40bb_1": "What ethical considerations should be taken into account when conducting harm assessments for AI systems?  ", "828a4a33-7ba1-4355-b495-bc896d3d40bb_2": "How important is it to have fallback mechanisms in place for AI systems from an ethical standpoint?", "e11aabba-876b-4e5d-8dfd-683a21d02b81_1": "What factors should be considered when evaluating the performance of automated systems in AI ethics?  ", "e11aabba-876b-4e5d-8dfd-683a21d02b81_2": "Why is ongoing human-led monitoring important in the context of automated systems?", "dd8b8faa-b4a8-4812-b225-efceea41bb03_1": "What is the importance of having clear governance structures in AI deployment?  ", "dd8b8faa-b4a8-4812-b225-efceea41bb03_2": "Who should be responsible for overseeing the ongoing governance of AI systems?", "599faa13-2fc4-4e30-ab66-711fc52e54e2_1": "What role do organizational stakeholders play in the governance of AI systems?  ", "599faa13-2fc4-4e30-ab66-711fc52e54e2_2": "Why is it important for responsibility for AI oversight to rest high enough in the organization?", "a8d0fa93-f94d-46fc-8b7a-81a1a132bd33_1": "How can independent ethics reviews contribute to the fair deployment of AI systems?  ", "a8d0fa93-f94d-46fc-8b7a-81a1a132bd33_2": "What are the potential consequences of using low-quality or irrelevant data in AI risk identification procedures?", "6f5dcd2c-142a-4fc8-920b-0408006ce5b2_1": "Why is it important for data used in automated systems to be relevant and of high quality?", "6f5dcd2c-142a-4fc8-920b-0408006ce5b2_2": "How should the relevance of data for AI systems be established according to ethical guidelines?", "401393da-6a24-44d2-9b1c-2453ae9b31eb_1": "How can the quality and validity of data used in AI predictions impact ethical decision-making in automated systems?  ", "401393da-6a24-44d2-9b1c-2453ae9b31eb_2": "What measures can be implemented to limit errors in data entry that may affect the outcomes of AI systems?", "4c495844-5525-4cab-aca0-e3c7581aa4ad_1": "Why is it important to document the justification for each data attribute and source used in an automated system?  ", "4c495844-5525-4cab-aca0-e3c7581aa4ad_2": "How can the justification process help ensure compliance with applicable laws in the context of AI systems?", "c306f26c-02dd-4598-9ad5-2efab6ed561b_1": "What are the potential risks associated with using derived data in automated systems?", "c306f26c-02dd-4598-9ad5-2efab6ed561b_2": "Why is it important to track and identify derived data in the context of automated systems?", "5e260492-8376-4428-b409-2d6342289682_1": "What are the potential risks associated with data reuse in sensitive domains?  ", "5e260492-8376-4428-b409-2d6342289682_2": "How can collateral consequences be mitigated when reusing data in new contexts?", "ac776309-a022-4e73-80b1-43235cdf4a39_1": "What measures should be implemented to mitigate risks associated with the reuse of sensitive domain data in AI systems?", "ac776309-a022-4e73-80b1-43235cdf4a39_2": "Under what conditions is the reuse of sensitive data legally authorized in AI applications?", "2b264d72-b64d-4cd9-be29-ae642ae5b475_1": "How can aggregated datasets help mitigate privacy concerns in AI systems?  ", "2b264d72-b64d-4cd9-be29-ae642ae5b475_2": "Why is independent evaluation important for the safety and effectiveness of automated systems?", "c1919033-ef4b-4716-b2ac-4804490699bd_1": "What role do independent evaluators play in ensuring the ethical deployment of AI systems?", "c1919033-ef4b-4716-b2ac-4804490699bd_2": "How can access to AI systems for evaluation be structured to maintain independence and trustworthiness?", "bff772c4-5404-4e20-8222-33ec3537be57_1": "What type of information should entities provide in their reports about automated systems?", "bff772c4-5404-4e20-8222-33ec3537be57_2": "Why is it important for entities to regularly update their reports on automated systems?", "f16e15db-1f21-4726-9763-40a8a6dc2c20_1": "How does the organization ensure the ethical use of data in training machine learning models, particularly regarding data completeness and relevance?  ", "f16e15db-1f21-4726-9763-40a8a6dc2c20_2": "What measures are in place to address public concerns raised during consultations about the organization's AI systems?", "4390d731-2f14-4c4f-aaa1-919e1f9a0332_1": "How do error rates in AI systems vary across different demographic groups, and what implications does this have for ethical AI deployment?  ", "4390d731-2f14-4c4f-aaa1-919e1f9a0332_2": "What role does ongoing monitoring and regular performance testing play in ensuring the ethical use of AI systems?", "e1e1be7b-91cb-447f-9005-9404702eaf14_1": "What is the importance of independent evaluations in ensuring ethical AI practices?  ", "e1e1be7b-91cb-447f-9005-9404702eaf14_2": "How does reporting in plain language and machine-readable formats contribute to AI transparency?", "1adc9709-c6a6-41a8-b150-7caf0d836b02_1": "What are the nine principles outlined in Executive Order 13960 for the use of trustworthy AI in federal agencies?  ", "1adc9709-c6a6-41a8-b150-7caf0d836b02_2": "How can laws and policies ensure the protection of rights and opportunities in the deployment of AI systems?", "52093311-f2d4-4234-812c-b2d589a6027d_1": "What are the ethical considerations for the federal government when using AI in relation to national values?  ", "52093311-f2d4-4234-812c-b2d589a6027d_2": "How does the requirement for AI to be accurate, reliable, and effective relate to ethical standards in its deployment?", "ed7930bf-9528-4748-8549-518835584165_1": "How does the Blueprint for an AI Bill of Rights ensure accountability in AI systems?  ", "ed7930bf-9528-4748-8549-518835584165_2": "In what ways can strong safety regulations for motor vehicles inform the ethical development of AI technologies?", "f8de058e-1862-4e12-b132-0aafb363dc3b_1": "How does the National Highway Traffic Safety Administration balance safety standards with manufacturers' innovation in vehicle technology?  ", "f8de058e-1862-4e12-b132-0aafb363dc3b_2": "What role does independent evaluation play in ensuring the ethical deployment of AI in vehicle safety systems?", "d3a2c0bd-e970-495f-84f6-94b6a6c34514_1": "How do local rules and contextually appropriate requirements contribute to the ethical deployment of AI systems?  ", "d3a2c0bd-e970-495f-84f6-94b6a6c34514_2": "What role do risk assessments and auditing mechanisms play in ensuring the safety and efficacy of AI systems?", "690c57f5-80a0-4731-986f-16b098030aad_1": "How can companies mitigate risks to their reputation when using AI technologies?  ", "690c57f5-80a0-4731-986f-16b098030aad_2": "What role does stakeholder engagement play in addressing legal responsibilities related to AI use?", "9554f69c-8ed8-489e-b75b-15d50b2a613d_1": "How does the NIST AI Risk Management Framework aim to enhance trustworthiness in AI systems?  ", "9554f69c-8ed8-489e-b75b-15d50b2a613d_2": "What role does stakeholder engagement play in the development of AI ethics frameworks, as illustrated by the examples provided?", "9060fdba-e234-4794-9afb-01a585a090b8_1": "How does the NIST framework ensure transparency in the evaluation of AI products and services?  ", "9060fdba-e234-4794-9afb-01a585a090b8_2": "What role does stakeholder collaboration play in the development of the NIST framework for AI ethics?", "8acf607f-6f26-4ef3-b9f5-45a10b9ef91b_1": "What characteristics of trustworthiness are essential for AI technologies according to the NIST framework?  ", "8acf607f-6f26-4ef3-b9f5-45a10b9ef91b_2": "How does the NIST framework address the mitigation of unintended and harmful bias in AI systems?", "c500fae5-e08d-499a-8459-ae483ab98017_1": "How can government frameworks for ethical AI use, such as those developed by the Department of Energy, influence the protection of rights and opportunities?  ", "c500fae5-e08d-499a-8459-ae483ab98017_2": "What role does the AI Advancement Council play in addressing ethical issues related to AI systems within the Department of Energy?", "0b241eff-f114-4a94-981b-0a8d35ebf737_1": "What ethical principles are emphasized for responsible artificial intelligence in national security and defense activities?  ", "0b241eff-f114-4a94-981b-0a8d35ebf737_2": "How has the U.S. Intelligence Community addressed the ethical considerations of artificial intelligence?", "475c60ab-d40e-4a79-aa69-368b1cf12a0e_1": "What principles guide the development and use of AI within the Intelligence Community according to the AI Ethics Framework?  ", "475c60ab-d40e-4a79-aa69-368b1cf12a0e_2": "How does the National Science Foundation contribute to the advancement of safe and trustworthy AI systems?", "10447d1e-046b-40db-9761-b4c52af2c271_1": "How does the Secure and Trustworthy Cyberspace program address ethical concerns related to privacy in autonomous systems?  ", "10447d1e-046b-40db-9761-b4c52af2c271_2": "What role do cybersecurity measures play in ensuring the ethical deployment of AI components in cyber-physical systems?", "525ff882-b6fc-471e-a237-2508c911df29_1": "How do formal verification methods contribute to the ethical use of automated systems in pretrial risk assessments?  ", "525ff882-b6fc-471e-a237-2508c911df29_2": "What role do transparency and validity requirements play in ensuring the ethical application of algorithmic pretrial risk assessments?", "a8b81568-9cb4-4620-839d-6480e10c3ded_1": "What measures must a locality take to ensure that a pretrial risk assessment is free of bias?", "a8b81568-9cb4-4620-839d-6480e10c3ded_2": "How does the requirement for formal validation of pretrial risk assessments relate to the protection of individuals from discrimination?", "3f62044a-91fb-43d1-8328-7258d1bb377f_1": "How does the requirement for public inspection of risk assessment information impact transparency in AI systems?  ", "3f62044a-91fb-43d1-8328-7258d1bb377f_2": "What are the ethical implications of allowing trade secrets to be used as a defense against discovery in criminal cases involving AI?", "9dd6783b-aef1-446f-aca5-174fe2733d29_1": "What constitutes algorithmic discrimination according to the provided context?  ", "9dd6783b-aef1-446f-aca5-174fe2733d29_2": "How can automated systems be designed to prevent algorithmic discrimination?", "96cc9754-62b9-4888-b353-41a418ee394a_1": "What measures should deployers of automated systems take to prevent algorithmic discrimination?  ", "96cc9754-62b9-4888-b353-41a418ee394a_2": "How can the design of automated systems promote equity in their use?", "311b5744-c4f0-4ad3-b85f-e9ce94e2a4ae_1": "How can the use of representative data in AI system design help mitigate ethical concerns related to bias?  ", "311b5744-c4f0-4ad3-b85f-e9ce94e2a4ae_2": "What role does independent evaluation play in ensuring ethical standards in AI development?", "cc4d0423-7f61-4e50-9f5a-db28947eeaeb_1": "What are some examples of automated systems that can produce inequitable outcomes?  ", "cc4d0423-7f61-4e50-9f5a-db28947eeaeb_2": "How can systemic biases in data affect the outcomes of algorithmic decision-making?", "9d1a63ee-1798-42df-bf1b-9243a354eee2_1": "How can AI systems contribute to discriminatory practices affecting Black Americans in healthcare?  ", "9d1a63ee-1798-42df-bf1b-9243a354eee2_2": "What are the ethical implications of using AI in industries where discriminatory practices may arise?", "a7db17a0-0844-42e2-bd83-98531aa2146f_1": "What measures are being taken to protect the public from algorithmic discrimination in AI systems?  ", "a7db17a0-0844-42e2-bd83-98531aa2146f_2": "How can bias testing influence the development and launch of AI products?", "ec1cc028-c6b5-4ed3-8ead-795e8b203bed_1": "What practices can be implemented to identify potential algorithmic discrimination in AI systems?  ", "ec1cc028-c6b5-4ed3-8ead-795e8b203bed_2": "How can transparency be ensured to the public in the mitigation of biases in AI algorithms?", "603b8fca-56e9-45da-a574-61838e07c474_1": "What are the key areas of life where algorithmic discrimination needs to be addressed to ensure equitable treatment?", "603b8fca-56e9-45da-a574-61838e07c474_2": "Why is it important to consider the holistic impact of automated systems on individuals' lives in the context of AI ethics?", "eeabe14f-572d-4d36-85f1-71cf7a135b3e_1": "What are the potential ethical implications of using nontraditional factors like educational attainment and employment history in automated systems for underserved communities?  ", "eeabe14f-572d-4d36-85f1-71cf7a135b3e_2": "How can proactive protections be implemented to support underserved communities affected by automated systems?", "ccfb41a6-06a6-4fee-b3c1-b70941cef395_1": "How does the use of biased data in loan underwriting models impact the fairness of financial services for applicants from HBCUs?  ", "ccfb41a6-06a6-4fee-b3c1-b70941cef395_2": "What ethical concerns arise from hiring tools that discriminate against women based on biased training data?", "c495760e-bd11-4d71-9b4d-648374fb9be3_1": "What ethical concerns arise from using race as a predictor in AI models used by universities?  ", "c495760e-bd11-4d71-9b4d-648374fb9be3_2": "How do disparities in AI predictions based on race impact the fairness of educational opportunities for students?", "6cbc7310-fad5-4058-9ab8-d9bc441034de_1": "How can risk assessment tools in education and criminal justice contribute to systemic bias against marginalized groups?", "6cbc7310-fad5-4058-9ab8-d9bc441034de_2": "What measures can be taken to ensure that AI tools do not perpetuate racial disparities in risk predictions?", "29ef6af6-d911-464f-850a-2881c349bb97_1": "What ethical considerations should be taken into account when reviewing AI tools?  ", "29ef6af6-d911-464f-850a-2881c349bb97_2": "How can transparency in AI tool reviews impact public trust?", "ba38e80a-f524-42bf-b718-7523d101d31d_1": "What ethical issues arise from the biased outcomes of automated sentiment analyzers in relation to marginalized groups?", "ba38e80a-f524-42bf-b718-7523d101d31d_2": "How can technology platforms address the risks of bias in AI tools like sentiment analyzers to ensure fair treatment of all individuals?", "16896240-a88f-4095-950e-064720eb2ed4_1": "How does making data public contribute to ethical research practices in AI?  ", "16896240-a88f-4095-950e-064720eb2ed4_2": "What role do reports identifying and measuring issues play in promoting transparency in AI development?", "fce722e6-04a3-4c23-b66d-fa86b3e5ac2a_1": "How do search engine results for specific racial and gender groups contribute to the sexualization of those groups in society?", "fce722e6-04a3-4c23-b66d-fa86b3e5ac2a_2": "In what ways do advertisement delivery systems perpetuate racial and gender stereotypes in job opportunities?", "24ca8649-3a2a-4911-9c22-7a26feb8f32c_1": "How do gender identity perceptions in security scanning settings impact the treatment of transgender travelers?  ", "24ca8649-3a2a-4911-9c22-7a26feb8f32c_2": "What ethical concerns arise from using operators' perceptions of gender identity in security screening processes?", "56b4723a-5f37-4433-8284-3a2f6af98581_1": "How can the implementation of a gender-neutral algorithm by TSA address potential biases in security screenings?  ", "56b4723a-5f37-4433-8284-3a2f6af98581_2": "What ethical concerns arise from AI systems flagging individuals with disabilities as potentially suspicious due to their access needs?", "60e3c0f6-359c-4e72-aa39-9bc6946a011f_1": "How do healthcare clinical algorithms ensure fairness when guiding clinical decisions for patients with similar health conditions?  ", "60e3c0f6-359c-4e72-aa39-9bc6946a011f_2": "What ethical considerations arise from the use of clinical algorithms in healthcare decision-making?", "bc4b39dd-5dea-44a1-96e2-58bc872d03ab_1": "How can sociodemographic variables in algorithms contribute to race-based health inequities?  ", "bc4b39dd-5dea-44a1-96e2-58bc872d03ab_2": "What are the implications of algorithmic discrimination protections in healthcare settings?", "84ca0df8-85b1-45a3-8c9e-79b373987623_1": "What proactive steps should be taken to ensure automated systems are free from algorithmic discrimination?", "84ca0df8-85b1-45a3-8c9e-79b373987623_2": "How do existing anti-discrimination laws relate to the expectations for automated systems?", "5dff4530-1ff6-4a3f-b9e7-3e75aab0fb1c_1": "How can AI systems be designed to ensure equity for underserved communities beyond existing legal protections?  ", "5dff4530-1ff6-4a3f-b9e7-3e75aab0fb1c_2": "What role do legal protections play in shaping ethical AI practices for marginalized groups?", "8e8cf8c6-0d64-4a12-8671-01ab73aabda5_1": "What measures should be taken to protect the public from algorithmic discrimination during the design phase of automated systems?  ", "8e8cf8c6-0d64-4a12-8671-01ab73aabda5_2": "Why is it important to conduct proactive equity assessments in the development of automated technologies?", "55480cb7-a3d5-4f14-af37-7ead5662435c_1": "How does the introduction of the technology impact equity among underserved communities such as Black, Latino, and Indigenous groups?  ", "55480cb7-a3d5-4f14-af37-7ead5662435c_2": "What measures can be taken to ensure that the effects of the technology on equity are assessed inclusively?", "2f9ab334-4d57-4956-823b-9eab20ca50ed_1": "How can equity assessments in AI systems ensure the inclusion of marginalized groups such as persons of color and LGBTQI+ individuals?  ", "2f9ab334-4d57-4956-823b-9eab20ca50ed_2": "What role does representative and robust data play in the ethical development and assessment of AI systems?", "c892c84a-441a-4446-8d33-32482d0268bd_1": "How can bias in AI systems be identified and mitigated based on the historical and societal context of the data used?  ", "c892c84a-441a-4446-8d33-32482d0268bd_2": "Why is it important to involve representatives of local communities in the review process of AI deployment?", "fb52d600-4eb2-4e60-8460-2a0b715b901b_1": "What are the risks associated with directly using demographic information in automated systems?  ", "fb52d600-4eb2-4e60-8460-2a0b715b901b_2": "How can reliance on proxies in decision-making contribute to algorithmic discrimination?", "ecc7f906-cf45-4cdb-9805-4ca65d930bd3_1": "What is the significance of proactive testing in identifying proxies in AI systems?", "ecc7f906-cf45-4cdb-9805-4ca65d930bd3_2": "How can demographic information influence the ethical implications of AI algorithms?", "4c5dc65b-62aa-49c5-aa0c-034a5acea392_1": "What steps should organizations take to address the issue of algorithmic discrimination in AI systems?  ", "4c5dc65b-62aa-49c5-aa0c-034a5acea392_2": "How can designers and developers identify and mitigate the impact of proxy features in AI algorithms?", "8f8d9ed7-e52a-45fe-b9dc-06dec8ed9b77_1": "How should organizations ensure accessibility in the design and deployment of automated systems for people with disabilities?  ", "8f8d9ed7-e52a-45fe-b9dc-06dec8ed9b77_2": "What role do user experience research and adherence to accessibility standards play in the development of automated systems?", "b0c6c6e4-2da0-49ec-8eba-d0c7e804bc63_1": "What measures should be used to assess disparities in automated systems during pre-deployment testing?", "b0c6c6e4-2da0-49ec-8eba-d0c7e804bc63_2": "Why is it important to evaluate disparities in both pre-deployment testing and in-context deployment of automated systems?", "bf1251e9-dc28-4c1c-9027-614b6b041c98_1": "How can inclusive demographic assessments contribute to reducing bias in AI systems?", "bf1251e9-dc28-4c1c-9027-614b6b041c98_2": "What ethical considerations arise from separating demographic data used for disparity assessment from data used in automated systems?", "4661cc35-825c-433f-9cb2-5dce09a5221e_1": "What should entities do if an automated system leads to different treatment of identified groups?  ", "4661cc35-825c-433f-9cb2-5dce09a5221e_2": "Why is it important to document disparities caused by automated systems?", "470c75c6-cd81-478b-b24e-7b8e3dd87d24_1": "What steps should be taken to mitigate disparities identified in an automated system to prevent algorithmic discrimination?  ", "470c75c6-cd81-478b-b24e-7b8e3dd87d24_2": "Why is it important to evaluate multiple models when designing an automated system?", "027a71e7-8f08-425c-a75f-21f0d2686848_1": "What should be considered when determining the validity of an automated system in the context of disparities?  ", "027a71e7-8f08-425c-a75f-21f0d2686848_2": "Under what circumstances should the use of an automated system be reconsidered in relation to disparities?", "7f80c238-3fc8-442d-b4d8-8b6951453847_1": "What are the potential consequences of using unobservable targets in AI systems?", "7f80c238-3fc8-442d-b4d8-8b6951453847_2": "Why is ongoing monitoring important for preventing algorithmic discrimination in automated systems?", "eef2691e-1cc7-48ed-b137-4715e94324d4_1": "What is the importance of regularly assessing automated systems for algorithmic discrimination?  ", "eef2691e-1cc7-48ed-b137-4715e94324d4_2": "How can unusual patterns in data indicate potential algorithmic discrimination in automated systems?", "fdded924-58f7-401a-bec9-ca76d9ec82b3_1": "How should demographic information be utilized in assessing the equity of AI systems?", "fdded924-58f7-401a-bec9-ca76d9ec82b3_2": "What actions should be taken if an AI system fails to meet equity standards during assessment?", "f0f9e11f-6729-473c-ab75-1c62e99d705a_1": "What measures should be taken to ensure that automated systems protect against algorithmic discrimination?", "f0f9e11f-6729-473c-ab75-1c62e99d705a_2": "Why is independent evaluation important for the ethical oversight of automated systems in the public sector?", "a986561a-360e-48e7-beb9-87037aa7cd47_1": "How can policy-based innovations help ensure privacy while allowing access to evaluation data?  ", "a986561a-360e-48e7-beb9-87037aa7cd47_2": "What role do technological controls play in balancing data access needs with privacy concerns?", "ec31d62b-7e61-4ed9-b789-1c9702ab5e86_1": "What key components should be included in an algorithmic impact assessment according to the context provided?  ", "ec31d62b-7e61-4ed9-b789-1c9702ab5e86_2": "Why is it important for the algorithmic impact assessment to be made public?", "ead55ff2-d1e6-4be6-8dc6-928bd07db5e8_1": "How can clear and machine-readable reporting enhance public accountability in AI systems?  ", "ead55ff2-d1e6-4be6-8dc6-928bd07db5e8_2": "What measures can be implemented to protect against algorithmic discrimination in AI?", "34e252d7-c874-4327-89f3-30eeac1b5ee3_1": "How can federal initiatives like the one launched by the Department of Justice help address discrimination in AI-driven lending practices?  ", "34e252d7-c874-4327-89f3-30eeac1b5ee3_2": "What role do laws and policies play in ensuring that AI technologies promote equitable access to financial services?", "e41566f6-9a2d-47ed-b372-d0b820bad2d4_1": "How does the Action Plan to Advance Property Appraisal and Valuation Equity address potential biases in Automated Valuation Models?  ", "e41566f6-9a2d-47ed-b372-d0b820bad2d4_2": "What role do prudential regulators play in ensuring nondiscrimination standards in mortgage lending practices?", "5ef66507-d7c7-40c2-9289-49e5da0ecfe2_1": "How can the use of AI in hiring processes lead to discrimination against individuals with disabilities under the ADA?", "5ef66507-d7c7-40c2-9289-49e5da0ecfe2_2": "What steps can employers take to ensure compliance with the ADA when using algorithmic decision-making systems?", "70d312e2-f894-4c1d-a040-551ad2f77bce_1": "How did the healthcare algorithm's reliance on past medical care costs contribute to discrimination in patient care?  ", "70d312e2-f894-4c1d-a040-551ad2f77bce_2": "What ethical concerns arise from using cost-based predictions in healthcare algorithms?", "e1f0b86a-6aea-46a8-9a60-ccd7898b473e_1": "How can algorithmic bias in healthcare impact the treatment of Black patients compared to white patients?  ", "e1f0b86a-6aea-46a8-9a60-ccd7898b473e_2": "What measures can businesses take to mitigate algorithmic bias in hiring practices?", "4f92e1d1-c593-412c-94cd-1386429cf49c_1": "What are the identified biases in AI models, and what mitigation steps have been employed to address them?  ", "4f92e1d1-c593-412c-94cd-1386429cf49c_2": "How do standards organizations' guidelines incorporate accessibility criteria in AI development?", "3b5de4a3-2641-4153-a259-a68f706b139a_1": "How do the Access Board\u2019s Section 508 regulations contribute to ethical considerations in AI technology design?  ", "3b5de4a3-2641-4153-a259-a68f706b139a_2": "What role does NIST's Special Publication 1270 play in addressing bias in artificial intelligence?", "1e7debda-9c18-4cc9-814b-19b1db54e4b9_1": "What are the three categories of bias in AI that can contribute to harms?  ", "1e7debda-9c18-4cc9-814b-19b1db54e4b9_2": "How can AI undermine public trust?", "8941f80b-a71d-479f-8357-03ad122aa90d_1": "What are the three broad challenges for mitigating bias in AI as described in the context?  ", "8941f80b-a71d-479f-8357-03ad122aa90d_2": "How does the socio-technical perspective contribute to identifying and managing AI bias?", "5fc30f25-9335-4bfc-b5e5-8b5cae07975b_1": "What are the key principles that should guide the design of automated systems to protect user data?", "5fc30f25-9335-4bfc-b5e5-8b5cae07975b_2": "How should designers and developers ensure that users have agency over their data in automated systems?", "220d232d-3757-40bd-9588-e757400f2ed5_1": "How should user experience design prioritize user choice in relation to data privacy?  ", "220d232d-3757-40bd-9588-e757400f2ed5_2": "Under what circumstances is it ethical to use consent as a justification for data collection?", "6b0ac03e-f44d-4868-a741-80cb6dc7296b_1": "What are the key requirements for consent requests related to data collection in AI ethics?", "6b0ac03e-f44d-4868-a741-80cb6dc7296b_2": "Why is it important to have enhanced protections for data related to sensitive domains such as health and education?", "bb65b911-cb4a-4ab2-915d-e9f975f33586_1": "What measures should be implemented to ensure that surveillance technologies do not infringe on privacy and civil liberties?  ", "bb65b911-cb4a-4ab2-915d-e9f975f33586_2": "Why is it important to conduct pre-deployment assessments of surveillance technologies?", "5fb441cd-74d2-4a60-8a18-528ce7122a5c_1": "What are the potential risks of using surveillance technologies in education and work environments?", "5fb441cd-74d2-4a60-8a18-528ce7122a5c_2": "Why is it important to have access to reporting that confirms data decisions have been respected?", "3e409470-ef0d-43c8-9078-242397bef7ce_1": "Why is data privacy considered a foundational principle in the context of AI ethics?  ", "3e409470-ef0d-43c8-9078-242397bef7ce_2": "What are the potential ethical implications of companies tracking and profiling individuals based on their data?", "62c7f759-9cb8-4901-b188-1f5a6a3383a1_1": "How do enhanced surveillance capabilities by law enforcement agencies impact individual privacy rights?  ", "62c7f759-9cb8-4901-b188-1f5a6a3383a1_2": "What ethical considerations arise from the use of technology that collects data for surveillance purposes?", "e5d65906-f021-4a13-a6c8-1872aee38996_1": "How does the lack of federal law regarding private data collection impact individual privacy rights?", "e5d65906-f021-4a13-a6c8-1872aee38996_2": "What ethical concerns arise from the use of inaccurate data in decision-making processes that affect people's lives?", "5c96aa32-1661-4120-ad69-d39e8078e14f_1": "How can the use of AI technologies in schools and workplaces be managed to mitigate mental health harms?  ", "5c96aa32-1661-4120-ad69-d39e8078e14f_2": "What ethical considerations should be taken into account when implementing AI technologies that impact mental health in educational and professional settings?", "d4b3b7ec-6902-4416-9a54-1256fae020c6_1": "How does the aggregation of personal data by data brokers contribute to mental health issues in communities?  ", "d4b3b7ec-6902-4416-9a54-1256fae020c6_2": "What measures can companies implement to protect consumer privacy in response to the risks associated with data harvesting?", "bba97538-3a78-4be9-bee1-81cefd7e7bf6_1": "How do legal protections govern the collection and use of data in relation to civil liberties?  ", "bba97538-3a78-4be9-bee1-81cefd7e7bf6_2": "What role do improved security practices play in the ethical management of data collection by the federal government?", "c3c68ad8-ef3a-4d32-a617-33b56e18d825_1": "What are the implications of the lack of a comprehensive regulatory framework for personal data protection in the United States on AI ethics?", "c3c68ad8-ef3a-4d32-a617-33b56e18d825_2": "How do existing consumer data privacy protection regimes address the ethical concerns related to automated systems monitoring public activities?", "0581c2b2-5c4d-491e-b8e2-44bf8fae2a05_1": "What ethical concerns arise from collecting information on individuals without their consent?  ", "0581c2b2-5c4d-491e-b8e2-44bf8fae2a05_2": "How does the lack of legal authority impact the ethical implications of surveillance practices?", "430134fc-390d-4594-af75-468053ae0d63_1": "How does the collection of personal data from social media by insurers raise ethical concerns regarding data privacy?  ", "430134fc-390d-4594-af75-468053ae0d63_2": "What are the potential ethical implications of a data broker suffering a breach that exposes personal data to identity theft?", "3e8ab056-45e3-44aa-9ae8-598391fe320f_1": "What ethical concerns arise from the use of facial recognition software by local police on videos from the community?  ", "3e8ab056-45e3-44aa-9ae8-598391fe320f_2": "How does the sharing of community videos with law enforcement impact individual privacy rights?", "7820dd1c-b91f-4d5a-9797-8e03b791798e_1": "What ethical concerns arise from companies using surveillance software to monitor employee discussions about union activity?  ", "7820dd1c-b91f-4d5a-9797-8e03b791798e_2": "How does the use of surveillance software to track employee discussions impact the right to privacy in the workplace?", "95e71866-dd41-4c03-8e47-03785df2f0d9_1": "What are the key expectations for automated systems regarding data privacy?", "95e71866-dd41-4c03-8e47-03785df2f0d9_2": "Why are traditional terms of service considered inadequate for protecting privacy in automated systems?", "1f185603-4a6b-4da7-9125-cb9f26353814_1": "How should automated systems ensure they meet expectations for collecting and using personal data?  ", "1f185603-4a6b-4da7-9125-cb9f26353814_2": "What does it mean to protect privacy by design and by default in the context of AI systems?", "f7553446-3508-4029-a051-79609e731f77_1": "How can automated systems ensure privacy is protected by default during their development?  ", "f7553446-3508-4029-a051-79609e731f77_2": "What measures should be taken to assess and mitigate privacy risks in automated systems?", "602e81cb-3dc4-4ab1-a349-1b080c24381d_1": "What ethical considerations must be taken into account when collecting data for training machine learning models?  ", "602e81cb-3dc4-4ab1-a349-1b080c24381d_2": "How should the expectations of individuals whose data is collected influence the use of that data in AI development?", "ca02d308-3272-408e-933d-6a6d1ed8203d_1": "What is the importance of ensuring that individuals understand what data is being collected about them in the context of AI ethics?  ", "ca02d308-3272-408e-933d-6a6d1ed8203d_2": "How can organizations prevent \"mission creep\" in their data collection practices according to ethical guidelines?", "289b8b06-49a6-45b5-a48c-93c990252809_1": "Why is it important to establish clear timelines for data retention in the context of AI ethics?  ", "289b8b06-49a6-45b5-a48c-93c990252809_2": "How does documenting and justifying data retention timelines contribute to ethical AI practices?", "835dfd47-b745-430a-83c8-cdb328fde0f0_1": "What measures should entities implement to mitigate privacy risks associated with sensitive data?", "835dfd47-b745-430a-83c8-cdb328fde0f0_2": "Why is it inappropriate for entities to transfer privacy risks to users through notice or consent requests?", "cafbdf81-f1b5-4945-810d-e10e48132be9_1": "What are some best practices for ensuring data privacy in AI applications?  ", "cafbdf81-f1b5-4945-810d-e10e48132be9_2": "How can privacy-enhancing cryptography contribute to data security in AI systems?", "1d058472-4335-4e50-80c8-0b02499fa382_1": "How do privacy-enhancing technologies contribute to ethical AI practices?  ", "1d058472-4335-4e50-80c8-0b02499fa382_2": "What role do fine-grained permissions and access control mechanisms play in ensuring user privacy in AI systems?", "2c886e68-248f-44ab-a137-bebe1bbc4b90_1": "What measures should be taken to ensure heightened oversight of surveillance systems before their deployment?  ", "2c886e68-248f-44ab-a137-bebe1bbc4b90_2": "How can automated systems be designed to protect the public from potential harms associated with unchecked surveillance?", "02a26c28-7802-4101-a4c9-6f21c83fa025_1": "How can ongoing assessments help prevent algorithmic discrimination in AI systems?  ", "02a26c28-7802-4101-a4c9-6f21c83fa025_2": "Why is it important to evaluate AI systems for discrimination based on community membership?", "92f8795c-a8f8-441a-8d0f-a9e11840a3d6_1": "What principles should guide the design and deployment of surveillance systems to ensure ethical use?  ", "92f8795c-a8f8-441a-8d0f-a9e11840a3d6_2": "How should individuals be informed about surveillance practices according to ethical guidelines?", "7e9d066f-08d2-4094-ba40-0b4a7e51d990_1": "How can surveillance systems be designed to protect civil liberties while still ensuring security?  ", "7e9d066f-08d2-4094-ba40-0b4a7e51d990_2": "What are the ethical implications of using automated systems for monitoring democratic processes like voting?", "04802aba-c172-4119-a321-1b9391d4733d_1": "How can the use of identity-related information in surveillance systems lead to algorithmic discrimination?  ", "04802aba-c172-4119-a321-1b9391d4733d_2": "What are the ethical implications of using continuous surveillance in workplaces and public education settings?", "00faaef0-e776-484d-a329-07a7d085de24_1": "How can continuous surveillance systems impact individuals' access to critical resources or services?  ", "00faaef0-e776-484d-a329-07a7d085de24_2": "What ethical considerations should organizations take into account when implementing monitoring systems?", "cb2cf1b0-d4c1-4deb-a6b3-af1743ecef7f_1": "How should consent practices be structured to prevent abusive surveillance in AI systems?  ", "cb2cf1b0-d4c1-4deb-a6b3-af1743ecef7f_2": "What are the key conditions that must be met for consent to remain valid in the context of data usage?", "811b47c1-c491-4e11-b1cf-fde37a1d35e9_1": "What ethical considerations should be taken into account when designing consent requests for AI systems?  ", "811b47c1-c491-4e11-b1cf-fde37a1d35e9_2": "How can AI systems ensure that users can refuse consent without facing adverse effects?", "a46adb8f-f78a-466e-8c6d-b4296c849ca8_1": "How should consent requests be designed to ensure users understand the context and implications of their data sharing?", "a46adb8f-f78a-466e-8c6d-b4296c849ca8_2": "What ethical considerations should be taken into account to avoid the use of \"dark patterns\" in user consent requests?", "a1c3f7a7-f72f-48e4-9364-6583bd972bc0_1": "What are the expectations for individuals regarding access to their data in automated systems?  ", "a1c3f7a7-f72f-48e4-9364-6583bd972bc0_2": "How should entities handle consent withdrawal and data deletion in relation to automated systems?", "3bc83b38-a0a2-480c-9107-84a200b23a90_1": "What ethical considerations arise from the withdrawal of data access consent in relation to user privacy?  ", "3bc83b38-a0a2-480c-9107-84a200b23a90_2": "How should organizations ensure the timely removal of user data from machine learning models after consent is withdrawn?", "8e35abe2-146d-4b6d-a89f-85a1622e77e9_1": "How can entities ensure that individuals have control over their automated systems in a complex data ecosystem?", "8e35abe2-146d-4b6d-a89f-85a1622e77e9_2": "What role does independent evaluation play in protecting data privacy and user control in automated systems?", "6477776e-d4bc-468e-9eb0-a0344590fb46_1": "How can independent evaluations of data policies ensure transparency while protecting individual privacy?  ", "6477776e-d4bc-468e-9eb0-a0344590fb46_2": "What are the ethical implications of making independent evaluations of data policies public?", "f2f97beb-ab11-4a13-aab0-c1a3801e7fbf_1": "What are the key components that should be included in a report provided to individuals about their data usage in a system?", "f2f97beb-ab11-4a13-aab0-c1a3801e7fbf_2": "Why is it important for the report on data usage to be machine-readable and understandable by most users?", "ca9d3ce6-52e5-4793-8b80-15470d1b6649_1": "How does identity verification contribute to user privacy in the context of AI reporting?  ", "ca9d3ce6-52e5-4793-8b80-15470d1b6649_2": "Why is it important to make summary reporting about data usage and access public?", "31db808a-c9b8-41cd-8ae6-486da8608489_1": "What are the key components that should be included in a surveillance pre-deployment assessment to ensure ethical data collection?  ", "31db808a-c9b8-41cd-8ae6-486da8608489_2": "Why is it important for the assessment of the impact of surveillance or data collection to be conducted by an independent party?", "27e57bb0-1c08-4180-85cb-d66d23396007_1": "Why are certain domains, such as health and education, considered sensitive and deserving of enhanced data protections?", "27e57bb0-1c08-4180-85cb-d66d23396007_2": "How do technological developments influence the public's understanding of what constitutes sensitive data domains?", "df5e4bff-4d76-426b-8243-be141247b730_1": "What are the potential inadequacies of current legal guidelines in protecting sensitive data related to AI?  ", "df5e4bff-4d76-426b-8243-be141247b730_2": "Why is it important for the American public to have assurances regarding the protection and appropriate use of sensitive data in AI?", "582b6172-deda-47f4-89fe-fbedf6626275_1": "What additional expectations should automated systems meet when handling sensitive data related to individuals?", "582b6172-deda-47f4-89fe-fbedf6626275_2": "Why is it important to have narrowly defined contexts for the use of automated systems in sensitive domains?", "0726c866-76ba-46af-a279-d3a7b89276e2_1": "What are the potential ethical implications of using custody and divorce information in AI systems?  ", "0726c866-76ba-46af-a279-d3a7b89276e2_2": "How can AI systems mitigate the risks of exposing individuals to meaningful harm, such as loss of privacy or financial harm?", "22919863-ac88-4830-923d-96448d4e7a87_1": "What types of data are considered sensitive when it comes to individuals who are not yet legal adults?  ", "22919863-ac88-4830-923d-96448d4e7a87_2": "Why are enhanced data protections necessary in sensitive domains related to human rights?", "d67356ca-c226-4a81-af3a-f58c97f2c835_1": "How does the sensitivity of domains like education, criminal justice, and personal finance impact the ethical considerations of AI deployment in these areas?  ", "d67356ca-c226-4a81-af3a-f58c97f2c835_2": "What ethical implications arise from the use of AI in sensitive domains, regardless of existing legal frameworks?", "48e5418d-9fcb-4e41-bba9-adabb44736ff_1": "How do societal norms influence the classification of sensitive data in AI ethics?  ", "48e5418d-9fcb-4e41-bba9-adabb44736ff_2": "In what ways can the changing nature of sensitive data impact AI decision-making processes?", "c3e89a77-6d74-42ea-8c95-29b74c56146d_1": "What ethical concerns arise from the use of medical data by insurance companies without patient consent?  ", "c3e89a77-6d74-42ea-8c95-29b74c56146d_2": "How does the use of predictive analytics in consumer data raise issues of privacy and consent, particularly in sensitive situations?", "47bde0f7-5a8a-44cb-9b21-2d284bf1feba_1": "What ethical concerns arise from the use of audio surveillance systems in schools to monitor student conversations?  ", "47bde0f7-5a8a-44cb-9b21-2d284bf1feba_2": "How do online proctoring systems balance the need for academic integrity with student privacy rights?", "ad61bff8-771e-4a84-b01c-212ea183c0eb_1": "How might the use of biometric markers in exams impact the emotional expression of students?", "ad61bff8-771e-4a84-b01c-212ea183c0eb_2": "What ethical concerns arise from the collection of sensitive student data for forecasting success?", "408348ef-38a3-4de3-b1f3-22c4e9aa7158_1": "What ethical concerns arise from the use of sensitive data without express parental consent in AI systems?  ", "408348ef-38a3-4de3-b1f3-22c4e9aa7158_2": "How does the lack of transparency in data usage contribute to potential discriminatory impacts in AI applications?", "30731cfd-0d5c-4f12-8e21-3a22a58f0b01_1": "How can the use of AI in background checks impact an individual's employment opportunities?  ", "30731cfd-0d5c-4f12-8e21-3a22a58f0b01_2": "What ethical considerations arise when companies provide inaccurate data about employees to third parties?", "12c2ede9-108a-4057-8328-96d31f41307c_1": "What are the expectations for automated systems regarding the handling of sensitive data?  ", "12c2ede9-108a-4057-8328-96d31f41307c_2": "Why is it important to acquire consent from a guardian and/or child when dealing with sensitive data in automated systems?", "fabad0c7-5c2e-4821-8bd7-039c4cddfd59_1": "What are the ethical implications of using sensitive data only for necessary functions in AI systems?  ", "fabad0c7-5c2e-4821-8bd7-039c4cddfd59_2": "How should organizations determine what constitutes a \"necessary function\" for the use of sensitive data in AI?", "7c806454-5881-4ab0-8a60-fdbb9b42cb2e_1": "What ethical considerations should be taken into account when acquiring consent for non-necessary functions in AI systems?  ", "7c806454-5881-4ab0-8a60-fdbb9b42cb2e_2": "How should sensitive data be handled to ensure that it does not limit individuals' rights, opportunities, or access?", "3448d00b-754c-4d34-8ea3-e6ccd31b4e8a_1": "What role does an independent ethics committee play in the ethical review of AI systems?  ", "3448d00b-754c-4d34-8ea3-e6ccd31b4e8a_2": "Under what circumstances might data not be used or shared despite having consent?", "76fb387d-2fba-450e-9fb4-e8bbe63f306a_1": "What ethical considerations should be taken into account when conducting human subject experimentation with dynamically developing algorithms?  ", "76fb387d-2fba-450e-9fb4-e8bbe63f306a_2": "Why is maintaining data quality particularly important in sensitive domains related to AI decision-making?", "8c1427f1-545d-4fe7-a656-9cb5a91f3c24_1": "What role should entities play in ensuring the accuracy and completeness of data used in AI systems for prevention and law enforcement?  ", "8c1427f1-545d-4fe7-a656-9cb5a91f3c24_2": "Why is it important for entities to conduct regular, independent audits of data in the context of AI ethics?", "c642e842-06e9-4526-9466-3da15fd1a631_1": "What principles should guide access to sensitive data in AI systems?", "c642e842-06e9-4526-9466-3da15fd1a631_2": "Why is it important to limit the sharing of sensitive data in AI applications?", "f2ef7556-455a-4cfa-b8ec-c36eabbb529a_1": "What ethical considerations should entities developing technologies in sensitive domains take into account regarding data privacy?  ", "f2ef7556-455a-4cfa-b8ec-c36eabbb529a_2": "How should organizations ensure the responsible handling of sensitive data they collect, use, store, or share?", "eb19e38f-c333-425b-8c94-ccc6a3f3b35c_1": "What types of data security lapses should be reported to ensure transparency in AI ethics?  ", "eb19e38f-c333-425b-8c94-ccc6a3f3b35c_2": "How can organizations assess data to determine it does not present a sensitive data risk before sharing or selling it?", "909121a0-809a-4703-997b-534ec295bfe2_1": "How does the Privacy Act of 1974 exemplify the principle of limiting data retention in the context of AI ethics?  ", "909121a0-809a-4703-997b-534ec295bfe2_2": "In what ways can laws and policies, like the Privacy Act, enhance individual rights and access to personal data in AI systems?", "8832388e-f791-4346-85ab-5c50265f977b_1": "How does the Privacy Act define the criteria for data retention by federal agencies?  ", "8832388e-f791-4346-85ab-5c50265f977b_2": "What implications does the Privacy Act have for the ethical use of AI in federal agencies?", "5cb384b0-7012-438f-a9be-5f10428e5e18_1": "How does the Privacy Act ensure individuals' rights to access their personal information stored in federal systems?  ", "5cb384b0-7012-438f-a9be-5f10428e5e18_2": "What legal recourse do individuals have if a federal agency fails to comply with the Privacy Act's requirements regarding their personal information?", "7a369c62-5f27-4181-92d1-8b0f59b4ccec_1": "What ethical obligations do organizations have to ensure the accuracy of individuals' information in their records?  ", "7a369c62-5f27-4181-92d1-8b0f59b4ccec_2": "How should organizations address the consequences of maintaining inaccurate or incomplete records regarding individuals' qualifications and rights?", "4b97b7b3-e790-43e5-ab36-febac372cf09_1": "How does the NIST Privacy Framework support ethical decision-making in the design and deployment of AI systems?  ", "4b97b7b3-e790-43e5-ab36-febac372cf09_2": "What ethical concerns arise from a school board's attempt to surveil students without community input?", "34a84df8-0355-4e2b-8480-289f6449b6b2_1": "What ethical concerns might have led to the ban on facial recognition systems in schools in Lockport, New York?  ", "34a84df8-0355-4e2b-8480-289f6449b6b2_2": "How does the requirement for a report on biometric identifying technology contribute to transparency and accountability in AI ethics?", "3523be37-e363-42c7-939f-daa70e3a3f76_1": "What are the privacy implications of using biometric identification technologies in schools?", "3523be37-e363-42c7-939f-daa70e3a3f76_2": "How does federal law ensure transparency in workplace surveillance during labor disputes?", "8aef759e-75d9-4b21-ad82-aa48190a3094_1": "How do reporting requirements for consultants in the Department of Labor impact transparency in AI ethics?  ", "8aef759e-75d9-4b21-ad82-aa48190a3094_2": "In what ways can well-designed technologies enhance user privacy in the context of AI applications?", "0030999d-3f51-4c92-8843-acdfec24b24d_1": "How can developers ensure transparency about user data usage in AI applications?  ", "0030999d-3f51-4c92-8843-acdfec24b24d_2": "What are the ethical implications of requiring app permissions for location tracking in AI systems?", "2882a36b-aa0e-4fb5-a523-b1df08eff13c_1": "What ethical responsibilities do designers and developers of automated systems have in terms of transparency and communication with users?", "2882a36b-aa0e-4fb5-a523-b1df08eff13c_2": "How can individuals impacted by automated systems ensure they are informed about significant changes in system functionality?", "0c3242a1-26c6-4995-b0bb-c8ce7fe4b62e_1": "What is the importance of providing technically valid explanations for decisions made by automated systems?  ", "0c3242a1-26c6-4995-b0bb-c8ce7fe4b62e_2": "How can automated systems ensure that their explanations are meaningful and useful to users and operators?", "ab6f96c5-e62c-49c9-9ef3-40e3d52262a5_1": "How should automated systems be assessed for clarity and quality in their notice and explanations to ensure ethical transparency?  ", "ab6f96c5-e62c-49c9-9ef3-40e3d52262a5_2": "What role does public reporting play in mitigating risks associated with automated systems in AI ethics?", "3d9ea148-1da7-4794-a0be-d46127db5fe1_1": "What are the potential consequences of automated systems determining opportunities in employment and credit?  ", "3d9ea148-1da7-4794-a0be-d46127db5fe1_2": "How can the lack of transparency in automated decision-making processes affect individuals' understanding of their experiences in various systems?", "2efaeb1b-fc8f-481d-a0f9-7197de12900f_1": "How does the lack of transparency in automated systems impact individuals labeled as \"high risk\" in the bail process?  ", "2efaeb1b-fc8f-481d-a0f9-7197de12900f_2": "What ethical considerations arise from individuals being denied access to information about the automated systems that affect their lives?", "4e4dee20-014c-47df-ba83-83dfabf81a87_1": "Why is clear and understandable notice important in the context of automated systems?", "4e4dee20-014c-47df-ba83-83dfabf81a87_2": "What challenges do opaque decision-making processes of automated systems pose for accountability?", "aa897bbf-b49c-4240-84ae-a95909d0fa2a_1": "Why is it important for automated systems to provide clear and valid explanations for their decisions?  ", "aa897bbf-b49c-4240-84ae-a95909d0fa2a_2": "How can the lack of explanation in automated systems impact the people affected by those decisions?", "7ca0feb2-1180-4329-9b5c-2cf8a01d3d4e_1": "What ethical considerations arise from the requirement to provide notice when using AI systems that impact individuals?  ", "7ca0feb2-1180-4329-9b5c-2cf8a01d3d4e_2": "How does the automation of explanations in AI systems align with the principles of transparency and accountability in AI ethics?", "ba84c47f-3661-4aba-adc6-70437c689443_1": "Why is it important for the American public to be informed about the use of automated systems that impact their rights?  ", "ba84c47f-3661-4aba-adc6-70437c689443_2": "What are the implications of inconsistent notice and explanation requirements for the use of AI across different sectors?", "6633a03a-588f-4a42-aa2e-f51003b14b90_1": "How does the use of algorithms in determining eligibility for services like Medicaid impact transparency and accountability in public decision-making?", "6633a03a-588f-4a42-aa2e-f51003b14b90_2": "What ethical concerns arise when automated systems, such as algorithms, are used to make decisions that affect vulnerable populations, like individuals with disabilities?", "096b7785-5989-4767-bce6-b1eeb5bfd57a_1": "What ethical concerns arise from using algorithms in child welfare investigations without notifying the parents involved?  ", "096b7785-5989-4767-bce6-b1eeb5bfd57a_2": "How does the lack of transparency in data collection for algorithmic assessments impact the fairness of child welfare decisions?", "9e3e68e9-f19a-4928-9365-ecebd6c30a32_1": "How does the denial of parents' knowledge in maltreatment assessments impact the ethical validity of risk assessments in AI systems?  ", "9e3e68e9-f19a-4928-9365-ecebd6c30a32_2": "What ethical concerns arise from the use of AI in maltreatment assessments when parents are not informed of their rights to contest decisions?", "0fd8917c-9fad-4fbe-aa0b-bd2a1aa43d13_1": "What ethical concerns arise from the lack of transparency in predictive policing systems?  ", "0fd8917c-9fad-4fbe-aa0b-bd2a1aa43d13_2": "How can the principle of accountability be applied to ensure that individuals understand the criteria used in predictive policing decisions?", "c72caf6f-8d32-466f-9c7b-bb7eee55afdc_1": "What ethical concerns arise from a system changing its criteria for awarding benefits without transparency?  ", "c72caf6f-8d32-466f-9c7b-bb7eee55afdc_2": "How do data entry errors and system flaws impact the fairness of benefit distribution in automated systems?", "e9cdd7c4-47e9-48da-841a-4eaeb30c120c_1": "How does the lack of explanation in AI decision-making impact the ability to correct errors?  ", "e9cdd7c4-47e9-48da-841a-4eaeb30c120c_2": "What ethical implications arise from the demand for AI outputs without sufficient transparency?", "f489cf15-d0fd-4932-a311-d09b9242bcbd_1": "What are the key expectations for automated systems regarding notice and explanation of their use?", "f489cf15-d0fd-4932-a311-d09b9242bcbd_2": "Why is it important for automated systems to provide clear and understandable documentation?", "5b780d10-f70b-40a8-98bc-23297874b66f_1": "Why is it important for AI systems to have publicly accessible documentation?  ", "5b780d10-f70b-40a8-98bc-23297874b66f_2": "How does clear documentation contribute to the ethical use of AI systems?", "c7c50a83-277d-4f4d-a42a-0b1b38a75afe_1": "What are the expectations for reporting in the context of automated decision-making systems as outlined in the framework?", "c7c50a83-277d-4f4d-a42a-0b1b38a75afe_2": "Why is it important for users to receive timely and up-to-date notices regarding the use of automated systems?", "24f63b0c-8ac8-48e0-b100-9f65d5a70587_1": "How can user testing contribute to the ethical assessment of automated systems?  ", "24f63b0c-8ac8-48e0-b100-9f65d5a70587_2": "Why is it important to provide clear notices and explanations to users impacted by automated systems?", "40ea1712-0fc0-493a-a073-75a0a4289c3b_1": "How can AI systems ensure that notices and explanations are accessible to users with disabilities?  ", "40ea1712-0fc0-493a-a073-75a0a4289c3b_2": "Why is it important for AI systems to provide tailored explanations for decisions made or actions taken?", "74a10716-4134-4d7b-9539-cd94739f136a_1": "How should AI systems differentiate between informational explanations and those that allow for recourse or appeal?  ", "74a10716-4134-4d7b-9539-cd94739f136a_2": "What ethical considerations arise when providing explanations for AI decisions that impact individuals' rights?", "ba49c935-b7a3-44a5-912c-19413a2ce79a_1": "How can tailored explanations in AI decision-making processes enhance transparency and accountability?", "ba49c935-b7a3-44a5-912c-19413a2ce79a_2": "What ethical considerations arise when providing different explanations to various audiences affected by an AI decision?", "4ceeb4cb-5b7d-414b-bbc8-9663d18f5300_1": "What ethical considerations should be taken into account when conducting AI research?  ", "4ceeb4cb-5b7d-414b-bbc8-9663d18f5300_2": "How can researchers ensure that their AI developments align with ethical standards?", "7f9e8779-4fa0-4991-9d60-c20792d2aaf7_1": "What role does risk assessment play in the development of automated systems according to the expectations outlined?  ", "7f9e8779-4fa0-4991-9d60-c20792d2aaf7_2": "Why is it important to include explanatory mechanisms in automated systems used in high-risk settings?", "4068a74b-d721-4727-8ae8-63dd3f46945a_1": "Why is it important to use transparent models in AI decision-making processes?  ", "4068a74b-d721-4727-8ae8-63dd3f46945a_2": "How should the level of explanation in AI systems be determined according to the risk level?", "2aea1a16-7ceb-41c4-ba11-87cf884f870f_1": "What is the importance of providing accurate explanations for AI decision-making in relation to ethical considerations?", "2aea1a16-7ceb-41c4-ba11-87cf884f870f_2": "How should simplifications in AI explanations be approached to maintain ethical standards?", "4c0a2dfd-94c9-46d0-a6cb-ecbd7609047e_1": "How should usability and interface complexity be balanced when presenting information in AI systems?  ", "4c0a2dfd-94c9-46d0-a6cb-ecbd7609047e_2": "What role does summary reporting play in ensuring transparency and accountability in AI decision-making?", "1efa7d9d-12a8-41a4-8eb8-8af7a265bffd_1": "What are the key factors that should be considered for accountability in AI systems?", "1efa7d9d-12a8-41a4-8eb8-8af7a265bffd_2": "How should explanations of AI system impacts be tailored to different users and levels of risk?", "31b4cd77-4539-4f36-aa0f-937186f380f3_1": "How does the Biometric Information Privacy Act in Illinois protect individuals' rights regarding their biometric data?", "31b4cd77-4539-4f36-aa0f-937186f380f3_2": "What are some practical approaches that can be implemented to ensure compliance with laws like the Biometric Information Privacy Act?", "190dd893-b53b-4700-b35a-b8b55b49b24b_1": "What ethical considerations should technology companies take into account when communicating with the public about AI developments?  ", "190dd893-b53b-4700-b35a-b8b55b49b24b_2": "How does the requirement for written notice to individuals or their representatives impact transparency in AI practices?", "c72b45ed-b8f4-4508-9ce9-fe13f94d6c50_1": "How does the framework developed by non-profit organizations and companies enhance transparency in machine learning systems?  ", "c72b45ed-b8f4-4508-9ce9-fe13f94d6c50_2": "What federal laws require lenders to notify consumers about decisions made regarding them?", "2b8b77aa-d83f-46b6-a43d-918c3308993c_1": "How does the Fair Credit Reporting Act ensure transparency in credit decisions for consumers?  ", "2b8b77aa-d83f-46b6-a43d-918c3308993c_2": "What ethical implications arise from the requirement to provide \"adverse action\" notices to consumers denied credit?", "ddbc86d0-8442-4129-9315-83e68bab4f84_1": "How does the requirement for creditors to provide explanations for adverse actions align with ethical principles in AI decision-making?  ", "ddbc86d0-8442-4129-9315-83e68bab4f84_2": "What ethical implications arise from the use of complex algorithms in credit scoring if consumers are not adequately informed about the reasons for adverse actions?", "96d2545b-bdd9-48d4-82ea-d929ec34dad6_1": "How does the California law ensure transparency in the use of automated systems for employee quotas in warehouses?  ", "96d2545b-bdd9-48d4-82ea-d929ec34dad6_2": "What ethical considerations arise from the use of automated systems to monitor and enforce employee quotas?", "8851b71f-d5dd-441b-860f-f0c452766707_1": "How does the requirement for employers in California to provide written descriptions of quotas relate to transparency in AI systems?  ", "8851b71f-d5dd-441b-860f-f0c452766707_2": "What role does the NIST play in promoting ethical standards for explainable AI systems?", "3d1c79a7-2e49-490e-ba05-42769aa54db1_1": "What are the core tenets of explainable AI that the Defense Advanced Research Projects Agency is implementing?  ", "3d1c79a7-2e49-490e-ba05-42769aa54db1_2": "How does the program on Explainable Artificial Intelligence aim to enhance the transparency of machine learning techniques?", "999cc9e5-a704-47c7-a5bc-cc862491a41f_1": "How can explainable AI contribute to building trust between human users and AI systems?  ", "999cc9e5-a704-47c7-a5bc-cc862491a41f_2": "What role does the National Science Foundation's program on Fairness in Artificial Intelligence play in promoting explainable AI?"}, "relevant_contexts": {"2b63e9da-5eb2-4515-a608-5e7786f084d1_1": ["2b63e9da-5eb2-4515-a608-5e7786f084d1"], "2b63e9da-5eb2-4515-a608-5e7786f084d1_2": ["2b63e9da-5eb2-4515-a608-5e7786f084d1"], "7ed5d69a-bcd6-4656-8b22-c949fcca3c7f_1": ["7ed5d69a-bcd6-4656-8b22-c949fcca3c7f"], "7ed5d69a-bcd6-4656-8b22-c949fcca3c7f_2": ["7ed5d69a-bcd6-4656-8b22-c949fcca3c7f"], "9044b75d-90c9-48b5-928e-7bcd84671a28_1": ["9044b75d-90c9-48b5-928e-7bcd84671a28"], "9044b75d-90c9-48b5-928e-7bcd84671a28_2": ["9044b75d-90c9-48b5-928e-7bcd84671a28"], "3645e5f9-8926-491d-b191-ba5112b25c49_1": ["3645e5f9-8926-491d-b191-ba5112b25c49"], "3645e5f9-8926-491d-b191-ba5112b25c49_2": ["3645e5f9-8926-491d-b191-ba5112b25c49"], "39993687-916c-4671-8d4b-4732af201b16_1": ["39993687-916c-4671-8d4b-4732af201b16"], "39993687-916c-4671-8d4b-4732af201b16_2": ["39993687-916c-4671-8d4b-4732af201b16"], "d19fb894-9e8d-4d18-a94d-1f01bdd33c56_1": ["d19fb894-9e8d-4d18-a94d-1f01bdd33c56"], "d19fb894-9e8d-4d18-a94d-1f01bdd33c56_2": ["d19fb894-9e8d-4d18-a94d-1f01bdd33c56"], "ff3ab363-0163-4dbd-955a-293ff6025248_1": ["ff3ab363-0163-4dbd-955a-293ff6025248"], "ff3ab363-0163-4dbd-955a-293ff6025248_2": ["ff3ab363-0163-4dbd-955a-293ff6025248"], "57277e82-772d-4954-bee1-78a723ef113a_1": ["57277e82-772d-4954-bee1-78a723ef113a"], "57277e82-772d-4954-bee1-78a723ef113a_2": ["57277e82-772d-4954-bee1-78a723ef113a"], "761f6036-77a2-4998-81de-7eb2b6330c04_1": ["761f6036-77a2-4998-81de-7eb2b6330c04"], "761f6036-77a2-4998-81de-7eb2b6330c04_2": ["761f6036-77a2-4998-81de-7eb2b6330c04"], "cb21e5d1-397e-4884-bf14-e22de8225d10_1": ["cb21e5d1-397e-4884-bf14-e22de8225d10"], "cb21e5d1-397e-4884-bf14-e22de8225d10_2": ["cb21e5d1-397e-4884-bf14-e22de8225d10"], "b69096bb-dfe0-440f-8dbe-963d97850aff_1": ["b69096bb-dfe0-440f-8dbe-963d97850aff"], "b69096bb-dfe0-440f-8dbe-963d97850aff_2": ["b69096bb-dfe0-440f-8dbe-963d97850aff"], "43070dc6-452b-4896-9642-d71f2c7decee_1": ["43070dc6-452b-4896-9642-d71f2c7decee"], "43070dc6-452b-4896-9642-d71f2c7decee_2": ["43070dc6-452b-4896-9642-d71f2c7decee"], "d15b0f49-6066-4f4b-b930-9f0d907c9eff_1": ["d15b0f49-6066-4f4b-b930-9f0d907c9eff"], "d15b0f49-6066-4f4b-b930-9f0d907c9eff_2": ["d15b0f49-6066-4f4b-b930-9f0d907c9eff"], "9eee00fb-1d02-43fa-801e-7f68e9690cfa_1": ["9eee00fb-1d02-43fa-801e-7f68e9690cfa"], "9eee00fb-1d02-43fa-801e-7f68e9690cfa_2": ["9eee00fb-1d02-43fa-801e-7f68e9690cfa"], "cae51451-45cb-4f73-a0f8-f76e0e6fd5ef_1": ["cae51451-45cb-4f73-a0f8-f76e0e6fd5ef"], "cae51451-45cb-4f73-a0f8-f76e0e6fd5ef_2": ["cae51451-45cb-4f73-a0f8-f76e0e6fd5ef"], "4ef57090-9555-4422-8147-7c76ed92a7d5_1": ["4ef57090-9555-4422-8147-7c76ed92a7d5"], "4ef57090-9555-4422-8147-7c76ed92a7d5_2": ["4ef57090-9555-4422-8147-7c76ed92a7d5"], "66a4ed20-14b1-45f1-84df-37f09b52e569_1": ["66a4ed20-14b1-45f1-84df-37f09b52e569"], "66a4ed20-14b1-45f1-84df-37f09b52e569_2": ["66a4ed20-14b1-45f1-84df-37f09b52e569"], "d4921251-b4d5-47bd-933b-3bc479317063_1": ["d4921251-b4d5-47bd-933b-3bc479317063"], "d4921251-b4d5-47bd-933b-3bc479317063_2": ["d4921251-b4d5-47bd-933b-3bc479317063"], "2394e9b3-81e2-4b54-8f03-a8a15add6484_1": ["2394e9b3-81e2-4b54-8f03-a8a15add6484"], "2394e9b3-81e2-4b54-8f03-a8a15add6484_2": ["2394e9b3-81e2-4b54-8f03-a8a15add6484"], "85928e54-ae18-4a1d-8650-42edd0b4ff5d_1": ["85928e54-ae18-4a1d-8650-42edd0b4ff5d"], "85928e54-ae18-4a1d-8650-42edd0b4ff5d_2": ["85928e54-ae18-4a1d-8650-42edd0b4ff5d"], "0214b542-d262-47df-b694-561355ee341d_1": ["0214b542-d262-47df-b694-561355ee341d"], "0214b542-d262-47df-b694-561355ee341d_2": ["0214b542-d262-47df-b694-561355ee341d"], "d8289c72-842b-4dde-a3d5-fd17a45632c1_1": ["d8289c72-842b-4dde-a3d5-fd17a45632c1"], "d8289c72-842b-4dde-a3d5-fd17a45632c1_2": ["d8289c72-842b-4dde-a3d5-fd17a45632c1"], "c175618a-4c65-4090-bfd8-69c6bbe61d5b_1": ["c175618a-4c65-4090-bfd8-69c6bbe61d5b"], "c175618a-4c65-4090-bfd8-69c6bbe61d5b_2": ["c175618a-4c65-4090-bfd8-69c6bbe61d5b"], "2d3b4509-9b83-450f-b319-4d8fc1293751_1": ["2d3b4509-9b83-450f-b319-4d8fc1293751"], "2d3b4509-9b83-450f-b319-4d8fc1293751_2": ["2d3b4509-9b83-450f-b319-4d8fc1293751"], "2f43deab-8be2-4cd3-9dc5-4a63947b2ae1_1": ["2f43deab-8be2-4cd3-9dc5-4a63947b2ae1"], "2f43deab-8be2-4cd3-9dc5-4a63947b2ae1_2": ["2f43deab-8be2-4cd3-9dc5-4a63947b2ae1"], "f70ec23e-99af-48fd-9e17-ece2eaee3d16_1": ["f70ec23e-99af-48fd-9e17-ece2eaee3d16"], "f70ec23e-99af-48fd-9e17-ece2eaee3d16_2": ["f70ec23e-99af-48fd-9e17-ece2eaee3d16"], "b59fa977-0d2b-4bb7-8583-13bbe3338f39_1": ["b59fa977-0d2b-4bb7-8583-13bbe3338f39"], "b59fa977-0d2b-4bb7-8583-13bbe3338f39_2": ["b59fa977-0d2b-4bb7-8583-13bbe3338f39"], "facfa226-5df2-4fa8-9cda-a0f1674fa12e_1": ["facfa226-5df2-4fa8-9cda-a0f1674fa12e"], "facfa226-5df2-4fa8-9cda-a0f1674fa12e_2": ["facfa226-5df2-4fa8-9cda-a0f1674fa12e"], "8cc2a2d9-2eed-45ad-af65-538324fcefb1_1": ["8cc2a2d9-2eed-45ad-af65-538324fcefb1"], "8cc2a2d9-2eed-45ad-af65-538324fcefb1_2": ["8cc2a2d9-2eed-45ad-af65-538324fcefb1"], "3bc51cf4-d565-46b0-8e09-508b2041824d_1": ["3bc51cf4-d565-46b0-8e09-508b2041824d"], "3bc51cf4-d565-46b0-8e09-508b2041824d_2": ["3bc51cf4-d565-46b0-8e09-508b2041824d"], "6c2a16cc-9fd1-46be-9fce-59ee4dfba44a_1": ["6c2a16cc-9fd1-46be-9fce-59ee4dfba44a"], "6c2a16cc-9fd1-46be-9fce-59ee4dfba44a_2": ["6c2a16cc-9fd1-46be-9fce-59ee4dfba44a"], "bca32085-cc69-4be5-9c8a-1c5cf12ae532_1": ["bca32085-cc69-4be5-9c8a-1c5cf12ae532"], "bca32085-cc69-4be5-9c8a-1c5cf12ae532_2": ["bca32085-cc69-4be5-9c8a-1c5cf12ae532"], "ec22a03b-6e3a-43ad-b92f-09231cf270ed_1": ["ec22a03b-6e3a-43ad-b92f-09231cf270ed"], "ec22a03b-6e3a-43ad-b92f-09231cf270ed_2": ["ec22a03b-6e3a-43ad-b92f-09231cf270ed"], "f458c57d-9ef9-448a-b325-4e7fde633c9f_1": ["f458c57d-9ef9-448a-b325-4e7fde633c9f"], "f458c57d-9ef9-448a-b325-4e7fde633c9f_2": ["f458c57d-9ef9-448a-b325-4e7fde633c9f"], "498eb8a3-1798-44fe-a1bb-ee5972a931a6_1": ["498eb8a3-1798-44fe-a1bb-ee5972a931a6"], "498eb8a3-1798-44fe-a1bb-ee5972a931a6_2": ["498eb8a3-1798-44fe-a1bb-ee5972a931a6"], "08130ab3-8809-41f9-a10c-c9c7080b67a6_1": ["08130ab3-8809-41f9-a10c-c9c7080b67a6"], "08130ab3-8809-41f9-a10c-c9c7080b67a6_2": ["08130ab3-8809-41f9-a10c-c9c7080b67a6"], "2d7dabaf-155c-4036-a458-59b8119c1a03_1": ["2d7dabaf-155c-4036-a458-59b8119c1a03"], "2d7dabaf-155c-4036-a458-59b8119c1a03_2": ["2d7dabaf-155c-4036-a458-59b8119c1a03"], "0827d937-883e-4b60-9b04-7e83cca84940_1": ["0827d937-883e-4b60-9b04-7e83cca84940"], "0827d937-883e-4b60-9b04-7e83cca84940_2": ["0827d937-883e-4b60-9b04-7e83cca84940"], "2e1c7072-d11c-4832-ba82-f2fd3a0e309e_1": ["2e1c7072-d11c-4832-ba82-f2fd3a0e309e"], "2e1c7072-d11c-4832-ba82-f2fd3a0e309e_2": ["2e1c7072-d11c-4832-ba82-f2fd3a0e309e"], "42da6bfa-8628-49ed-b638-a2b9be70becc_1": ["42da6bfa-8628-49ed-b638-a2b9be70becc"], "42da6bfa-8628-49ed-b638-a2b9be70becc_2": ["42da6bfa-8628-49ed-b638-a2b9be70becc"], "586ae00e-8427-491b-a0a6-94a21394af7c_1": ["586ae00e-8427-491b-a0a6-94a21394af7c"], "586ae00e-8427-491b-a0a6-94a21394af7c_2": ["586ae00e-8427-491b-a0a6-94a21394af7c"], "337ca019-42c2-4790-ba4f-36dfb745dc11_1": ["337ca019-42c2-4790-ba4f-36dfb745dc11"], "337ca019-42c2-4790-ba4f-36dfb745dc11_2": ["337ca019-42c2-4790-ba4f-36dfb745dc11"], "40d48902-c91a-408f-91e6-4034893da786_1": ["40d48902-c91a-408f-91e6-4034893da786"], "40d48902-c91a-408f-91e6-4034893da786_2": ["40d48902-c91a-408f-91e6-4034893da786"], "b1c0f3a6-07a7-4a9a-b753-9a50a3c277f3_1": ["b1c0f3a6-07a7-4a9a-b753-9a50a3c277f3"], "b1c0f3a6-07a7-4a9a-b753-9a50a3c277f3_2": ["b1c0f3a6-07a7-4a9a-b753-9a50a3c277f3"], "53d396a2-66c4-4977-90e7-0bb3a2484e16_1": ["53d396a2-66c4-4977-90e7-0bb3a2484e16"], "53d396a2-66c4-4977-90e7-0bb3a2484e16_2": ["53d396a2-66c4-4977-90e7-0bb3a2484e16"], "e3f5ac23-ad36-4454-8a57-3cd4c0dd9283_1": ["e3f5ac23-ad36-4454-8a57-3cd4c0dd9283"], "e3f5ac23-ad36-4454-8a57-3cd4c0dd9283_2": ["e3f5ac23-ad36-4454-8a57-3cd4c0dd9283"], "6181a68a-0654-4b9f-9fbe-e7f224ee42cc_1": ["6181a68a-0654-4b9f-9fbe-e7f224ee42cc"], "6181a68a-0654-4b9f-9fbe-e7f224ee42cc_2": ["6181a68a-0654-4b9f-9fbe-e7f224ee42cc"], "b8e5f957-237b-4204-9b9a-a45cc9535d88_1": ["b8e5f957-237b-4204-9b9a-a45cc9535d88"], "b8e5f957-237b-4204-9b9a-a45cc9535d88_2": ["b8e5f957-237b-4204-9b9a-a45cc9535d88"], "d47b9e1c-489a-4c71-a99b-c45894f40e39_1": ["d47b9e1c-489a-4c71-a99b-c45894f40e39"], "d47b9e1c-489a-4c71-a99b-c45894f40e39_2": ["d47b9e1c-489a-4c71-a99b-c45894f40e39"], "2f4e355a-2898-4cc3-8ca1-50fb833163ab_1": ["2f4e355a-2898-4cc3-8ca1-50fb833163ab"], "2f4e355a-2898-4cc3-8ca1-50fb833163ab_2": ["2f4e355a-2898-4cc3-8ca1-50fb833163ab"], "1eb81643-0479-4669-b94c-1538bf03b398_1": ["1eb81643-0479-4669-b94c-1538bf03b398"], "1eb81643-0479-4669-b94c-1538bf03b398_2": ["1eb81643-0479-4669-b94c-1538bf03b398"], "95e72817-edc5-4037-8517-acf270aa38a1_1": ["95e72817-edc5-4037-8517-acf270aa38a1"], "95e72817-edc5-4037-8517-acf270aa38a1_2": ["95e72817-edc5-4037-8517-acf270aa38a1"], "f876a0e6-2549-4dea-9bc7-16a5a0fbf3a0_1": ["f876a0e6-2549-4dea-9bc7-16a5a0fbf3a0"], "f876a0e6-2549-4dea-9bc7-16a5a0fbf3a0_2": ["f876a0e6-2549-4dea-9bc7-16a5a0fbf3a0"], "b9a14487-6e9e-4423-99c1-9dd441b1a316_1": ["b9a14487-6e9e-4423-99c1-9dd441b1a316"], "b9a14487-6e9e-4423-99c1-9dd441b1a316_2": ["b9a14487-6e9e-4423-99c1-9dd441b1a316"], "f5d21644-a601-4747-bd5a-ffb8e242df95_1": ["f5d21644-a601-4747-bd5a-ffb8e242df95"], "f5d21644-a601-4747-bd5a-ffb8e242df95_2": ["f5d21644-a601-4747-bd5a-ffb8e242df95"], "b4980938-40f7-491e-a986-6401a99cf198_1": ["b4980938-40f7-491e-a986-6401a99cf198"], "b4980938-40f7-491e-a986-6401a99cf198_2": ["b4980938-40f7-491e-a986-6401a99cf198"], "b814145f-813e-48e7-a532-bb731bbda211_1": ["b814145f-813e-48e7-a532-bb731bbda211"], "b814145f-813e-48e7-a532-bb731bbda211_2": ["b814145f-813e-48e7-a532-bb731bbda211"], "1b61df3a-157c-4cb7-a504-9ce289071061_1": ["1b61df3a-157c-4cb7-a504-9ce289071061"], "1b61df3a-157c-4cb7-a504-9ce289071061_2": ["1b61df3a-157c-4cb7-a504-9ce289071061"], "c0238690-f8df-4333-95b9-9d6ae1c9c584_1": ["c0238690-f8df-4333-95b9-9d6ae1c9c584"], "c0238690-f8df-4333-95b9-9d6ae1c9c584_2": ["c0238690-f8df-4333-95b9-9d6ae1c9c584"], "0b113d5f-1c35-4d6f-a0ec-4929f5852df4_1": ["0b113d5f-1c35-4d6f-a0ec-4929f5852df4"], "0b113d5f-1c35-4d6f-a0ec-4929f5852df4_2": ["0b113d5f-1c35-4d6f-a0ec-4929f5852df4"], "632db52c-2137-4d81-8f38-50ba34866e02_1": ["632db52c-2137-4d81-8f38-50ba34866e02"], "632db52c-2137-4d81-8f38-50ba34866e02_2": ["632db52c-2137-4d81-8f38-50ba34866e02"], "fc0446c2-84a2-4f27-966b-f5d328a70f50_1": ["fc0446c2-84a2-4f27-966b-f5d328a70f50"], "fc0446c2-84a2-4f27-966b-f5d328a70f50_2": ["fc0446c2-84a2-4f27-966b-f5d328a70f50"], "eff9ff37-f61f-4420-9055-e2a218c7b41c_1": ["eff9ff37-f61f-4420-9055-e2a218c7b41c"], "eff9ff37-f61f-4420-9055-e2a218c7b41c_2": ["eff9ff37-f61f-4420-9055-e2a218c7b41c"], "98a604f9-3590-48ce-95e7-977f304548d0_1": ["98a604f9-3590-48ce-95e7-977f304548d0"], "98a604f9-3590-48ce-95e7-977f304548d0_2": ["98a604f9-3590-48ce-95e7-977f304548d0"], "3d8070c4-6254-4b5c-8ba4-da2ccf2e0d00_1": ["3d8070c4-6254-4b5c-8ba4-da2ccf2e0d00"], "3d8070c4-6254-4b5c-8ba4-da2ccf2e0d00_2": ["3d8070c4-6254-4b5c-8ba4-da2ccf2e0d00"], "522a2717-200a-4374-8fd5-d3abdfbc1226_1": ["522a2717-200a-4374-8fd5-d3abdfbc1226"], "522a2717-200a-4374-8fd5-d3abdfbc1226_2": ["522a2717-200a-4374-8fd5-d3abdfbc1226"], "75e202a1-d140-4f47-ab2b-e211e543a2c5_1": ["75e202a1-d140-4f47-ab2b-e211e543a2c5"], "75e202a1-d140-4f47-ab2b-e211e543a2c5_2": ["75e202a1-d140-4f47-ab2b-e211e543a2c5"], "041d2876-f023-40b1-b0f1-c6be2e3d1b74_1": ["041d2876-f023-40b1-b0f1-c6be2e3d1b74"], "041d2876-f023-40b1-b0f1-c6be2e3d1b74_2": ["041d2876-f023-40b1-b0f1-c6be2e3d1b74"], "4a9174fe-7911-42c1-a501-1349cc643ff1_1": ["4a9174fe-7911-42c1-a501-1349cc643ff1"], "4a9174fe-7911-42c1-a501-1349cc643ff1_2": ["4a9174fe-7911-42c1-a501-1349cc643ff1"], "8c9806de-cd1b-4da8-9191-64efcef9e09d_1": ["8c9806de-cd1b-4da8-9191-64efcef9e09d"], "8c9806de-cd1b-4da8-9191-64efcef9e09d_2": ["8c9806de-cd1b-4da8-9191-64efcef9e09d"], "3165553a-9b8f-480c-afa3-17192d6a2b6c_1": ["3165553a-9b8f-480c-afa3-17192d6a2b6c"], "3165553a-9b8f-480c-afa3-17192d6a2b6c_2": ["3165553a-9b8f-480c-afa3-17192d6a2b6c"], "664037f2-7155-4df2-988e-78aabec95a6f_1": ["664037f2-7155-4df2-988e-78aabec95a6f"], "664037f2-7155-4df2-988e-78aabec95a6f_2": ["664037f2-7155-4df2-988e-78aabec95a6f"], "5be54f63-786c-49fd-8126-f5bd288f8600_1": ["5be54f63-786c-49fd-8126-f5bd288f8600"], "5be54f63-786c-49fd-8126-f5bd288f8600_2": ["5be54f63-786c-49fd-8126-f5bd288f8600"], "f81943d9-e0a4-4e02-9518-58b1c430f446_1": ["f81943d9-e0a4-4e02-9518-58b1c430f446"], "f81943d9-e0a4-4e02-9518-58b1c430f446_2": ["f81943d9-e0a4-4e02-9518-58b1c430f446"], "9020b6f0-1074-4064-82e9-95845d0b121e_1": ["9020b6f0-1074-4064-82e9-95845d0b121e"], "9020b6f0-1074-4064-82e9-95845d0b121e_2": ["9020b6f0-1074-4064-82e9-95845d0b121e"], "92a6cf51-caf8-4cc2-91bb-a966dbf400df_1": ["92a6cf51-caf8-4cc2-91bb-a966dbf400df"], "92a6cf51-caf8-4cc2-91bb-a966dbf400df_2": ["92a6cf51-caf8-4cc2-91bb-a966dbf400df"], "b8b71f36-757d-495c-9719-e84c0a976606_1": ["b8b71f36-757d-495c-9719-e84c0a976606"], "b8b71f36-757d-495c-9719-e84c0a976606_2": ["b8b71f36-757d-495c-9719-e84c0a976606"], "cc8c282e-d378-4571-980f-cc0ddf33a406_1": ["cc8c282e-d378-4571-980f-cc0ddf33a406"], "cc8c282e-d378-4571-980f-cc0ddf33a406_2": ["cc8c282e-d378-4571-980f-cc0ddf33a406"], "99697ee1-707b-43e9-b4ae-722e0fec5901_1": ["99697ee1-707b-43e9-b4ae-722e0fec5901"], "99697ee1-707b-43e9-b4ae-722e0fec5901_2": ["99697ee1-707b-43e9-b4ae-722e0fec5901"], "7ad79f6c-d800-49dc-864b-b1deb43ea49f_1": ["7ad79f6c-d800-49dc-864b-b1deb43ea49f"], "7ad79f6c-d800-49dc-864b-b1deb43ea49f_2": ["7ad79f6c-d800-49dc-864b-b1deb43ea49f"], "edaf9e38-6479-48ef-ba9d-5d6c07ae6f09_1": ["edaf9e38-6479-48ef-ba9d-5d6c07ae6f09"], "edaf9e38-6479-48ef-ba9d-5d6c07ae6f09_2": ["edaf9e38-6479-48ef-ba9d-5d6c07ae6f09"], "81f3b7b1-3a02-44c8-8727-4e4b24c3a730_1": ["81f3b7b1-3a02-44c8-8727-4e4b24c3a730"], "81f3b7b1-3a02-44c8-8727-4e4b24c3a730_2": ["81f3b7b1-3a02-44c8-8727-4e4b24c3a730"], "4c6f7d89-da85-42d5-9489-fbdb8d8ef27e_1": ["4c6f7d89-da85-42d5-9489-fbdb8d8ef27e"], "4c6f7d89-da85-42d5-9489-fbdb8d8ef27e_2": ["4c6f7d89-da85-42d5-9489-fbdb8d8ef27e"], "a9367afa-7030-48f2-ad57-a2f1b36648b4_1": ["a9367afa-7030-48f2-ad57-a2f1b36648b4"], "a9367afa-7030-48f2-ad57-a2f1b36648b4_2": ["a9367afa-7030-48f2-ad57-a2f1b36648b4"], "3c6632b7-4be4-40c6-876b-e9050252fe27_1": ["3c6632b7-4be4-40c6-876b-e9050252fe27"], "3c6632b7-4be4-40c6-876b-e9050252fe27_2": ["3c6632b7-4be4-40c6-876b-e9050252fe27"], "d3e92914-f693-4ffd-affc-73a1af5af922_1": ["d3e92914-f693-4ffd-affc-73a1af5af922"], "d3e92914-f693-4ffd-affc-73a1af5af922_2": ["d3e92914-f693-4ffd-affc-73a1af5af922"], "ffe359b8-2946-4487-b123-167bcd402f5b_1": ["ffe359b8-2946-4487-b123-167bcd402f5b"], "ffe359b8-2946-4487-b123-167bcd402f5b_2": ["ffe359b8-2946-4487-b123-167bcd402f5b"], "5b75b1af-b531-4af4-af70-39540fd42e54_1": ["5b75b1af-b531-4af4-af70-39540fd42e54"], "5b75b1af-b531-4af4-af70-39540fd42e54_2": ["5b75b1af-b531-4af4-af70-39540fd42e54"], "1238d8f9-c2bd-42f8-88c2-a1288d42a98d_1": ["1238d8f9-c2bd-42f8-88c2-a1288d42a98d"], "1238d8f9-c2bd-42f8-88c2-a1288d42a98d_2": ["1238d8f9-c2bd-42f8-88c2-a1288d42a98d"], "f9954383-4233-4888-af4d-037eed9ee778_1": ["f9954383-4233-4888-af4d-037eed9ee778"], "f9954383-4233-4888-af4d-037eed9ee778_2": ["f9954383-4233-4888-af4d-037eed9ee778"], "87c6faa4-a0b0-49f7-93bf-8488edb84ac2_1": ["87c6faa4-a0b0-49f7-93bf-8488edb84ac2"], "87c6faa4-a0b0-49f7-93bf-8488edb84ac2_2": ["87c6faa4-a0b0-49f7-93bf-8488edb84ac2"], "29057260-21d6-4d98-8c94-563c7af4c2a6_1": ["29057260-21d6-4d98-8c94-563c7af4c2a6"], "29057260-21d6-4d98-8c94-563c7af4c2a6_2": ["29057260-21d6-4d98-8c94-563c7af4c2a6"], "1938b0e4-4263-45d4-8faa-c1d668a424c1_1": ["1938b0e4-4263-45d4-8faa-c1d668a424c1"], "1938b0e4-4263-45d4-8faa-c1d668a424c1_2": ["1938b0e4-4263-45d4-8faa-c1d668a424c1"], "280ee76b-a037-4e64-a5ef-b0a924563916_1": ["280ee76b-a037-4e64-a5ef-b0a924563916"], "280ee76b-a037-4e64-a5ef-b0a924563916_2": ["280ee76b-a037-4e64-a5ef-b0a924563916"], "604e5eb5-6d9c-4b92-b747-aff4269bc558_1": ["604e5eb5-6d9c-4b92-b747-aff4269bc558"], "604e5eb5-6d9c-4b92-b747-aff4269bc558_2": ["604e5eb5-6d9c-4b92-b747-aff4269bc558"], "43e9df7f-b104-488e-ade6-812ec0b85f76_1": ["43e9df7f-b104-488e-ade6-812ec0b85f76"], "43e9df7f-b104-488e-ade6-812ec0b85f76_2": ["43e9df7f-b104-488e-ade6-812ec0b85f76"], "3c449b5a-c2ea-40a6-b15c-c59ca58f6e40_1": ["3c449b5a-c2ea-40a6-b15c-c59ca58f6e40"], "3c449b5a-c2ea-40a6-b15c-c59ca58f6e40_2": ["3c449b5a-c2ea-40a6-b15c-c59ca58f6e40"], "c3f37ade-3ffc-4098-857b-7f07e94ba162_1": ["c3f37ade-3ffc-4098-857b-7f07e94ba162"], "c3f37ade-3ffc-4098-857b-7f07e94ba162_2": ["c3f37ade-3ffc-4098-857b-7f07e94ba162"], "634d3e1e-b2ab-42dd-8ad8-57013d5f96bf_1": ["634d3e1e-b2ab-42dd-8ad8-57013d5f96bf"], "634d3e1e-b2ab-42dd-8ad8-57013d5f96bf_2": ["634d3e1e-b2ab-42dd-8ad8-57013d5f96bf"], "98564560-d952-479b-aa34-5020a64a3cf0_1": ["98564560-d952-479b-aa34-5020a64a3cf0"], "98564560-d952-479b-aa34-5020a64a3cf0_2": ["98564560-d952-479b-aa34-5020a64a3cf0"], "acb01b35-7287-4e65-aa40-a9b96df85eb2_1": ["acb01b35-7287-4e65-aa40-a9b96df85eb2"], "acb01b35-7287-4e65-aa40-a9b96df85eb2_2": ["acb01b35-7287-4e65-aa40-a9b96df85eb2"], "6be2c786-aa9e-4a2b-848f-467ef69ab36c_1": ["6be2c786-aa9e-4a2b-848f-467ef69ab36c"], "6be2c786-aa9e-4a2b-848f-467ef69ab36c_2": ["6be2c786-aa9e-4a2b-848f-467ef69ab36c"], "79abe2e9-b1f4-41a5-aea6-ad20a38685f5_1": ["79abe2e9-b1f4-41a5-aea6-ad20a38685f5"], "79abe2e9-b1f4-41a5-aea6-ad20a38685f5_2": ["79abe2e9-b1f4-41a5-aea6-ad20a38685f5"], "d7cfcc0d-953a-4818-b77e-a89206c8bee3_1": ["d7cfcc0d-953a-4818-b77e-a89206c8bee3"], "d7cfcc0d-953a-4818-b77e-a89206c8bee3_2": ["d7cfcc0d-953a-4818-b77e-a89206c8bee3"], "8d000301-fae4-46f2-9274-9a6263bd184c_1": ["8d000301-fae4-46f2-9274-9a6263bd184c"], "8d000301-fae4-46f2-9274-9a6263bd184c_2": ["8d000301-fae4-46f2-9274-9a6263bd184c"], "8cebe0ab-1fe9-4d44-9e6b-ac207e5b8dec_1": ["8cebe0ab-1fe9-4d44-9e6b-ac207e5b8dec"], "8cebe0ab-1fe9-4d44-9e6b-ac207e5b8dec_2": ["8cebe0ab-1fe9-4d44-9e6b-ac207e5b8dec"], "84a037db-cea9-4f44-9971-d9c90396d636_1": ["84a037db-cea9-4f44-9971-d9c90396d636"], "84a037db-cea9-4f44-9971-d9c90396d636_2": ["84a037db-cea9-4f44-9971-d9c90396d636"], "2ed7e2e9-7c6f-401d-80ef-69c6eabf0cd6_1": ["2ed7e2e9-7c6f-401d-80ef-69c6eabf0cd6"], "2ed7e2e9-7c6f-401d-80ef-69c6eabf0cd6_2": ["2ed7e2e9-7c6f-401d-80ef-69c6eabf0cd6"], "828a4a33-7ba1-4355-b495-bc896d3d40bb_1": ["828a4a33-7ba1-4355-b495-bc896d3d40bb"], "828a4a33-7ba1-4355-b495-bc896d3d40bb_2": ["828a4a33-7ba1-4355-b495-bc896d3d40bb"], "e11aabba-876b-4e5d-8dfd-683a21d02b81_1": ["e11aabba-876b-4e5d-8dfd-683a21d02b81"], "e11aabba-876b-4e5d-8dfd-683a21d02b81_2": ["e11aabba-876b-4e5d-8dfd-683a21d02b81"], "dd8b8faa-b4a8-4812-b225-efceea41bb03_1": ["dd8b8faa-b4a8-4812-b225-efceea41bb03"], "dd8b8faa-b4a8-4812-b225-efceea41bb03_2": ["dd8b8faa-b4a8-4812-b225-efceea41bb03"], "599faa13-2fc4-4e30-ab66-711fc52e54e2_1": ["599faa13-2fc4-4e30-ab66-711fc52e54e2"], "599faa13-2fc4-4e30-ab66-711fc52e54e2_2": ["599faa13-2fc4-4e30-ab66-711fc52e54e2"], "a8d0fa93-f94d-46fc-8b7a-81a1a132bd33_1": ["a8d0fa93-f94d-46fc-8b7a-81a1a132bd33"], "a8d0fa93-f94d-46fc-8b7a-81a1a132bd33_2": ["a8d0fa93-f94d-46fc-8b7a-81a1a132bd33"], "6f5dcd2c-142a-4fc8-920b-0408006ce5b2_1": ["6f5dcd2c-142a-4fc8-920b-0408006ce5b2"], "6f5dcd2c-142a-4fc8-920b-0408006ce5b2_2": ["6f5dcd2c-142a-4fc8-920b-0408006ce5b2"], "401393da-6a24-44d2-9b1c-2453ae9b31eb_1": ["401393da-6a24-44d2-9b1c-2453ae9b31eb"], "401393da-6a24-44d2-9b1c-2453ae9b31eb_2": ["401393da-6a24-44d2-9b1c-2453ae9b31eb"], "4c495844-5525-4cab-aca0-e3c7581aa4ad_1": ["4c495844-5525-4cab-aca0-e3c7581aa4ad"], "4c495844-5525-4cab-aca0-e3c7581aa4ad_2": ["4c495844-5525-4cab-aca0-e3c7581aa4ad"], "c306f26c-02dd-4598-9ad5-2efab6ed561b_1": ["c306f26c-02dd-4598-9ad5-2efab6ed561b"], "c306f26c-02dd-4598-9ad5-2efab6ed561b_2": ["c306f26c-02dd-4598-9ad5-2efab6ed561b"], "5e260492-8376-4428-b409-2d6342289682_1": ["5e260492-8376-4428-b409-2d6342289682"], "5e260492-8376-4428-b409-2d6342289682_2": ["5e260492-8376-4428-b409-2d6342289682"], "ac776309-a022-4e73-80b1-43235cdf4a39_1": ["ac776309-a022-4e73-80b1-43235cdf4a39"], "ac776309-a022-4e73-80b1-43235cdf4a39_2": ["ac776309-a022-4e73-80b1-43235cdf4a39"], "2b264d72-b64d-4cd9-be29-ae642ae5b475_1": ["2b264d72-b64d-4cd9-be29-ae642ae5b475"], "2b264d72-b64d-4cd9-be29-ae642ae5b475_2": ["2b264d72-b64d-4cd9-be29-ae642ae5b475"], "c1919033-ef4b-4716-b2ac-4804490699bd_1": ["c1919033-ef4b-4716-b2ac-4804490699bd"], "c1919033-ef4b-4716-b2ac-4804490699bd_2": ["c1919033-ef4b-4716-b2ac-4804490699bd"], "bff772c4-5404-4e20-8222-33ec3537be57_1": ["bff772c4-5404-4e20-8222-33ec3537be57"], "bff772c4-5404-4e20-8222-33ec3537be57_2": ["bff772c4-5404-4e20-8222-33ec3537be57"], "f16e15db-1f21-4726-9763-40a8a6dc2c20_1": ["f16e15db-1f21-4726-9763-40a8a6dc2c20"], "f16e15db-1f21-4726-9763-40a8a6dc2c20_2": ["f16e15db-1f21-4726-9763-40a8a6dc2c20"], "4390d731-2f14-4c4f-aaa1-919e1f9a0332_1": ["4390d731-2f14-4c4f-aaa1-919e1f9a0332"], "4390d731-2f14-4c4f-aaa1-919e1f9a0332_2": ["4390d731-2f14-4c4f-aaa1-919e1f9a0332"], "e1e1be7b-91cb-447f-9005-9404702eaf14_1": ["e1e1be7b-91cb-447f-9005-9404702eaf14"], "e1e1be7b-91cb-447f-9005-9404702eaf14_2": ["e1e1be7b-91cb-447f-9005-9404702eaf14"], "1adc9709-c6a6-41a8-b150-7caf0d836b02_1": ["1adc9709-c6a6-41a8-b150-7caf0d836b02"], "1adc9709-c6a6-41a8-b150-7caf0d836b02_2": ["1adc9709-c6a6-41a8-b150-7caf0d836b02"], "52093311-f2d4-4234-812c-b2d589a6027d_1": ["52093311-f2d4-4234-812c-b2d589a6027d"], "52093311-f2d4-4234-812c-b2d589a6027d_2": ["52093311-f2d4-4234-812c-b2d589a6027d"], "ed7930bf-9528-4748-8549-518835584165_1": ["ed7930bf-9528-4748-8549-518835584165"], "ed7930bf-9528-4748-8549-518835584165_2": ["ed7930bf-9528-4748-8549-518835584165"], "f8de058e-1862-4e12-b132-0aafb363dc3b_1": ["f8de058e-1862-4e12-b132-0aafb363dc3b"], "f8de058e-1862-4e12-b132-0aafb363dc3b_2": ["f8de058e-1862-4e12-b132-0aafb363dc3b"], "d3a2c0bd-e970-495f-84f6-94b6a6c34514_1": ["d3a2c0bd-e970-495f-84f6-94b6a6c34514"], "d3a2c0bd-e970-495f-84f6-94b6a6c34514_2": ["d3a2c0bd-e970-495f-84f6-94b6a6c34514"], "690c57f5-80a0-4731-986f-16b098030aad_1": ["690c57f5-80a0-4731-986f-16b098030aad"], "690c57f5-80a0-4731-986f-16b098030aad_2": ["690c57f5-80a0-4731-986f-16b098030aad"], "9554f69c-8ed8-489e-b75b-15d50b2a613d_1": ["9554f69c-8ed8-489e-b75b-15d50b2a613d"], "9554f69c-8ed8-489e-b75b-15d50b2a613d_2": ["9554f69c-8ed8-489e-b75b-15d50b2a613d"], "9060fdba-e234-4794-9afb-01a585a090b8_1": ["9060fdba-e234-4794-9afb-01a585a090b8"], "9060fdba-e234-4794-9afb-01a585a090b8_2": ["9060fdba-e234-4794-9afb-01a585a090b8"], "8acf607f-6f26-4ef3-b9f5-45a10b9ef91b_1": ["8acf607f-6f26-4ef3-b9f5-45a10b9ef91b"], "8acf607f-6f26-4ef3-b9f5-45a10b9ef91b_2": ["8acf607f-6f26-4ef3-b9f5-45a10b9ef91b"], "c500fae5-e08d-499a-8459-ae483ab98017_1": ["c500fae5-e08d-499a-8459-ae483ab98017"], "c500fae5-e08d-499a-8459-ae483ab98017_2": ["c500fae5-e08d-499a-8459-ae483ab98017"], "0b241eff-f114-4a94-981b-0a8d35ebf737_1": ["0b241eff-f114-4a94-981b-0a8d35ebf737"], "0b241eff-f114-4a94-981b-0a8d35ebf737_2": ["0b241eff-f114-4a94-981b-0a8d35ebf737"], "475c60ab-d40e-4a79-aa69-368b1cf12a0e_1": ["475c60ab-d40e-4a79-aa69-368b1cf12a0e"], "475c60ab-d40e-4a79-aa69-368b1cf12a0e_2": ["475c60ab-d40e-4a79-aa69-368b1cf12a0e"], "10447d1e-046b-40db-9761-b4c52af2c271_1": ["10447d1e-046b-40db-9761-b4c52af2c271"], "10447d1e-046b-40db-9761-b4c52af2c271_2": ["10447d1e-046b-40db-9761-b4c52af2c271"], "525ff882-b6fc-471e-a237-2508c911df29_1": ["525ff882-b6fc-471e-a237-2508c911df29"], "525ff882-b6fc-471e-a237-2508c911df29_2": ["525ff882-b6fc-471e-a237-2508c911df29"], "a8b81568-9cb4-4620-839d-6480e10c3ded_1": ["a8b81568-9cb4-4620-839d-6480e10c3ded"], "a8b81568-9cb4-4620-839d-6480e10c3ded_2": ["a8b81568-9cb4-4620-839d-6480e10c3ded"], "3f62044a-91fb-43d1-8328-7258d1bb377f_1": ["3f62044a-91fb-43d1-8328-7258d1bb377f"], "3f62044a-91fb-43d1-8328-7258d1bb377f_2": ["3f62044a-91fb-43d1-8328-7258d1bb377f"], "9dd6783b-aef1-446f-aca5-174fe2733d29_1": ["9dd6783b-aef1-446f-aca5-174fe2733d29"], "9dd6783b-aef1-446f-aca5-174fe2733d29_2": ["9dd6783b-aef1-446f-aca5-174fe2733d29"], "96cc9754-62b9-4888-b353-41a418ee394a_1": ["96cc9754-62b9-4888-b353-41a418ee394a"], "96cc9754-62b9-4888-b353-41a418ee394a_2": ["96cc9754-62b9-4888-b353-41a418ee394a"], "311b5744-c4f0-4ad3-b85f-e9ce94e2a4ae_1": ["311b5744-c4f0-4ad3-b85f-e9ce94e2a4ae"], "311b5744-c4f0-4ad3-b85f-e9ce94e2a4ae_2": ["311b5744-c4f0-4ad3-b85f-e9ce94e2a4ae"], "cc4d0423-7f61-4e50-9f5a-db28947eeaeb_1": ["cc4d0423-7f61-4e50-9f5a-db28947eeaeb"], "cc4d0423-7f61-4e50-9f5a-db28947eeaeb_2": ["cc4d0423-7f61-4e50-9f5a-db28947eeaeb"], "9d1a63ee-1798-42df-bf1b-9243a354eee2_1": ["9d1a63ee-1798-42df-bf1b-9243a354eee2"], "9d1a63ee-1798-42df-bf1b-9243a354eee2_2": ["9d1a63ee-1798-42df-bf1b-9243a354eee2"], "a7db17a0-0844-42e2-bd83-98531aa2146f_1": ["a7db17a0-0844-42e2-bd83-98531aa2146f"], "a7db17a0-0844-42e2-bd83-98531aa2146f_2": ["a7db17a0-0844-42e2-bd83-98531aa2146f"], "ec1cc028-c6b5-4ed3-8ead-795e8b203bed_1": ["ec1cc028-c6b5-4ed3-8ead-795e8b203bed"], "ec1cc028-c6b5-4ed3-8ead-795e8b203bed_2": ["ec1cc028-c6b5-4ed3-8ead-795e8b203bed"], "603b8fca-56e9-45da-a574-61838e07c474_1": ["603b8fca-56e9-45da-a574-61838e07c474"], "603b8fca-56e9-45da-a574-61838e07c474_2": ["603b8fca-56e9-45da-a574-61838e07c474"], "eeabe14f-572d-4d36-85f1-71cf7a135b3e_1": ["eeabe14f-572d-4d36-85f1-71cf7a135b3e"], "eeabe14f-572d-4d36-85f1-71cf7a135b3e_2": ["eeabe14f-572d-4d36-85f1-71cf7a135b3e"], "ccfb41a6-06a6-4fee-b3c1-b70941cef395_1": ["ccfb41a6-06a6-4fee-b3c1-b70941cef395"], "ccfb41a6-06a6-4fee-b3c1-b70941cef395_2": ["ccfb41a6-06a6-4fee-b3c1-b70941cef395"], "c495760e-bd11-4d71-9b4d-648374fb9be3_1": ["c495760e-bd11-4d71-9b4d-648374fb9be3"], "c495760e-bd11-4d71-9b4d-648374fb9be3_2": ["c495760e-bd11-4d71-9b4d-648374fb9be3"], "6cbc7310-fad5-4058-9ab8-d9bc441034de_1": ["6cbc7310-fad5-4058-9ab8-d9bc441034de"], "6cbc7310-fad5-4058-9ab8-d9bc441034de_2": ["6cbc7310-fad5-4058-9ab8-d9bc441034de"], "29ef6af6-d911-464f-850a-2881c349bb97_1": ["29ef6af6-d911-464f-850a-2881c349bb97"], "29ef6af6-d911-464f-850a-2881c349bb97_2": ["29ef6af6-d911-464f-850a-2881c349bb97"], "ba38e80a-f524-42bf-b718-7523d101d31d_1": ["ba38e80a-f524-42bf-b718-7523d101d31d"], "ba38e80a-f524-42bf-b718-7523d101d31d_2": ["ba38e80a-f524-42bf-b718-7523d101d31d"], "16896240-a88f-4095-950e-064720eb2ed4_1": ["16896240-a88f-4095-950e-064720eb2ed4"], "16896240-a88f-4095-950e-064720eb2ed4_2": ["16896240-a88f-4095-950e-064720eb2ed4"], "fce722e6-04a3-4c23-b66d-fa86b3e5ac2a_1": ["fce722e6-04a3-4c23-b66d-fa86b3e5ac2a"], "fce722e6-04a3-4c23-b66d-fa86b3e5ac2a_2": ["fce722e6-04a3-4c23-b66d-fa86b3e5ac2a"], "24ca8649-3a2a-4911-9c22-7a26feb8f32c_1": ["24ca8649-3a2a-4911-9c22-7a26feb8f32c"], "24ca8649-3a2a-4911-9c22-7a26feb8f32c_2": ["24ca8649-3a2a-4911-9c22-7a26feb8f32c"], "56b4723a-5f37-4433-8284-3a2f6af98581_1": ["56b4723a-5f37-4433-8284-3a2f6af98581"], "56b4723a-5f37-4433-8284-3a2f6af98581_2": ["56b4723a-5f37-4433-8284-3a2f6af98581"], "60e3c0f6-359c-4e72-aa39-9bc6946a011f_1": ["60e3c0f6-359c-4e72-aa39-9bc6946a011f"], "60e3c0f6-359c-4e72-aa39-9bc6946a011f_2": ["60e3c0f6-359c-4e72-aa39-9bc6946a011f"], "bc4b39dd-5dea-44a1-96e2-58bc872d03ab_1": ["bc4b39dd-5dea-44a1-96e2-58bc872d03ab"], "bc4b39dd-5dea-44a1-96e2-58bc872d03ab_2": ["bc4b39dd-5dea-44a1-96e2-58bc872d03ab"], "84ca0df8-85b1-45a3-8c9e-79b373987623_1": ["84ca0df8-85b1-45a3-8c9e-79b373987623"], "84ca0df8-85b1-45a3-8c9e-79b373987623_2": ["84ca0df8-85b1-45a3-8c9e-79b373987623"], "5dff4530-1ff6-4a3f-b9e7-3e75aab0fb1c_1": ["5dff4530-1ff6-4a3f-b9e7-3e75aab0fb1c"], "5dff4530-1ff6-4a3f-b9e7-3e75aab0fb1c_2": ["5dff4530-1ff6-4a3f-b9e7-3e75aab0fb1c"], "8e8cf8c6-0d64-4a12-8671-01ab73aabda5_1": ["8e8cf8c6-0d64-4a12-8671-01ab73aabda5"], "8e8cf8c6-0d64-4a12-8671-01ab73aabda5_2": ["8e8cf8c6-0d64-4a12-8671-01ab73aabda5"], "55480cb7-a3d5-4f14-af37-7ead5662435c_1": ["55480cb7-a3d5-4f14-af37-7ead5662435c"], "55480cb7-a3d5-4f14-af37-7ead5662435c_2": ["55480cb7-a3d5-4f14-af37-7ead5662435c"], "2f9ab334-4d57-4956-823b-9eab20ca50ed_1": ["2f9ab334-4d57-4956-823b-9eab20ca50ed"], "2f9ab334-4d57-4956-823b-9eab20ca50ed_2": ["2f9ab334-4d57-4956-823b-9eab20ca50ed"], "c892c84a-441a-4446-8d33-32482d0268bd_1": ["c892c84a-441a-4446-8d33-32482d0268bd"], "c892c84a-441a-4446-8d33-32482d0268bd_2": ["c892c84a-441a-4446-8d33-32482d0268bd"], "fb52d600-4eb2-4e60-8460-2a0b715b901b_1": ["fb52d600-4eb2-4e60-8460-2a0b715b901b"], "fb52d600-4eb2-4e60-8460-2a0b715b901b_2": ["fb52d600-4eb2-4e60-8460-2a0b715b901b"], "ecc7f906-cf45-4cdb-9805-4ca65d930bd3_1": ["ecc7f906-cf45-4cdb-9805-4ca65d930bd3"], "ecc7f906-cf45-4cdb-9805-4ca65d930bd3_2": ["ecc7f906-cf45-4cdb-9805-4ca65d930bd3"], "4c5dc65b-62aa-49c5-aa0c-034a5acea392_1": ["4c5dc65b-62aa-49c5-aa0c-034a5acea392"], "4c5dc65b-62aa-49c5-aa0c-034a5acea392_2": ["4c5dc65b-62aa-49c5-aa0c-034a5acea392"], "8f8d9ed7-e52a-45fe-b9dc-06dec8ed9b77_1": ["8f8d9ed7-e52a-45fe-b9dc-06dec8ed9b77"], "8f8d9ed7-e52a-45fe-b9dc-06dec8ed9b77_2": ["8f8d9ed7-e52a-45fe-b9dc-06dec8ed9b77"], "b0c6c6e4-2da0-49ec-8eba-d0c7e804bc63_1": ["b0c6c6e4-2da0-49ec-8eba-d0c7e804bc63"], "b0c6c6e4-2da0-49ec-8eba-d0c7e804bc63_2": ["b0c6c6e4-2da0-49ec-8eba-d0c7e804bc63"], "bf1251e9-dc28-4c1c-9027-614b6b041c98_1": ["bf1251e9-dc28-4c1c-9027-614b6b041c98"], "bf1251e9-dc28-4c1c-9027-614b6b041c98_2": ["bf1251e9-dc28-4c1c-9027-614b6b041c98"], "4661cc35-825c-433f-9cb2-5dce09a5221e_1": ["4661cc35-825c-433f-9cb2-5dce09a5221e"], "4661cc35-825c-433f-9cb2-5dce09a5221e_2": ["4661cc35-825c-433f-9cb2-5dce09a5221e"], "470c75c6-cd81-478b-b24e-7b8e3dd87d24_1": ["470c75c6-cd81-478b-b24e-7b8e3dd87d24"], "470c75c6-cd81-478b-b24e-7b8e3dd87d24_2": ["470c75c6-cd81-478b-b24e-7b8e3dd87d24"], "027a71e7-8f08-425c-a75f-21f0d2686848_1": ["027a71e7-8f08-425c-a75f-21f0d2686848"], "027a71e7-8f08-425c-a75f-21f0d2686848_2": ["027a71e7-8f08-425c-a75f-21f0d2686848"], "7f80c238-3fc8-442d-b4d8-8b6951453847_1": ["7f80c238-3fc8-442d-b4d8-8b6951453847"], "7f80c238-3fc8-442d-b4d8-8b6951453847_2": ["7f80c238-3fc8-442d-b4d8-8b6951453847"], "eef2691e-1cc7-48ed-b137-4715e94324d4_1": ["eef2691e-1cc7-48ed-b137-4715e94324d4"], "eef2691e-1cc7-48ed-b137-4715e94324d4_2": ["eef2691e-1cc7-48ed-b137-4715e94324d4"], "fdded924-58f7-401a-bec9-ca76d9ec82b3_1": ["fdded924-58f7-401a-bec9-ca76d9ec82b3"], "fdded924-58f7-401a-bec9-ca76d9ec82b3_2": ["fdded924-58f7-401a-bec9-ca76d9ec82b3"], "f0f9e11f-6729-473c-ab75-1c62e99d705a_1": ["f0f9e11f-6729-473c-ab75-1c62e99d705a"], "f0f9e11f-6729-473c-ab75-1c62e99d705a_2": ["f0f9e11f-6729-473c-ab75-1c62e99d705a"], "a986561a-360e-48e7-beb9-87037aa7cd47_1": ["a986561a-360e-48e7-beb9-87037aa7cd47"], "a986561a-360e-48e7-beb9-87037aa7cd47_2": ["a986561a-360e-48e7-beb9-87037aa7cd47"], "ec31d62b-7e61-4ed9-b789-1c9702ab5e86_1": ["ec31d62b-7e61-4ed9-b789-1c9702ab5e86"], "ec31d62b-7e61-4ed9-b789-1c9702ab5e86_2": ["ec31d62b-7e61-4ed9-b789-1c9702ab5e86"], "ead55ff2-d1e6-4be6-8dc6-928bd07db5e8_1": ["ead55ff2-d1e6-4be6-8dc6-928bd07db5e8"], "ead55ff2-d1e6-4be6-8dc6-928bd07db5e8_2": ["ead55ff2-d1e6-4be6-8dc6-928bd07db5e8"], "34e252d7-c874-4327-89f3-30eeac1b5ee3_1": ["34e252d7-c874-4327-89f3-30eeac1b5ee3"], "34e252d7-c874-4327-89f3-30eeac1b5ee3_2": ["34e252d7-c874-4327-89f3-30eeac1b5ee3"], "e41566f6-9a2d-47ed-b372-d0b820bad2d4_1": ["e41566f6-9a2d-47ed-b372-d0b820bad2d4"], "e41566f6-9a2d-47ed-b372-d0b820bad2d4_2": ["e41566f6-9a2d-47ed-b372-d0b820bad2d4"], "5ef66507-d7c7-40c2-9289-49e5da0ecfe2_1": ["5ef66507-d7c7-40c2-9289-49e5da0ecfe2"], "5ef66507-d7c7-40c2-9289-49e5da0ecfe2_2": ["5ef66507-d7c7-40c2-9289-49e5da0ecfe2"], "70d312e2-f894-4c1d-a040-551ad2f77bce_1": ["70d312e2-f894-4c1d-a040-551ad2f77bce"], "70d312e2-f894-4c1d-a040-551ad2f77bce_2": ["70d312e2-f894-4c1d-a040-551ad2f77bce"], "e1f0b86a-6aea-46a8-9a60-ccd7898b473e_1": ["e1f0b86a-6aea-46a8-9a60-ccd7898b473e"], "e1f0b86a-6aea-46a8-9a60-ccd7898b473e_2": ["e1f0b86a-6aea-46a8-9a60-ccd7898b473e"], "4f92e1d1-c593-412c-94cd-1386429cf49c_1": ["4f92e1d1-c593-412c-94cd-1386429cf49c"], "4f92e1d1-c593-412c-94cd-1386429cf49c_2": ["4f92e1d1-c593-412c-94cd-1386429cf49c"], "3b5de4a3-2641-4153-a259-a68f706b139a_1": ["3b5de4a3-2641-4153-a259-a68f706b139a"], "3b5de4a3-2641-4153-a259-a68f706b139a_2": ["3b5de4a3-2641-4153-a259-a68f706b139a"], "1e7debda-9c18-4cc9-814b-19b1db54e4b9_1": ["1e7debda-9c18-4cc9-814b-19b1db54e4b9"], "1e7debda-9c18-4cc9-814b-19b1db54e4b9_2": ["1e7debda-9c18-4cc9-814b-19b1db54e4b9"], "8941f80b-a71d-479f-8357-03ad122aa90d_1": ["8941f80b-a71d-479f-8357-03ad122aa90d"], "8941f80b-a71d-479f-8357-03ad122aa90d_2": ["8941f80b-a71d-479f-8357-03ad122aa90d"], "5fc30f25-9335-4bfc-b5e5-8b5cae07975b_1": ["5fc30f25-9335-4bfc-b5e5-8b5cae07975b"], "5fc30f25-9335-4bfc-b5e5-8b5cae07975b_2": ["5fc30f25-9335-4bfc-b5e5-8b5cae07975b"], "220d232d-3757-40bd-9588-e757400f2ed5_1": ["220d232d-3757-40bd-9588-e757400f2ed5"], "220d232d-3757-40bd-9588-e757400f2ed5_2": ["220d232d-3757-40bd-9588-e757400f2ed5"], "6b0ac03e-f44d-4868-a741-80cb6dc7296b_1": ["6b0ac03e-f44d-4868-a741-80cb6dc7296b"], "6b0ac03e-f44d-4868-a741-80cb6dc7296b_2": ["6b0ac03e-f44d-4868-a741-80cb6dc7296b"], "bb65b911-cb4a-4ab2-915d-e9f975f33586_1": ["bb65b911-cb4a-4ab2-915d-e9f975f33586"], "bb65b911-cb4a-4ab2-915d-e9f975f33586_2": ["bb65b911-cb4a-4ab2-915d-e9f975f33586"], "5fb441cd-74d2-4a60-8a18-528ce7122a5c_1": ["5fb441cd-74d2-4a60-8a18-528ce7122a5c"], "5fb441cd-74d2-4a60-8a18-528ce7122a5c_2": ["5fb441cd-74d2-4a60-8a18-528ce7122a5c"], "3e409470-ef0d-43c8-9078-242397bef7ce_1": ["3e409470-ef0d-43c8-9078-242397bef7ce"], "3e409470-ef0d-43c8-9078-242397bef7ce_2": ["3e409470-ef0d-43c8-9078-242397bef7ce"], "62c7f759-9cb8-4901-b188-1f5a6a3383a1_1": ["62c7f759-9cb8-4901-b188-1f5a6a3383a1"], "62c7f759-9cb8-4901-b188-1f5a6a3383a1_2": ["62c7f759-9cb8-4901-b188-1f5a6a3383a1"], "e5d65906-f021-4a13-a6c8-1872aee38996_1": ["e5d65906-f021-4a13-a6c8-1872aee38996"], "e5d65906-f021-4a13-a6c8-1872aee38996_2": ["e5d65906-f021-4a13-a6c8-1872aee38996"], "5c96aa32-1661-4120-ad69-d39e8078e14f_1": ["5c96aa32-1661-4120-ad69-d39e8078e14f"], "5c96aa32-1661-4120-ad69-d39e8078e14f_2": ["5c96aa32-1661-4120-ad69-d39e8078e14f"], "d4b3b7ec-6902-4416-9a54-1256fae020c6_1": ["d4b3b7ec-6902-4416-9a54-1256fae020c6"], "d4b3b7ec-6902-4416-9a54-1256fae020c6_2": ["d4b3b7ec-6902-4416-9a54-1256fae020c6"], "bba97538-3a78-4be9-bee1-81cefd7e7bf6_1": ["bba97538-3a78-4be9-bee1-81cefd7e7bf6"], "bba97538-3a78-4be9-bee1-81cefd7e7bf6_2": ["bba97538-3a78-4be9-bee1-81cefd7e7bf6"], "c3c68ad8-ef3a-4d32-a617-33b56e18d825_1": ["c3c68ad8-ef3a-4d32-a617-33b56e18d825"], "c3c68ad8-ef3a-4d32-a617-33b56e18d825_2": ["c3c68ad8-ef3a-4d32-a617-33b56e18d825"], "0581c2b2-5c4d-491e-b8e2-44bf8fae2a05_1": ["0581c2b2-5c4d-491e-b8e2-44bf8fae2a05"], "0581c2b2-5c4d-491e-b8e2-44bf8fae2a05_2": ["0581c2b2-5c4d-491e-b8e2-44bf8fae2a05"], "430134fc-390d-4594-af75-468053ae0d63_1": ["430134fc-390d-4594-af75-468053ae0d63"], "430134fc-390d-4594-af75-468053ae0d63_2": ["430134fc-390d-4594-af75-468053ae0d63"], "3e8ab056-45e3-44aa-9ae8-598391fe320f_1": ["3e8ab056-45e3-44aa-9ae8-598391fe320f"], "3e8ab056-45e3-44aa-9ae8-598391fe320f_2": ["3e8ab056-45e3-44aa-9ae8-598391fe320f"], "7820dd1c-b91f-4d5a-9797-8e03b791798e_1": ["7820dd1c-b91f-4d5a-9797-8e03b791798e"], "7820dd1c-b91f-4d5a-9797-8e03b791798e_2": ["7820dd1c-b91f-4d5a-9797-8e03b791798e"], "95e71866-dd41-4c03-8e47-03785df2f0d9_1": ["95e71866-dd41-4c03-8e47-03785df2f0d9"], "95e71866-dd41-4c03-8e47-03785df2f0d9_2": ["95e71866-dd41-4c03-8e47-03785df2f0d9"], "1f185603-4a6b-4da7-9125-cb9f26353814_1": ["1f185603-4a6b-4da7-9125-cb9f26353814"], "1f185603-4a6b-4da7-9125-cb9f26353814_2": ["1f185603-4a6b-4da7-9125-cb9f26353814"], "f7553446-3508-4029-a051-79609e731f77_1": ["f7553446-3508-4029-a051-79609e731f77"], "f7553446-3508-4029-a051-79609e731f77_2": ["f7553446-3508-4029-a051-79609e731f77"], "602e81cb-3dc4-4ab1-a349-1b080c24381d_1": ["602e81cb-3dc4-4ab1-a349-1b080c24381d"], "602e81cb-3dc4-4ab1-a349-1b080c24381d_2": ["602e81cb-3dc4-4ab1-a349-1b080c24381d"], "ca02d308-3272-408e-933d-6a6d1ed8203d_1": ["ca02d308-3272-408e-933d-6a6d1ed8203d"], "ca02d308-3272-408e-933d-6a6d1ed8203d_2": ["ca02d308-3272-408e-933d-6a6d1ed8203d"], "289b8b06-49a6-45b5-a48c-93c990252809_1": ["289b8b06-49a6-45b5-a48c-93c990252809"], "289b8b06-49a6-45b5-a48c-93c990252809_2": ["289b8b06-49a6-45b5-a48c-93c990252809"], "835dfd47-b745-430a-83c8-cdb328fde0f0_1": ["835dfd47-b745-430a-83c8-cdb328fde0f0"], "835dfd47-b745-430a-83c8-cdb328fde0f0_2": ["835dfd47-b745-430a-83c8-cdb328fde0f0"], "cafbdf81-f1b5-4945-810d-e10e48132be9_1": ["cafbdf81-f1b5-4945-810d-e10e48132be9"], "cafbdf81-f1b5-4945-810d-e10e48132be9_2": ["cafbdf81-f1b5-4945-810d-e10e48132be9"], "1d058472-4335-4e50-80c8-0b02499fa382_1": ["1d058472-4335-4e50-80c8-0b02499fa382"], "1d058472-4335-4e50-80c8-0b02499fa382_2": ["1d058472-4335-4e50-80c8-0b02499fa382"], "2c886e68-248f-44ab-a137-bebe1bbc4b90_1": ["2c886e68-248f-44ab-a137-bebe1bbc4b90"], "2c886e68-248f-44ab-a137-bebe1bbc4b90_2": ["2c886e68-248f-44ab-a137-bebe1bbc4b90"], "02a26c28-7802-4101-a4c9-6f21c83fa025_1": ["02a26c28-7802-4101-a4c9-6f21c83fa025"], "02a26c28-7802-4101-a4c9-6f21c83fa025_2": ["02a26c28-7802-4101-a4c9-6f21c83fa025"], "92f8795c-a8f8-441a-8d0f-a9e11840a3d6_1": ["92f8795c-a8f8-441a-8d0f-a9e11840a3d6"], "92f8795c-a8f8-441a-8d0f-a9e11840a3d6_2": ["92f8795c-a8f8-441a-8d0f-a9e11840a3d6"], "7e9d066f-08d2-4094-ba40-0b4a7e51d990_1": ["7e9d066f-08d2-4094-ba40-0b4a7e51d990"], "7e9d066f-08d2-4094-ba40-0b4a7e51d990_2": ["7e9d066f-08d2-4094-ba40-0b4a7e51d990"], "04802aba-c172-4119-a321-1b9391d4733d_1": ["04802aba-c172-4119-a321-1b9391d4733d"], "04802aba-c172-4119-a321-1b9391d4733d_2": ["04802aba-c172-4119-a321-1b9391d4733d"], "00faaef0-e776-484d-a329-07a7d085de24_1": ["00faaef0-e776-484d-a329-07a7d085de24"], "00faaef0-e776-484d-a329-07a7d085de24_2": ["00faaef0-e776-484d-a329-07a7d085de24"], "cb2cf1b0-d4c1-4deb-a6b3-af1743ecef7f_1": ["cb2cf1b0-d4c1-4deb-a6b3-af1743ecef7f"], "cb2cf1b0-d4c1-4deb-a6b3-af1743ecef7f_2": ["cb2cf1b0-d4c1-4deb-a6b3-af1743ecef7f"], "811b47c1-c491-4e11-b1cf-fde37a1d35e9_1": ["811b47c1-c491-4e11-b1cf-fde37a1d35e9"], "811b47c1-c491-4e11-b1cf-fde37a1d35e9_2": ["811b47c1-c491-4e11-b1cf-fde37a1d35e9"], "a46adb8f-f78a-466e-8c6d-b4296c849ca8_1": ["a46adb8f-f78a-466e-8c6d-b4296c849ca8"], "a46adb8f-f78a-466e-8c6d-b4296c849ca8_2": ["a46adb8f-f78a-466e-8c6d-b4296c849ca8"], "a1c3f7a7-f72f-48e4-9364-6583bd972bc0_1": ["a1c3f7a7-f72f-48e4-9364-6583bd972bc0"], "a1c3f7a7-f72f-48e4-9364-6583bd972bc0_2": ["a1c3f7a7-f72f-48e4-9364-6583bd972bc0"], "3bc83b38-a0a2-480c-9107-84a200b23a90_1": ["3bc83b38-a0a2-480c-9107-84a200b23a90"], "3bc83b38-a0a2-480c-9107-84a200b23a90_2": ["3bc83b38-a0a2-480c-9107-84a200b23a90"], "8e35abe2-146d-4b6d-a89f-85a1622e77e9_1": ["8e35abe2-146d-4b6d-a89f-85a1622e77e9"], "8e35abe2-146d-4b6d-a89f-85a1622e77e9_2": ["8e35abe2-146d-4b6d-a89f-85a1622e77e9"], "6477776e-d4bc-468e-9eb0-a0344590fb46_1": ["6477776e-d4bc-468e-9eb0-a0344590fb46"], "6477776e-d4bc-468e-9eb0-a0344590fb46_2": ["6477776e-d4bc-468e-9eb0-a0344590fb46"], "f2f97beb-ab11-4a13-aab0-c1a3801e7fbf_1": ["f2f97beb-ab11-4a13-aab0-c1a3801e7fbf"], "f2f97beb-ab11-4a13-aab0-c1a3801e7fbf_2": ["f2f97beb-ab11-4a13-aab0-c1a3801e7fbf"], "ca9d3ce6-52e5-4793-8b80-15470d1b6649_1": ["ca9d3ce6-52e5-4793-8b80-15470d1b6649"], "ca9d3ce6-52e5-4793-8b80-15470d1b6649_2": ["ca9d3ce6-52e5-4793-8b80-15470d1b6649"], "31db808a-c9b8-41cd-8ae6-486da8608489_1": ["31db808a-c9b8-41cd-8ae6-486da8608489"], "31db808a-c9b8-41cd-8ae6-486da8608489_2": ["31db808a-c9b8-41cd-8ae6-486da8608489"], "27e57bb0-1c08-4180-85cb-d66d23396007_1": ["27e57bb0-1c08-4180-85cb-d66d23396007"], "27e57bb0-1c08-4180-85cb-d66d23396007_2": ["27e57bb0-1c08-4180-85cb-d66d23396007"], "df5e4bff-4d76-426b-8243-be141247b730_1": ["df5e4bff-4d76-426b-8243-be141247b730"], "df5e4bff-4d76-426b-8243-be141247b730_2": ["df5e4bff-4d76-426b-8243-be141247b730"], "582b6172-deda-47f4-89fe-fbedf6626275_1": ["582b6172-deda-47f4-89fe-fbedf6626275"], "582b6172-deda-47f4-89fe-fbedf6626275_2": ["582b6172-deda-47f4-89fe-fbedf6626275"], "0726c866-76ba-46af-a279-d3a7b89276e2_1": ["0726c866-76ba-46af-a279-d3a7b89276e2"], "0726c866-76ba-46af-a279-d3a7b89276e2_2": ["0726c866-76ba-46af-a279-d3a7b89276e2"], "22919863-ac88-4830-923d-96448d4e7a87_1": ["22919863-ac88-4830-923d-96448d4e7a87"], "22919863-ac88-4830-923d-96448d4e7a87_2": ["22919863-ac88-4830-923d-96448d4e7a87"], "d67356ca-c226-4a81-af3a-f58c97f2c835_1": ["d67356ca-c226-4a81-af3a-f58c97f2c835"], "d67356ca-c226-4a81-af3a-f58c97f2c835_2": ["d67356ca-c226-4a81-af3a-f58c97f2c835"], "48e5418d-9fcb-4e41-bba9-adabb44736ff_1": ["48e5418d-9fcb-4e41-bba9-adabb44736ff"], "48e5418d-9fcb-4e41-bba9-adabb44736ff_2": ["48e5418d-9fcb-4e41-bba9-adabb44736ff"], "c3e89a77-6d74-42ea-8c95-29b74c56146d_1": ["c3e89a77-6d74-42ea-8c95-29b74c56146d"], "c3e89a77-6d74-42ea-8c95-29b74c56146d_2": ["c3e89a77-6d74-42ea-8c95-29b74c56146d"], "47bde0f7-5a8a-44cb-9b21-2d284bf1feba_1": ["47bde0f7-5a8a-44cb-9b21-2d284bf1feba"], "47bde0f7-5a8a-44cb-9b21-2d284bf1feba_2": ["47bde0f7-5a8a-44cb-9b21-2d284bf1feba"], "ad61bff8-771e-4a84-b01c-212ea183c0eb_1": ["ad61bff8-771e-4a84-b01c-212ea183c0eb"], "ad61bff8-771e-4a84-b01c-212ea183c0eb_2": ["ad61bff8-771e-4a84-b01c-212ea183c0eb"], "408348ef-38a3-4de3-b1f3-22c4e9aa7158_1": ["408348ef-38a3-4de3-b1f3-22c4e9aa7158"], "408348ef-38a3-4de3-b1f3-22c4e9aa7158_2": ["408348ef-38a3-4de3-b1f3-22c4e9aa7158"], "30731cfd-0d5c-4f12-8e21-3a22a58f0b01_1": ["30731cfd-0d5c-4f12-8e21-3a22a58f0b01"], "30731cfd-0d5c-4f12-8e21-3a22a58f0b01_2": ["30731cfd-0d5c-4f12-8e21-3a22a58f0b01"], "12c2ede9-108a-4057-8328-96d31f41307c_1": ["12c2ede9-108a-4057-8328-96d31f41307c"], "12c2ede9-108a-4057-8328-96d31f41307c_2": ["12c2ede9-108a-4057-8328-96d31f41307c"], "fabad0c7-5c2e-4821-8bd7-039c4cddfd59_1": ["fabad0c7-5c2e-4821-8bd7-039c4cddfd59"], "fabad0c7-5c2e-4821-8bd7-039c4cddfd59_2": ["fabad0c7-5c2e-4821-8bd7-039c4cddfd59"], "7c806454-5881-4ab0-8a60-fdbb9b42cb2e_1": ["7c806454-5881-4ab0-8a60-fdbb9b42cb2e"], "7c806454-5881-4ab0-8a60-fdbb9b42cb2e_2": ["7c806454-5881-4ab0-8a60-fdbb9b42cb2e"], "3448d00b-754c-4d34-8ea3-e6ccd31b4e8a_1": ["3448d00b-754c-4d34-8ea3-e6ccd31b4e8a"], "3448d00b-754c-4d34-8ea3-e6ccd31b4e8a_2": ["3448d00b-754c-4d34-8ea3-e6ccd31b4e8a"], "76fb387d-2fba-450e-9fb4-e8bbe63f306a_1": ["76fb387d-2fba-450e-9fb4-e8bbe63f306a"], "76fb387d-2fba-450e-9fb4-e8bbe63f306a_2": ["76fb387d-2fba-450e-9fb4-e8bbe63f306a"], "8c1427f1-545d-4fe7-a656-9cb5a91f3c24_1": ["8c1427f1-545d-4fe7-a656-9cb5a91f3c24"], "8c1427f1-545d-4fe7-a656-9cb5a91f3c24_2": ["8c1427f1-545d-4fe7-a656-9cb5a91f3c24"], "c642e842-06e9-4526-9466-3da15fd1a631_1": ["c642e842-06e9-4526-9466-3da15fd1a631"], "c642e842-06e9-4526-9466-3da15fd1a631_2": ["c642e842-06e9-4526-9466-3da15fd1a631"], "f2ef7556-455a-4cfa-b8ec-c36eabbb529a_1": ["f2ef7556-455a-4cfa-b8ec-c36eabbb529a"], "f2ef7556-455a-4cfa-b8ec-c36eabbb529a_2": ["f2ef7556-455a-4cfa-b8ec-c36eabbb529a"], "eb19e38f-c333-425b-8c94-ccc6a3f3b35c_1": ["eb19e38f-c333-425b-8c94-ccc6a3f3b35c"], "eb19e38f-c333-425b-8c94-ccc6a3f3b35c_2": ["eb19e38f-c333-425b-8c94-ccc6a3f3b35c"], "909121a0-809a-4703-997b-534ec295bfe2_1": ["909121a0-809a-4703-997b-534ec295bfe2"], "909121a0-809a-4703-997b-534ec295bfe2_2": ["909121a0-809a-4703-997b-534ec295bfe2"], "8832388e-f791-4346-85ab-5c50265f977b_1": ["8832388e-f791-4346-85ab-5c50265f977b"], "8832388e-f791-4346-85ab-5c50265f977b_2": ["8832388e-f791-4346-85ab-5c50265f977b"], "5cb384b0-7012-438f-a9be-5f10428e5e18_1": ["5cb384b0-7012-438f-a9be-5f10428e5e18"], "5cb384b0-7012-438f-a9be-5f10428e5e18_2": ["5cb384b0-7012-438f-a9be-5f10428e5e18"], "7a369c62-5f27-4181-92d1-8b0f59b4ccec_1": ["7a369c62-5f27-4181-92d1-8b0f59b4ccec"], "7a369c62-5f27-4181-92d1-8b0f59b4ccec_2": ["7a369c62-5f27-4181-92d1-8b0f59b4ccec"], "4b97b7b3-e790-43e5-ab36-febac372cf09_1": ["4b97b7b3-e790-43e5-ab36-febac372cf09"], "4b97b7b3-e790-43e5-ab36-febac372cf09_2": ["4b97b7b3-e790-43e5-ab36-febac372cf09"], "34a84df8-0355-4e2b-8480-289f6449b6b2_1": ["34a84df8-0355-4e2b-8480-289f6449b6b2"], "34a84df8-0355-4e2b-8480-289f6449b6b2_2": ["34a84df8-0355-4e2b-8480-289f6449b6b2"], "3523be37-e363-42c7-939f-daa70e3a3f76_1": ["3523be37-e363-42c7-939f-daa70e3a3f76"], "3523be37-e363-42c7-939f-daa70e3a3f76_2": ["3523be37-e363-42c7-939f-daa70e3a3f76"], "8aef759e-75d9-4b21-ad82-aa48190a3094_1": ["8aef759e-75d9-4b21-ad82-aa48190a3094"], "8aef759e-75d9-4b21-ad82-aa48190a3094_2": ["8aef759e-75d9-4b21-ad82-aa48190a3094"], "0030999d-3f51-4c92-8843-acdfec24b24d_1": ["0030999d-3f51-4c92-8843-acdfec24b24d"], "0030999d-3f51-4c92-8843-acdfec24b24d_2": ["0030999d-3f51-4c92-8843-acdfec24b24d"], "2882a36b-aa0e-4fb5-a523-b1df08eff13c_1": ["2882a36b-aa0e-4fb5-a523-b1df08eff13c"], "2882a36b-aa0e-4fb5-a523-b1df08eff13c_2": ["2882a36b-aa0e-4fb5-a523-b1df08eff13c"], "0c3242a1-26c6-4995-b0bb-c8ce7fe4b62e_1": ["0c3242a1-26c6-4995-b0bb-c8ce7fe4b62e"], "0c3242a1-26c6-4995-b0bb-c8ce7fe4b62e_2": ["0c3242a1-26c6-4995-b0bb-c8ce7fe4b62e"], "ab6f96c5-e62c-49c9-9ef3-40e3d52262a5_1": ["ab6f96c5-e62c-49c9-9ef3-40e3d52262a5"], "ab6f96c5-e62c-49c9-9ef3-40e3d52262a5_2": ["ab6f96c5-e62c-49c9-9ef3-40e3d52262a5"], "3d9ea148-1da7-4794-a0be-d46127db5fe1_1": ["3d9ea148-1da7-4794-a0be-d46127db5fe1"], "3d9ea148-1da7-4794-a0be-d46127db5fe1_2": ["3d9ea148-1da7-4794-a0be-d46127db5fe1"], "2efaeb1b-fc8f-481d-a0f9-7197de12900f_1": ["2efaeb1b-fc8f-481d-a0f9-7197de12900f"], "2efaeb1b-fc8f-481d-a0f9-7197de12900f_2": ["2efaeb1b-fc8f-481d-a0f9-7197de12900f"], "4e4dee20-014c-47df-ba83-83dfabf81a87_1": ["4e4dee20-014c-47df-ba83-83dfabf81a87"], "4e4dee20-014c-47df-ba83-83dfabf81a87_2": ["4e4dee20-014c-47df-ba83-83dfabf81a87"], "aa897bbf-b49c-4240-84ae-a95909d0fa2a_1": ["aa897bbf-b49c-4240-84ae-a95909d0fa2a"], "aa897bbf-b49c-4240-84ae-a95909d0fa2a_2": ["aa897bbf-b49c-4240-84ae-a95909d0fa2a"], "7ca0feb2-1180-4329-9b5c-2cf8a01d3d4e_1": ["7ca0feb2-1180-4329-9b5c-2cf8a01d3d4e"], "7ca0feb2-1180-4329-9b5c-2cf8a01d3d4e_2": ["7ca0feb2-1180-4329-9b5c-2cf8a01d3d4e"], "ba84c47f-3661-4aba-adc6-70437c689443_1": ["ba84c47f-3661-4aba-adc6-70437c689443"], "ba84c47f-3661-4aba-adc6-70437c689443_2": ["ba84c47f-3661-4aba-adc6-70437c689443"], "6633a03a-588f-4a42-aa2e-f51003b14b90_1": ["6633a03a-588f-4a42-aa2e-f51003b14b90"], "6633a03a-588f-4a42-aa2e-f51003b14b90_2": ["6633a03a-588f-4a42-aa2e-f51003b14b90"], "096b7785-5989-4767-bce6-b1eeb5bfd57a_1": ["096b7785-5989-4767-bce6-b1eeb5bfd57a"], "096b7785-5989-4767-bce6-b1eeb5bfd57a_2": ["096b7785-5989-4767-bce6-b1eeb5bfd57a"], "9e3e68e9-f19a-4928-9365-ecebd6c30a32_1": ["9e3e68e9-f19a-4928-9365-ecebd6c30a32"], "9e3e68e9-f19a-4928-9365-ecebd6c30a32_2": ["9e3e68e9-f19a-4928-9365-ecebd6c30a32"], "0fd8917c-9fad-4fbe-aa0b-bd2a1aa43d13_1": ["0fd8917c-9fad-4fbe-aa0b-bd2a1aa43d13"], "0fd8917c-9fad-4fbe-aa0b-bd2a1aa43d13_2": ["0fd8917c-9fad-4fbe-aa0b-bd2a1aa43d13"], "c72caf6f-8d32-466f-9c7b-bb7eee55afdc_1": ["c72caf6f-8d32-466f-9c7b-bb7eee55afdc"], "c72caf6f-8d32-466f-9c7b-bb7eee55afdc_2": ["c72caf6f-8d32-466f-9c7b-bb7eee55afdc"], "e9cdd7c4-47e9-48da-841a-4eaeb30c120c_1": ["e9cdd7c4-47e9-48da-841a-4eaeb30c120c"], "e9cdd7c4-47e9-48da-841a-4eaeb30c120c_2": ["e9cdd7c4-47e9-48da-841a-4eaeb30c120c"], "f489cf15-d0fd-4932-a311-d09b9242bcbd_1": ["f489cf15-d0fd-4932-a311-d09b9242bcbd"], "f489cf15-d0fd-4932-a311-d09b9242bcbd_2": ["f489cf15-d0fd-4932-a311-d09b9242bcbd"], "5b780d10-f70b-40a8-98bc-23297874b66f_1": ["5b780d10-f70b-40a8-98bc-23297874b66f"], "5b780d10-f70b-40a8-98bc-23297874b66f_2": ["5b780d10-f70b-40a8-98bc-23297874b66f"], "c7c50a83-277d-4f4d-a42a-0b1b38a75afe_1": ["c7c50a83-277d-4f4d-a42a-0b1b38a75afe"], "c7c50a83-277d-4f4d-a42a-0b1b38a75afe_2": ["c7c50a83-277d-4f4d-a42a-0b1b38a75afe"], "24f63b0c-8ac8-48e0-b100-9f65d5a70587_1": ["24f63b0c-8ac8-48e0-b100-9f65d5a70587"], "24f63b0c-8ac8-48e0-b100-9f65d5a70587_2": ["24f63b0c-8ac8-48e0-b100-9f65d5a70587"], "40ea1712-0fc0-493a-a073-75a0a4289c3b_1": ["40ea1712-0fc0-493a-a073-75a0a4289c3b"], "40ea1712-0fc0-493a-a073-75a0a4289c3b_2": ["40ea1712-0fc0-493a-a073-75a0a4289c3b"], "74a10716-4134-4d7b-9539-cd94739f136a_1": ["74a10716-4134-4d7b-9539-cd94739f136a"], "74a10716-4134-4d7b-9539-cd94739f136a_2": ["74a10716-4134-4d7b-9539-cd94739f136a"], "ba49c935-b7a3-44a5-912c-19413a2ce79a_1": ["ba49c935-b7a3-44a5-912c-19413a2ce79a"], "ba49c935-b7a3-44a5-912c-19413a2ce79a_2": ["ba49c935-b7a3-44a5-912c-19413a2ce79a"], "4ceeb4cb-5b7d-414b-bbc8-9663d18f5300_1": ["4ceeb4cb-5b7d-414b-bbc8-9663d18f5300"], "4ceeb4cb-5b7d-414b-bbc8-9663d18f5300_2": ["4ceeb4cb-5b7d-414b-bbc8-9663d18f5300"], "7f9e8779-4fa0-4991-9d60-c20792d2aaf7_1": ["7f9e8779-4fa0-4991-9d60-c20792d2aaf7"], "7f9e8779-4fa0-4991-9d60-c20792d2aaf7_2": ["7f9e8779-4fa0-4991-9d60-c20792d2aaf7"], "4068a74b-d721-4727-8ae8-63dd3f46945a_1": ["4068a74b-d721-4727-8ae8-63dd3f46945a"], "4068a74b-d721-4727-8ae8-63dd3f46945a_2": ["4068a74b-d721-4727-8ae8-63dd3f46945a"], "2aea1a16-7ceb-41c4-ba11-87cf884f870f_1": ["2aea1a16-7ceb-41c4-ba11-87cf884f870f"], "2aea1a16-7ceb-41c4-ba11-87cf884f870f_2": ["2aea1a16-7ceb-41c4-ba11-87cf884f870f"], "4c0a2dfd-94c9-46d0-a6cb-ecbd7609047e_1": ["4c0a2dfd-94c9-46d0-a6cb-ecbd7609047e"], "4c0a2dfd-94c9-46d0-a6cb-ecbd7609047e_2": ["4c0a2dfd-94c9-46d0-a6cb-ecbd7609047e"], "1efa7d9d-12a8-41a4-8eb8-8af7a265bffd_1": ["1efa7d9d-12a8-41a4-8eb8-8af7a265bffd"], "1efa7d9d-12a8-41a4-8eb8-8af7a265bffd_2": ["1efa7d9d-12a8-41a4-8eb8-8af7a265bffd"], "31b4cd77-4539-4f36-aa0f-937186f380f3_1": ["31b4cd77-4539-4f36-aa0f-937186f380f3"], "31b4cd77-4539-4f36-aa0f-937186f380f3_2": ["31b4cd77-4539-4f36-aa0f-937186f380f3"], "190dd893-b53b-4700-b35a-b8b55b49b24b_1": ["190dd893-b53b-4700-b35a-b8b55b49b24b"], "190dd893-b53b-4700-b35a-b8b55b49b24b_2": ["190dd893-b53b-4700-b35a-b8b55b49b24b"], "c72b45ed-b8f4-4508-9ce9-fe13f94d6c50_1": ["c72b45ed-b8f4-4508-9ce9-fe13f94d6c50"], "c72b45ed-b8f4-4508-9ce9-fe13f94d6c50_2": ["c72b45ed-b8f4-4508-9ce9-fe13f94d6c50"], "2b8b77aa-d83f-46b6-a43d-918c3308993c_1": ["2b8b77aa-d83f-46b6-a43d-918c3308993c"], "2b8b77aa-d83f-46b6-a43d-918c3308993c_2": ["2b8b77aa-d83f-46b6-a43d-918c3308993c"], "ddbc86d0-8442-4129-9315-83e68bab4f84_1": ["ddbc86d0-8442-4129-9315-83e68bab4f84"], "ddbc86d0-8442-4129-9315-83e68bab4f84_2": ["ddbc86d0-8442-4129-9315-83e68bab4f84"], "96d2545b-bdd9-48d4-82ea-d929ec34dad6_1": ["96d2545b-bdd9-48d4-82ea-d929ec34dad6"], "96d2545b-bdd9-48d4-82ea-d929ec34dad6_2": ["96d2545b-bdd9-48d4-82ea-d929ec34dad6"], "8851b71f-d5dd-441b-860f-f0c452766707_1": ["8851b71f-d5dd-441b-860f-f0c452766707"], "8851b71f-d5dd-441b-860f-f0c452766707_2": ["8851b71f-d5dd-441b-860f-f0c452766707"], "3d1c79a7-2e49-490e-ba05-42769aa54db1_1": ["3d1c79a7-2e49-490e-ba05-42769aa54db1"], "3d1c79a7-2e49-490e-ba05-42769aa54db1_2": ["3d1c79a7-2e49-490e-ba05-42769aa54db1"], "999cc9e5-a704-47c7-a5bc-cc862491a41f_1": ["999cc9e5-a704-47c7-a5bc-cc862491a41f"], "999cc9e5-a704-47c7-a5bc-cc862491a41f_2": ["999cc9e5-a704-47c7-a5bc-cc862491a41f"]}, "corpus": {"2b63e9da-5eb2-4515-a608-5e7786f084d1": "BLUEPRINT FOR AN \nAI BILL OF \nRIGHTS \nMAKING AUTOMATED \nSYSTEMS WORK FOR \nTHE AMERICAN PEOPLE \nOCTOBER 2022", "7ed5d69a-bcd6-4656-8b22-c949fcca3c7f": "About this Document \nThe Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People was \npublished by the White House Office of Science and Technology Policy in October 2022. This framework was \nreleased one year after OSTP announced the launch of a process to develop \u201ca bill of rights for an AI-powered \nworld.\u201d Its release follows a year of public engagement to inform this initiative. The framework is available \nonline at: https://www.whitehouse.gov/ostp/ai-bill-of-rights \nAbout the Office of Science and Technology Policy \nThe Office of Science and Technology Policy (OSTP) was established by the National Science and Technology", "9044b75d-90c9-48b5-928e-7bcd84671a28": "Policy, Organization, and Priorities Act of 1976 to provide the President and others within the Executive Office \nof the President with advice on the scientific, engineering, and technological aspects of the economy, national", "3645e5f9-8926-491d-b191-ba5112b25c49": "security, health, foreign relations, the environment, and the technological recovery and use of resources, among \nother topics. OSTP leads interagency science and technology policy coordination efforts, assists the Office of \nManagement and Budget (OMB) with an annual review and analysis of Federal research and development in \nbudgets, and serves as a source of scientific and technological analysis and judgment for the President with \nrespect to major policies, plans, and programs of the Federal Government. \nLegal Disclaimer \nThe Blueprint for an AI Bill of Rights: Making Automated Systems Work for the American People is a white paper \npublished by the White House Office of Science and Technology Policy. It is intended to support the", "39993687-916c-4671-8d4b-4732af201b16": "development of policies and practices that protect civil rights and promote democratic values in the building, \ndeployment, and governance of automated systems.", "d19fb894-9e8d-4d18-a94d-1f01bdd33c56": "deployment, and governance of automated systems. \nThe Blueprint for an AI Bill of Rights is non-binding and does not constitute U.S. government policy. It \ndoes not supersede, modify, or direct an interpretation of any existing statute, regulation, policy, or \ninternational instrument. It does not constitute binding guidance for the public or Federal agencies and \ntherefore does not require compliance with the principles described herein. It also is not determinative of what \nthe U.S. government\u2019s position will be in any international negotiation. Adoption of these principles may not \nmeet the requirements of existing statutes, regulations, policies, or international instruments, or the", "ff3ab363-0163-4dbd-955a-293ff6025248": "requirements of the Federal agencies that enforce them. These principles are not intended to, and do not, \nprohibit or limit any lawful activity of a government agency, including law enforcement, national security, or \nintelligence activities.", "57277e82-772d-4954-bee1-78a723ef113a": "intelligence activities. \nThe appropriate application of the principles set forth in this white paper depends significantly on the \ncontext in which automated systems are being utilized. In some circumstances, application of these principles \nin whole or in part may not be appropriate given the intended use of automated systems to achieve government \nagency missions. Future sector-specific guidance will likely be necessary and important for guiding the use of \nautomated systems in certain settings such as AI systems used as part of school building security or automated \nhealth diagnostic systems. \nThe Blueprint for an AI Bill of Rights recognizes that law enforcement activities require a balancing of", "761f6036-77a2-4998-81de-7eb2b6330c04": "equities, for example, between the protection of sensitive law enforcement information and the principle of \nnotice; as such, notice may not be appropriate, or may need to be adjusted to protect sources, methods, and", "cb21e5d1-397e-4884-bf14-e22de8225d10": "other law enforcement equities. Even in contexts where these principles may not apply in whole or in part, \nfederal departments and agencies remain subject to judicial, privacy, and civil liberties oversight as well as \nexisting policies and safeguards that govern automated systems, including, for example, Executive Order 13960, \nPromoting the Use of Trustworthy Artificial Intelligence in the Federal Government (December 2020). \nThis white paper recognizes that national security (which includes certain law enforcement and \nhomeland security activities) and defense activities are of increased sensitivity and interest to our nation\u2019s", "b69096bb-dfe0-440f-8dbe-963d97850aff": "adversaries and are often subject to special requirements, such as those governing classified information and \nother protected data. Such activities require alternative, compatible safeguards through existing policies that \ngovern automated systems and AI, such as the Department of Defense (DOD) AI Ethical Principles and", "43070dc6-452b-4896-9642-d71f2c7decee": "Responsible AI Implementation Pathway and the Intelligence Community (IC) AI Ethics Principles and \nFramework. The implementation of these policies to national security and defense activities can be informed by \nthe Blueprint for an AI Bill of Rights where feasible. \nThe Blueprint for an AI Bill of Rights is not intended to, and does not, create any legal right, benefit, or \ndefense, substantive or procedural, enforceable at law or in equity by any party against the United States, its \ndepartments, agencies, or entities, its officers, employees, or agents, or any other person, nor does it constitute a \nwaiver of sovereign immunity. \nCopyright Information", "d15b0f49-6066-4f4b-b930-9f0d907c9eff": "This document is a work of the United States Government and is in the public domain (see 17 U.S.C. \u00a7105). \n2", "9eee00fb-1d02-43fa-801e-7f68e9690cfa": "SECTION TITLE\u00ad\nFOREWORD\nAmong the great challenges posed to democracy today is the use of technology, data, and automated systems in \nways that threaten the rights of the American public. Too often, these tools are used to limit our opportunities and \nprevent our access to critical resources or services. These problems are well documented. In America and around \nthe world, systems supposed to help with patient care have proven unsafe, ineffective, or biased. Algorithms used \nin hiring and credit decisions have been found to reflect and reproduce existing unwanted inequities or embed \nnew harmful bias and discrimination. Unchecked social media data collection has been used to threaten people\u2019s", "cae51451-45cb-4f73-a0f8-f76e0e6fd5ef": "opportunities, undermine their privacy, or pervasively track their activity\u2014often without their knowledge or \nconsent. \nThese outcomes are deeply harmful\u2014but they are not inevitable. Automated systems have brought about extraor-", "4ef57090-9555-4422-8147-7c76ed92a7d5": "dinary benefits, from technology that helps farmers grow food more efficiently and computers that predict storm \npaths, to algorithms that can identify diseases in patients. These tools now drive important decisions across \nsectors, while data is helping to revolutionize global industries. Fueled by the power of American innovation, \nthese tools hold the potential to redefine every part of our society and make life better for everyone. \nThis important progress must not come at the price of civil rights or democratic values, foundational American \nprinciples that President Biden has affirmed as a cornerstone of his Administration. On his first day in office, the", "66a4ed20-14b1-45f1-84df-37f09b52e569": "President ordered the full Federal government to work to root out inequity, embed fairness in decision-\nmaking processes, and affirmatively advance civil rights, equal opportunity, and racial justice in America.1 The \nPresident has spoken forcefully about the urgent challenges posed to democracy today and has regularly called", "d4921251-b4d5-47bd-933b-3bc479317063": "on people of conscience to act to preserve civil rights\u2014including the right to privacy, which he has called \u201cthe \nbasis for so many more rights that we have come to take for granted that are ingrained in the fabric of this \ncountry.\u201d2\nTo advance President Biden\u2019s vision, the White House Office of Science and Technology Policy has identified \nfive principles that should guide the design, use, and deployment of automated systems to protect the American \npublic in the age of artificial intelligence. The Blueprint for an AI Bill of Rights is a guide for a society that \nprotects all people from these threats\u2014and uses technologies in ways that reinforce our highest values.", "2394e9b3-81e2-4b54-8f03-a8a15add6484": "Responding to the experiences of the American public, and informed by insights from researchers, \ntechnologists, advocates, journalists, and policymakers, this framework is accompanied by a technical \ncompanion\u2014a handbook for anyone seeking to incorporate these protections into policy and practice, including", "85928e54-ae18-4a1d-8650-42edd0b4ff5d": "detailed steps toward actualizing these principles in the technological design process. These principles help \nprovide guidance whenever automated systems can meaningfully impact the public\u2019s rights, opportunities, \nor access to critical needs. \n3", "0214b542-d262-47df-b694-561355ee341d": "ABOUT THIS FRAMEWORK\u00ad\u00ad\u00ad\u00ad\u00ad\nThe Blueprint for an AI Bill of Rights is a set of five principles and associated practices to help guide the \ndesign, use, and deployment of automated systems to protect the rights of the American public in the age of \nartificial intel-ligence. Developed through extensive consultation with the American public, these principles are \na blueprint for building and deploying automated systems that are aligned with democratic values and protect \ncivil rights, civil liberties, and privacy. The Blueprint for an AI Bill of Rights includes this Foreword, the five \nprinciples, notes on Applying the The Blueprint for an AI Bill of Rights, and a Technical Companion that gives", "d8289c72-842b-4dde-a3d5-fd17a45632c1": "concrete steps that can be taken by many kinds of organizations\u2014from governments at all levels to companies of \nall sizes\u2014to uphold these values. Experts from across the private sector, governments, and international", "c175618a-4c65-4090-bfd8-69c6bbe61d5b": "consortia have published principles and frameworks to guide the responsible use of automated systems; this \nframework provides a national values statement and toolkit that is sector-agnostic to inform building these \nprotections into policy, practice, or the technological design process.  Where existing law or policy\u2014such as \nsector-specific privacy laws and oversight requirements\u2014do not already provide guidance, the Blueprint for an \nAI Bill of Rights should be used to inform policy decisions.\nLISTENING TO THE AMERICAN PUBLIC\nThe White House Office of Science and Technology Policy has led a year-long process to seek and distill input \nfrom people across the country\u2014from impacted communities and industry stakeholders to technology develop-", "2d3b4509-9b83-450f-b319-4d8fc1293751": "ers and other experts across fields and sectors, as well as policymakers throughout the Federal government\u2014on \nthe issue of algorithmic and data-driven harms and potential remedies. Through panel discussions, public listen-", "2f43deab-8be2-4cd3-9dc5-4a63947b2ae1": "ing sessions, meetings, a formal request for information, and input to a publicly accessible and widely-publicized \nemail address, people throughout the United States, public servants across Federal agencies, and members of the \ninternational community spoke up about both the promises and potential harms of these technologies, and \nplayed a central role in shaping the Blueprint for an AI Bill of Rights. The core messages gleaned from these \ndiscussions include that AI has transformative potential to improve Americans\u2019 lives, and that preventing the \nharms of these technologies is both necessary and achievable. The Appendix includes a full list of public engage-\nments. \n4", "f70ec23e-99af-48fd-9e17-ece2eaee3d16": "AI BILL OF RIGHTS\nFFECTIVE SYSTEMS\nineffective systems. Automated systems should be \ncommunities, stakeholders, and domain experts to identify \nSystems should undergo pre-deployment testing, risk \nthat demonstrate they are safe and effective based on \nincluding those beyond the intended use, and adherence to \nprotective measures should include the possibility of not \nAutomated systems should not be designed with an intent \nreasonably foreseeable possibility of endangering your safety or the safety of your community. They should \nstemming from unintended, yet foreseeable, uses or \n \n \n \n \n  \n \n \nSECTION TITLE\nBLUEPRINT FOR AN\nSAFE AND E \nYou should be protected from unsafe or \ndeveloped with consultation from diverse", "b59fa977-0d2b-4bb7-8583-13bbe3338f39": "concerns, risks, and potential impacts of the system. \nidentification and mitigation, and ongoing monitoring \ntheir intended use, mitigation of unsafe outcomes \ndomain-specific standards. Outcomes of these \ndeploying the system or removing a system from use. \nor", "facfa226-5df2-4fa8-9cda-a0f1674fa12e": "or \nbe designed to proactively protect you from harms \nimpacts of automated systems. You should be protected from inappropriate or irrelevant data use in the \ndesign, development, and deployment of automated systems, and from the compounded harm of its reuse. \nIndependent evaluation and reporting that confirms that the system is safe and effective, including reporting of \nsteps taken to mitigate potential harms, should be performed and the results made public whenever possible. \nALGORITHMIC DISCRIMINATION PROTECTIONS\nYou should not face discrimination by algorithms and systems should be used and designed in \nan equitable way. Algorithmic discrimination occurs when automated systems contribute to unjustified", "8cc2a2d9-2eed-45ad-af65-538324fcefb1": "different treatment or impacts disfavoring people based on their race, color, ethnicity, sex (including \npregnancy, childbirth, and related medical conditions, gender identity, intersex status, and sexual", "3bc51cf4-d565-46b0-8e09-508b2041824d": "orientation), religion, age, national origin, disability, veteran status, genetic information, or any other \nclassification protected by law. Depending on the specific circumstances, such algorithmic discrimination \nmay violate legal protections. Designers, developers, and deployers of automated systems should take \nproactive \nand \ncontinuous \nmeasures \nto \nprotect \nindividuals \nand \ncommunities \nfrom algorithmic \ndiscrimination and to use and design systems in an equitable way. This protection should include proactive \nequity assessments as part of the system design, use of representative data and protection against proxies \nfor demographic features, ensuring accessibility for people with disabilities in design and development,", "6c2a16cc-9fd1-46be-9fce-59ee4dfba44a": "pre-deployment and ongoing disparity testing and mitigation, and clear organizational oversight. Independent \nevaluation and plain language reporting in the form of an algorithmic impact assessment, including", "bca32085-cc69-4be5-9c8a-1c5cf12ae532": "disparity testing results and mitigation information, should be performed and made public whenever \npossible to confirm these protections. \n5", "ec22a03b-6e3a-43ad-b92f-09231cf270ed": "SECTION TITLE\nDATA PRIVACY\nYou should be protected from abusive data practices via built-in protections and you \nshould have agency over how data about you is used. You should be protected from violations of \nprivacy through design choices that ensure such protections are included by default, including ensuring that \ndata collection conforms to reasonable expectations and that only data strictly necessary for the specific \ncontext is collected. Designers, developers, and deployers of automated systems should seek your permission \nand respect your decisions regarding collection, use, access, transfer, and deletion of your data in appropriate", "f458c57d-9ef9-448a-b325-4e7fde633c9f": "ways and to the greatest extent possible; where not possible, alternative privacy by design safeguards should be \nused. Systems should not employ user experience and design decisions that obfuscate user choice or burden \nusers with defaults that are privacy invasive. Consent should only be used to justify collection of data in cases", "498eb8a3-1798-44fe-a1bb-ee5972a931a6": "where it can be appropriately and meaningfully given. Any consent requests should be brief, be understandable \nin plain language, and give you agency over data collection and the specific context of use; current hard-to\u00ad\nunderstand notice-and-choice practices for broad uses of data should be changed. Enhanced protections and \nrestrictions for data and inferences related to sensitive domains, including health, work, education, criminal \njustice, and finance, and for data pertaining to youth should put you first. In sensitive domains, your data and \nrelated inferences should only be used for necessary functions, and you should be protected by ethical review", "08130ab3-8809-41f9-a10c-c9c7080b67a6": "and use prohibitions. You and your communities should be free from unchecked surveillance; surveillance \ntechnologies should be subject to heightened oversight that includes at least pre-deployment assessment of their \npotential harms and scope limits to protect privacy and civil liberties. Continuous surveillance and monitoring", "2d7dabaf-155c-4036-a458-59b8119c1a03": "should not be used in education, work, housing, or in other contexts where the use of such surveillance \ntechnologies is likely to limit rights, opportunities, or access. Whenever possible, you should have access to \nreporting that confirms your data decisions have been respected and provides an assessment of the \npotential impact of surveillance technologies on your rights, opportunities, or access. \nNOTICE AND EXPLANATION\nYou should know that an automated system is being used and understand how and why it \ncontributes to outcomes that impact you. Designers, developers, and deployers of automated systems \nshould provide generally accessible plain language documentation including clear descriptions of the overall", "0827d937-883e-4b60-9b04-7e83cca84940": "system functioning and the role automation plays, notice that such systems are in use, the individual or organiza\u00ad\ntion responsible for the system, and explanations of outcomes that are clear, timely, and accessible. Such notice", "2e1c7072-d11c-4832-ba82-f2fd3a0e309e": "should be kept up-to-date and people impacted by the system should be notified of significant use case or key \nfunctionality changes. You should know how and why an outcome impacting you was determined by an \nautomated system, including when the automated system is not the sole input determining the outcome. \nAutomated systems should provide explanations that are technically valid, meaningful and useful to you and to \nany operators or others who need to understand the system, and calibrated to the level of risk based on the \ncontext. Reporting that includes summary information about these automated systems in plain language and \nassessments of the clarity and quality of the notice and explanations should be made public whenever possible. \n6", "42da6bfa-8628-49ed-b638-a2b9be70becc": "SECTION TITLE\nHUMAN ALTERNATIVES, CONSIDERATION, AND FALLBACK\nYou should be able to opt out, where appropriate, and have access to a person who can quickly \nconsider and remedy problems you encounter. You should be able to opt out from automated systems in \nfavor of a human alternative, where appropriate. Appropriateness should be determined based on reasonable \nexpectations in a given context and with a focus on ensuring broad accessibility and protecting the public from \nespecially harmful impacts. In some cases, a human or other alternative may be required by law. You should have \naccess to timely human consideration and remedy by a fallback and escalation process if an automated system", "586ae00e-8427-491b-a0a6-94a21394af7c": "fails, it produces an error, or you would like to appeal or contest its impacts on you. Human consideration and \nfallback should be accessible, equitable, effective, maintained, accompanied by appropriate operator training, and", "337ca019-42c2-4790-ba4f-36dfb745dc11": "should not impose an unreasonable burden on the public. Automated systems with an intended use within sensi\u00ad\ntive domains, including, but not limited to, criminal justice, employment, education, and health, should additional\u00ad\nly be tailored to the purpose, provide meaningful access for oversight, include training for any people interacting \nwith the system, and incorporate human consideration for adverse or high-risk decisions. Reporting that includes \na description of these human governance processes and assessment of their timeliness, accessibility, outcomes, \nand effectiveness should be made public whenever possible.", "40d48902-c91a-408f-91e6-4034893da786": "Definitions for key terms in The Blueprint for an AI Bill of Rights can be found in Applying the Blueprint for an AI Bill of Rights. \nAccompanying analysis and tools for actualizing each principle can be found in the Technical Companion. \n7", "b1c0f3a6-07a7-4a9a-b753-9a50a3c277f3": "SECTION TITLE\nApplying The Blueprint for an AI Bill of Rights \nWhile many of the concerns addressed in this framework derive from the use of AI, the technical \ncapabilities and specific definitions of such systems change with the speed of innovation, and the potential \nharms of their use occur even with less technologically sophisticated tools. Thus, this framework uses a two-\npart test to determine what systems are in scope. This framework applies to (1) automated systems that (2) \nhave the potential to meaningfully impact the American public\u2019s rights, opportunities, or access to \ncritical resources or services. These rights, opportunities, and access to critical resources of services should", "53d396a2-66c4-4977-90e7-0bb3a2484e16": "be enjoyed equally and be fully protected, regardless of the changing role that automated systems may play in \nour lives. \nThis framework describes protections that should be applied with respect to all automated systems that", "e3f5ac23-ad36-4454-8a57-3cd4c0dd9283": "have the potential to meaningfully impact individuals' or communities' exercise of: \nRIGHTS, OPPORTUNITIES, OR ACCESS\nCivil rights, civil liberties, and privacy, including freedom of speech, voting, and protections from discrimi\u00ad\nnation, excessive punishment, unlawful surveillance, and violations of privacy and other freedoms in both \npublic and private sector contexts; \nEqual opportunities, including equitable access to education, housing, credit, employment, and other \nprograms; or, \nAccess to critical resources or services, such as healthcare, financial services, safety, social services, \nnon-deceptive information about goods and services, and government benefits.", "6181a68a-0654-4b9f-9fbe-e7f224ee42cc": "A list of examples of automated systems for which these principles should be considered is provided in the \nAppendix. The Technical Companion, which follows, offers supportive guidance for any person or entity that \ncreates, deploys, or oversees automated systems.", "b8e5f957-237b-4204-9b9a-a45cc9535d88": "creates, deploys, or oversees automated systems. \nConsidered together, the five principles and associated practices of the Blueprint for an AI Bill of \nRights form an overlapping set of backstops against potential harms. This purposefully overlapping \nframework, when taken as a whole, forms a blueprint to help protect the public from harm. \nThe measures taken to realize the vision set forward in this framework should be proportionate \nwith the extent and nature of the harm, or risk of harm, to people's rights, opportunities, and \naccess. \nRELATIONSHIP TO EXISTING LAW AND POLICY\nThe Blueprint for an AI Bill of Rights is an exercise in envisioning a future where the American public is", "d47b9e1c-489a-4c71-a99b-c45894f40e39": "protected from the potential harms, and can fully enjoy the benefits, of automated systems. It describes princi\u00ad\nples that can help ensure these protections. Some of these protections are already required by the U.S. Constitu\u00ad", "2f4e355a-2898-4cc3-8ca1-50fb833163ab": "tion or implemented under existing U.S. laws. For example, government surveillance, and data search and \nseizure are subject to legal requirements and judicial oversight. There are Constitutional requirements for \nhuman review of criminal investigative matters and statutory requirements for judicial review. Civil rights laws \nprotect the American people against discrimination. \n8", "1eb81643-0479-4669-b94c-1538bf03b398": "SECTION TITLE\n \n \n \n \n \n \nApplying The Blueprint for an AI Bill of Rights \nRELATIONSHIP TO EXISTING LAW AND POLICY\nThere are regulatory safety requirements for medical devices, as well as sector-, population-, or technology-spe\u00ad\ncific privacy and security protections. Ensuring some of the additional protections proposed in this framework \nwould require new laws to be enacted or new policies and practices to be adopted. In some cases, exceptions to \nthe principles described in the Blueprint for an AI Bill of Rights may be necessary to comply with existing law, \nconform to the practicalities of a specific use case, or balance competing public interests. In particular, law", "95e72817-edc5-4037-8517-acf270aa38a1": "enforcement, and other regulatory contexts may require government actors to protect civil rights, civil liberties, \nand privacy in a manner consistent with, but using alternate mechanisms to, the specific principles discussed in", "f876a0e6-2549-4dea-9bc7-16a5a0fbf3a0": "this framework. The Blueprint for an AI Bill of Rights is meant to assist governments and the private sector in \nmoving principles into practice. \nThe expectations given in the Technical Companion are meant to serve as a blueprint for the development of \nadditional technical standards and practices that should be tailored for particular sectors and contexts. While \nexisting laws informed the development of the Blueprint for an AI Bill of Rights, this framework does not detail \nthose laws beyond providing them as examples, where appropriate, of existing protective measures. This \nframework instead shares a broad, forward-leaning vision of recommended principles for automated system", "b9a14487-6e9e-4423-99c1-9dd441b1a316": "development and use to inform private and public involvement with these systems where they have the poten\u00ad\ntial to meaningfully impact rights, opportunities, or access. Additionally, this framework does not analyze or", "f5d21644-a601-4747-bd5a-ffb8e242df95": "take a position on legislative and regulatory proposals in municipal, state, and federal government, or those in \nother countries. \nWe have seen modest progress in recent years, with some state and local governments responding to these prob\u00ad\nlems with legislation, and some courts extending longstanding statutory protections to new and emerging tech\u00ad\nnologies. There are companies working to incorporate additional protections in their design and use of auto\u00ad\nmated systems, and researchers developing innovative guardrails. Advocates, researchers, and government \norganizations have proposed principles for the ethical use of AI and other automated systems. These include", "b4980938-40f7-491e-a986-6401a99cf198": "the Organization for Economic Co-operation and Development\u2019s (OECD\u2019s) 2019 Recommendation on Artificial \nIntelligence, which includes principles for responsible stewardship of trustworthy AI and which the United \nStates adopted, and Executive Order 13960 on Promoting the Use of Trustworthy Artificial Intelligence in the", "b814145f-813e-48e7-a532-bb731bbda211": "Federal Government, which sets out principles that govern the federal government\u2019s use of AI. The Blueprint \nfor an AI Bill of Rights is fully consistent with these principles and with the direction in Executive Order 13985 \non Advancing Racial Equity and Support for Underserved Communities Through the Federal Government. \nThese principles find kinship in the Fair Information Practice Principles (FIPPs), derived from the 1973 report \nof an advisory committee to the U.S. Department of Health, Education, and Welfare, Records, Computers, \nand the Rights of Citizens.4 While there is no single, universal articulation of the FIPPs, these core \nprinciples for managing information about individuals have been incorporated into data privacy laws and", "1b61df3a-157c-4cb7-a504-9ce289071061": "policies across the globe.5 The Blueprint for an AI Bill of Rights embraces elements of the FIPPs that are \nparticularly relevant to automated systems, without articulating a specific set of FIPPs or scoping", "c0238690-f8df-4333-95b9-9d6ae1c9c584": "applicability or the interests served to a single particular domain, like privacy, civil rights and civil liberties, \nethics, or risk management. The Technical Companion builds on this prior work to provide practical next \nsteps to move these principles into practice and promote common approaches that allow technological \ninnovation to flourish while protecting people from harm. \n9", "0b113d5f-1c35-4d6f-a0ec-4929f5852df4": "Applying The Blueprint for an AI Bill of Rights \nDEFINITIONS\nALGORITHMIC DISCRIMINATION: \u201cAlgorithmic discrimination\u201d occurs when automated systems \ncontribute to unjustified different treatment or impacts disfavoring people based on their race, color, ethnicity, \nsex (including pregnancy, childbirth, and related medical conditions, gender identity, intersex status, and sexual \norientation), religion, age, national origin, disability, veteran status, genetic information, or any other classifica-\ntion protected by law. Depending on the specific circumstances, such algorithmic discrimination may violate \nlegal protections. Throughout this framework the term \u201calgorithmic discrimination\u201d takes this meaning (and", "632db52c-2137-4d81-8f38-50ba34866e02": "not a technical understanding of discrimination as distinguishing between items). \nAUTOMATED SYSTEM: An \"automated system\" is any system, software, or process that uses computation as", "fc0446c2-84a2-4f27-966b-f5d328a70f50": "whole or part of a system to determine outcomes, make or aid decisions, inform policy implementation, collect \ndata or observations, or otherwise interact with individuals and/or communities. Automated systems \ninclude, but are not limited to, systems derived from machine learning, statistics, or other data processing \nor artificial intelligence techniques, and exclude passive computing infrastructure. \u201cPassive computing \ninfrastructure\u201d is any intermediary technology that does not influence or determine the outcome of decision, \nmake or aid in decisions, inform policy implementation, or collect data or observations, including web \nhosting, domain registration, networking, caching, data storage, or cybersecurity. Throughout this", "eff9ff37-f61f-4420-9055-e2a218c7b41c": "framework, automated systems that are considered in scope are only those that have the potential to \nmeaningfully impact individuals\u2019 or communi-ties\u2019 rights, opportunities, or access.", "98a604f9-3590-48ce-95e7-977f304548d0": "COMMUNITIES: \u201cCommunities\u201d include: neighborhoods; social network connections (both online and \noffline); families (construed broadly); people connected by affinity, identity, or shared traits; and formal organi-\nzational ties. This includes Tribes, Clans, Bands, Rancherias, Villages, and other Indigenous communities. AI \nand other data-driven automated systems most directly collect data on, make inferences about, and may cause \nharm to individuals. But the overall magnitude of their impacts may be most readily visible at the level of com-\nmunities. Accordingly, the concept of community is integral to the scope of the Blueprint for an AI Bill of Rights.", "3d8070c4-6254-4b5c-8ba4-da2ccf2e0d00": "United States law and policy have long employed approaches for protecting the rights of individuals, but exist-\ning frameworks have sometimes struggled to provide protections when effects manifest most clearly at a com-\nmunity level. For these reasons, the Blueprint for an AI Bill of Rights asserts that the harms of automated", "522a2717-200a-4374-8fd5-d3abdfbc1226": "systems should be evaluated, protected against, and redressed at both the individual and community levels. \nEQUITY: \u201cEquity\u201d means the consistent and systematic fair, just, and impartial treatment of all individuals. \nSystemic, fair, and just treatment must take into account the status of individuals who belong to underserved \ncommunities that have been denied such treatment, such as Black, Latino, and Indigenous and Native American \npersons, Asian Americans and Pacific Islanders and other persons of color; members of religious minorities; \nwomen, girls, and non-binary people; lesbian, gay, bisexual, transgender, queer, and intersex (LGBTQI+)", "75e202a1-d140-4f47-ab2b-e211e543a2c5": "persons; older adults; persons with disabilities; persons who live in rural areas; and persons otherwise adversely \naffected by persistent poverty or inequality. \nRIGHTS, OPPORTUNITIES, OR ACCESS: \u201cRights, opportunities, or access\u201d is used to indicate the scoping", "041d2876-f023-40b1-b0f1-c6be2e3d1b74": "of this framework. It describes the set of: civil rights, civil liberties, and privacy, including freedom of speech, \nvoting, and protections from discrimination, excessive punishment, unlawful surveillance, and violations of \nprivacy and other freedoms in both public and private sector contexts; equal opportunities, including equitable \naccess to education, housing, credit, employment, and other programs; or, access to critical resources or \nservices, such as healthcare, financial services, safety, social services, non-deceptive information about goods \nand services, and government benefits. \n10", "4a9174fe-7911-42c1-a501-1349cc643ff1": "Applying The Blueprint for an AI Bill of Rights \nSENSITIVE DATA: Data and metadata are sensitive if they pertain to an individual in a sensitive domain \n(defined below); are generated by technologies used in a sensitive domain; can be used to infer data from a \nsensitive domain or sensitive data about an individual (such as disability-related data, genomic data, biometric \ndata, behavioral data, geolocation data, data related to interaction with the criminal justice system, relationship \nhistory and legal status such as custody and divorce information, and home, work, or school environmental \ndata); or have the reasonable potential to be used in ways that are likely to expose individuals to meaningful", "8c9806de-cd1b-4da8-9191-64efcef9e09d": "harm, such as a loss of privacy or financial harm due to identity theft. Data and metadata generated by or about \nthose who are not yet legal adults is also sensitive, even if not related to a sensitive domain. Such data includes,", "3165553a-9b8f-480c-afa3-17192d6a2b6c": "but is not limited to, numerical, text, image, audio, or video data. \nSENSITIVE DOMAINS: \u201cSensitive domains\u201d are those in which activities being conducted can cause material \nharms, including significant adverse effects on human rights such as autonomy and dignity, as well as civil liber\u00ad\nties and civil rights. Domains that have historically been singled out as deserving of enhanced data protections \nor where such enhanced protections are reasonably expected by the public include, but are not limited to, \nhealth, family planning and care, employment, education, criminal justice, and personal finance. In the context \nof this framework, such domains are considered sensitive whether or not the specifics of a system context", "664037f2-7155-4df2-988e-78aabec95a6f": "would necessitate coverage under existing law, and domains and data that are considered sensitive are under\u00ad\nstood to change over time based on societal norms and context. \nSURVEILLANCE TECHNOLOGY: \u201cSurveillance technology\u201d refers to products or services marketed for", "5be54f63-786c-49fd-8126-f5bd288f8600": "or that can be lawfully used to detect, monitor, intercept, collect, exploit, preserve, protect, transmit, and/or \nretain data, identifying information, or communications concerning individuals or groups. This framework \nlimits its focus to both government and commercial use of surveillance technologies when juxtaposed with \nreal-time or subsequent automated analysis and when such systems have a potential for meaningful impact \non individuals\u2019 or communities\u2019 rights, opportunities, or access. \nUNDERSERVED COMMUNITIES: The term \u201cunderserved communities\u201d refers to communities that have \nbeen systematically denied a full opportunity to participate in aspects of economic, social, and civic life, as", "f81943d9-e0a4-4e02-9518-58b1c430f446": "exemplified by the list in the preceding definition of \u201cequity.\u201d \n11", "9020b6f0-1074-4064-82e9-95845d0b121e": "FROM \nPRINCIPLES \nTO PRACTICE \nA TECHINCAL COMPANION TO\nTHE Blueprint for an \nAI BILL OF RIGHTS\n12", "92a6cf51-caf8-4cc2-91bb-a966dbf400df": "TABLE OF CONTENTS\nFROM PRINCIPLES TO PRACTICE: A TECHNICAL COMPANION TO THE BLUEPRINT \nFOR AN AI BILL OF RIGHTS \n \nUSING THIS TECHNICAL COMPANION\n \nSAFE AND EFFECTIVE SYSTEMS\n \nALGORITHMIC DISCRIMINATION PROTECTIONS\n \nDATA PRIVACY\n \nNOTICE AND EXPLANATION\n \nHUMAN ALTERNATIVES, CONSIDERATION, AND FALLBACK\nAPPENDIX\n \nEXAMPLES OF AUTOMATED SYSTEMS\n \nLISTENING TO THE AMERICAN PEOPLE\nENDNOTES \n12\n14\n15\n23\n30\n40\n46\n53\n53\n55\n63\n13", "b8b71f36-757d-495c-9719-e84c0a976606": "-    \nUSING THIS TECHNICAL COMPANION\nThe Blueprint for an AI Bill of Rights is a set of five principles and associated practices to help guide the design, \nuse, and deployment of automated systems to protect the rights of the American public in the age of artificial \nintelligence. This technical companion considers each principle in the Blueprint for an AI Bill of Rights and \nprovides examples and concrete steps for communities, industry, governments, and others to take in order to \nbuild these protections into policy, practice, or the technological design process. \nTaken together, the technical protections and practices laid out in the Blueprint for an AI Bill of Rights can help", "cc8c282e-d378-4571-980f-cc0ddf33a406": "guard the American public against many of the potential and actual harms identified by researchers, technolo\u00ad\ngists, advocates, journalists, policymakers, and communities in the United States and around the world. This", "99697ee1-707b-43e9-b4ae-722e0fec5901": "technical companion is intended to be used as a reference by people across many circumstances \u2013 anyone \nimpacted by automated systems, and anyone developing, designing, deploying, evaluating, or making policy to \ngovern the use of an automated system. \nEach principle is accompanied by three supplemental sections: \n1\n2\nWHY THIS PRINCIPLE IS IMPORTANT: \nThis section provides a brief summary of the problems that the principle seeks to address and protect against, including \nillustrative examples. \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS: \n\u2022 The expectations for automated systems are meant to serve as a blueprint for the development of additional technical\nstandards and practices that should be tailored for particular sectors and contexts.", "7ad79f6c-d800-49dc-864b-b1deb43ea49f": "\u2022 This section outlines practical steps that can be implemented to realize the vision of the Blueprint for an AI Bill of Rights. The", "edaf9e38-6479-48ef-ba9d-5d6c07ae6f09": "expectations laid out often mirror existing practices for technology development, including pre-deployment testing, ongoing \nmonitoring, and governance structures for automated systems, but also go further to address unmet needs for change and offer \nconcrete directions for how those changes can be made. \n\u2022 Expectations about reporting are intended for the entity developing or using the automated system. The resulting reports can \nbe provided to the public, regulators, auditors, industry standards groups, or others engaged in independent review, and should \nbe made public as much as possible consistent with law, regulation, and policy, and noting that intellectual property, law", "81f3b7b1-3a02-44c8-8727-4e4b24c3a730": "enforcement, or national security considerations may prevent public release. Where public reports are not possible, the \ninformation should be provided to oversight bodies and privacy, civil liberties, or other ethics officers charged with safeguard", "4c6f7d89-da85-42d5-9489-fbdb8d8ef27e": "ing individuals\u2019 rights. These reporting expectations are important for transparency, so the American people can have\nconfidence that their rights, opportunities, and access as well as their expectations about technologies are respected. \n3\nHOW THESE PRINCIPLES CAN MOVE INTO PRACTICE: \nThis section provides real-life examples of how these guiding principles can become reality, through laws, policies, and practices. \nIt describes practical technical and sociotechnical approaches to protecting rights, opportunities, and access. \nThe examples provided are not critiques or endorsements, but rather are offered as illustrative cases to help", "a9367afa-7030-48f2-ad57-a2f1b36648b4": "provide a concrete vision for actualizing the Blueprint for an AI Bill of Rights. Effectively implementing these \nprocesses require the cooperation of and collaboration among industry, civil society, researchers, policymakers, \ntechnologists, and the public. \n14", "3c6632b7-4be4-40c6-876b-e9050252fe27": "SAFE AND EFFECTIVE SYSTEMS \nYou should be protected from unsafe or ineffective sys\u00ad\ntems. Automated systems should be developed with consultation \nfrom diverse communities, stakeholders, and domain experts to iden\u00ad\ntify concerns, risks, and potential impacts of the system. Systems \nshould undergo pre-deployment testing, risk identification and miti\u00ad\ngation, and ongoing monitoring that demonstrate they are safe and \neffective based on their intended use, mitigation of unsafe outcomes \nincluding those beyond the intended use, and adherence to do\u00ad\nmain-specific standards. Outcomes of these protective measures \nshould include the possibility of not deploying the system or remov\u00ad\ning a system from use. Automated systems should not be designed", "d3e92914-f693-4ffd-affc-73a1af5af922": "with an intent or reasonably foreseeable possibility of endangering \nyour safety or the safety of your community. They should be designed \nto proactively protect you from harms stemming from unintended,", "ffe359b8-2946-4487-b123-167bcd402f5b": "yet foreseeable, uses or impacts of automated systems. You should be \nprotected from inappropriate or irrelevant data use in the design, de\u00ad\nvelopment, and deployment of automated systems, and from the \ncompounded harm of its reuse. Independent evaluation and report\u00ad\ning that confirms that the system is safe and effective, including re\u00ad\nporting of steps taken to mitigate potential harms, should be per\u00ad\nformed and the results made public whenever possible. \n15", "5b75b1af-b531-4af4-af70-39540fd42e54": "SAFE AND EFFECTIVE \nSYSTEMS \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \nWhile technologies are being deployed to solve problems across a wide array of issues, our reliance on technology can \nalso lead to its use in situations where it has not yet been proven to work\u2014either at all or within an acceptable range \nof error. In other cases, technologies do not work as intended or as promised, causing substantial and unjustified harm. \nAutomated systems sometimes rely on data from other systems, including historical data, allowing irrelevant informa\u00ad", "1238d8f9-c2bd-42f8-88c2-a1288d42a98d": "tion from past decisions to infect decision-making in unrelated situations.  In some cases, technologies are purposeful\u00ad\nly designed to violate the safety of others, such as technologies designed to facilitate stalking; in other cases, intended \nor unintended uses lead to unintended harms.", "f9954383-4233-4888-af4d-037eed9ee778": "or unintended uses lead to unintended harms. \nMany of the harms resulting from these technologies are preventable, and actions are already being taken to protect \nthe public. Some companies have put in place safeguards that have prevented harm from occurring by ensuring that \nkey development decisions are vetted by an ethics review; others have identified and mitigated harms found through \npre-deployment testing and ongoing monitoring processes. Governments at all levels have existing public consulta\u00ad\ntion processes that may be applied when considering the use of new automated systems, and existing product develop\u00ad\nment and testing practices already protect the American public from many potential harms.", "87c6faa4-a0b0-49f7-93bf-8488edb84ac2": "Still, these kinds of practices are deployed too rarely and unevenly. Expanded, proactive protections could build on \nthese existing practices, increase confidence in the use of automated systems, and protect the American public. Inno\u00ad", "29057260-21d6-4d98-8c94-563c7af4c2a6": "vators deserve clear rules of the road that allow new ideas to flourish, and the American public deserves protections \nfrom unsafe outcomes. All can benefit from assurances that automated systems will be designed, tested, and consis\u00ad\ntently confirmed to work as intended, and that they will be proactively protected from foreseeable unintended harm\u00ad\nful outcomes. \n\u2022\nA proprietary model was developed to predict the likelihood of sepsis in hospitalized patients and was imple\u00ad\nmented at hundreds of hospitals around the country. An independent study showed that the model predictions\nunderperformed relative to the designer\u2019s claims while also causing \u2018alert fatigue\u2019 by falsely alerting\nlikelihood of sepsis.6\n\u2022", "1938b0e4-4263-45d4-8faa-c1d668a424c1": "\u2022\nOn social media, Black people who quote and criticize racist messages have had their own speech silenced when\na platform\u2019s automated moderation system failed to distinguish this \u201ccounter speech\u201d (or other critique", "280ee76b-a037-4e64-a5ef-b0a924563916": "and journalism) from the original hateful messages to which such speech responded.7\n\u2022\nA device originally developed to help people track and find lost items has been used as a tool by stalkers to track\nvictims\u2019 locations in violation of their privacy and safety. The device manufacturer took steps after release to\nprotect people from unwanted tracking by alerting people on their phones when a device is found to be moving\nwith them over time and also by having the device make an occasional noise, but not all phones are able\nto receive the notification and the devices remain a safety concern due to their misuse.8 \n\u2022\nAn algorithm used to deploy police was found to repeatedly send police to neighborhoods they regularly visit,", "604e5eb5-6d9c-4b92-b747-aff4269bc558": "even if those neighborhoods were not the ones with the highest crime rates. These incorrect crime predictions\nwere the result of a feedback loop generated from the reuse of data from previous arrests and algorithm\npredictions.9\n16", "43e9df7f-b104-488e-ade6-812ec0b85f76": "SAFE AND EFFECTIVE \nSYSTEMS \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \n\u2022\nAI-enabled \u201cnudification\u201d technology that creates images where people appear to be nude\u2014including apps that\nenable non-technical users to create or alter images of individuals without their consent\u2014has proliferated at an\nalarming rate. Such technology is becoming a common form of image-based abuse that disproportionately\nimpacts women. As these tools become more sophisticated, they are producing altered images that are increasing\u00ad", "3c449b5a-c2ea-40a6-b15c-c59ca58f6e40": "ly realistic and are difficult for both humans and AI to detect as inauthentic. Regardless of authenticity, the expe\u00ad\nrience of harm to victims of non-consensual intimate images can be devastatingly real\u2014affecting their personal\nand professional lives, and impacting their mental and physical health.10\n\u2022", "c3f37ade-3ffc-4098-857b-7f07e94ba162": "\u2022\nA company installed AI-powered cameras in its delivery vans in order to evaluate the road safety habits of its driv\u00ad\ners, but the system incorrectly penalized drivers when other cars cut them off or when other events beyond\ntheir control took place on the road. As a result, drivers were incorrectly ineligible to receive a bonus.11\n17", "634d3e1e-b2ab-42dd-8ad8-57013d5f96bf": "SAFE AND EFFECTIVE \nSYSTEMS \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nIn order to ensure that an automated system is safe and effective, it should include safeguards to protect the \npublic from harm in a proactive and ongoing manner; avoid use of data inappropriate for or irrelevant to the task \nat hand, including reuse that could cause compounded harm; and demonstrate the safety and effectiveness of \nthe system. These expectations are explained below. \nProtect the public from harm in a proactive and ongoing manner", "98564560-d952-479b-aa34-5020a64a3cf0": "Consultation. The public should be consulted in the design, implementation, deployment, acquisition, and \nmaintenance phases of automated system development, with emphasis on early-stage consultation before a", "acb01b35-7287-4e65-aa40-a9b96df85eb2": "system is introduced or a large change implemented. This consultation should directly engage diverse impact\u00ad\ned communities to consider concerns and risks that may be unique to those communities, or disproportionate\u00ad\nly prevalent or severe for them. The extent of this engagement and the form of outreach to relevant stakehold\u00ad\ners may differ depending on the specific automated system and development phase, but should include \nsubject matter, sector-specific, and context-specific experts as well as experts on potential impacts such as \ncivil rights, civil liberties, and privacy experts. For private sector applications, consultations before product", "6be2c786-aa9e-4a2b-848f-467ef69ab36c": "launch may need to be confidential. Government applications, particularly law enforcement applications or \napplications that raise national security considerations, may require confidential or limited engagement based \non system sensitivities and preexisting oversight laws and structures. Concerns raised in this consultation", "79abe2e9-b1f4-41a5-aea6-ad20a38685f5": "should be documented, and the automated system developers were proposing to create, use, or deploy should \nbe reconsidered based on this feedback. \nTesting. Systems should undergo extensive testing before deployment. This testing should follow \ndomain-specific best practices, when available, for ensuring the technology will work in its real-world \ncontext. Such testing should take into account both the specific technology used and the roles of any human \noperators or reviewers who impact system outcomes or effectiveness; testing should include both automated \nsystems testing and human-led (manual) testing. Testing conditions should mirror as closely as possible the", "d7cfcc0d-953a-4818-b77e-a89206c8bee3": "conditions in which the system will be deployed, and new testing may be required for each deployment to \naccount for material differences in conditions from one deployment to another. Following testing, system \nperformance should be compared with the in-place, potentially human-driven, status quo procedures, with", "8d000301-fae4-46f2-9274-9a6263bd184c": "existing human performance considered as a performance baseline for the algorithm to meet pre-deployment, \nand as a lifecycle minimum performance standard. Decision possibilities resulting from performance testing \nshould include the possibility of not deploying the system. \nRisk identification and mitigation. Before deployment, and in a proactive and ongoing manner, poten\u00ad\ntial risks of the automated system should be identified and mitigated. Identified risks should focus on the \npotential for meaningful impact on people\u2019s rights, opportunities, or access and include those to impacted \ncommunities that may not be direct users of the automated system, risks resulting from purposeful misuse of", "8cebe0ab-1fe9-4d44-9e6b-ac207e5b8dec": "the system, and other concerns identified via the consultation process. Assessment and, where possible, mea\u00ad\nsurement of the impact of risks should be included and balanced such that high impact risks receive attention", "84a037db-cea9-4f44-9971-d9c90396d636": "and mitigation proportionate with those impacts. Automated systems with the intended purpose of violating \nthe safety of others should not be developed or used; systems with such safety violations as identified unin\u00ad\ntended consequences should not be used until the risk can be mitigated. Ongoing risk mitigation may necessi\u00ad\ntate rollback or significant modification to a launched automated system. \n18", "2ed7e2e9-7c6f-401d-80ef-69c6eabf0cd6": "SAFE AND EFFECTIVE \nSYSTEMS \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nOngoing monitoring. Automated systems should have ongoing monitoring procedures, including recalibra\u00ad\ntion procedures, in place to ensure that their performance does not fall below an acceptable level over time, \nbased on changing real-world conditions or deployment contexts, post-deployment modification, or unexpect\u00ad\ned conditions. This ongoing monitoring should include continuous evaluation of performance metrics and", "828a4a33-7ba1-4355-b495-bc896d3d40bb": "harm assessments, updates of any systems, and retraining of any machine learning models as necessary, as well \nas ensuring that fallback mechanisms are in place to allow reversion to a previously working system. Monitor\u00ad", "e11aabba-876b-4e5d-8dfd-683a21d02b81": "ing should take into account the performance of both technical system components (the algorithm as well as \nany hardware components, data inputs, etc.) and human operators. It should include mechanisms for testing \nthe actual accuracy of any predictions or recommendations generated by a system, not just a human operator\u2019s \ndetermination of their accuracy. Ongoing monitoring procedures should include manual, human-led monitor\u00ad\ning as a check in the event there are shortcomings in automated monitoring systems. These monitoring proce\u00ad\ndures should be in place for the lifespan of the deployed automated system. \nClear organizational oversight. Entities responsible for the development or use of automated systems", "dd8b8faa-b4a8-4812-b225-efceea41bb03": "should lay out clear governance structures and procedures.  This includes clearly-stated governance proce\u00ad\ndures before deploying the system, as well as responsibility of specific individuals or entities to oversee ongoing", "599faa13-2fc4-4e30-ab66-711fc52e54e2": "assessment and mitigation. Organizational stakeholders including those with oversight of the business process \nor operation being automated, as well as other organizational divisions that may be affected due to the use of \nthe system, should be involved in establishing governance procedures. Responsibility should rest high enough \nin the organization that decisions about resources, mitigation, incident response, and potential rollback can be \nmade promptly, with sufficient weight given to risk mitigation objectives against competing concerns. Those \nholding this responsibility should be made aware of any use cases with the potential for meaningful impact on", "a8d0fa93-f94d-46fc-8b7a-81a1a132bd33": "people\u2019s rights, opportunities, or access as determined based on risk identification procedures.  In some cases, \nit may be appropriate for an independent ethics review to be conducted before deployment. \nAvoid inappropriate, low-quality, or irrelevant data use and the compounded harm of its \nreuse", "6f5dcd2c-142a-4fc8-920b-0408006ce5b2": "reuse \nRelevant and high-quality data. Data used as part of any automated system\u2019s creation, evaluation, or \ndeployment should be relevant, of high quality, and tailored to the task at hand. Relevancy should be \nestablished based on research-backed demonstration of the causal influence of the data to the specific use case \nor justified more generally based on a reasonable expectation of usefulness in the domain and/or for the \nsystem design or ongoing development. Relevance of data should not be established solely by appealing to \nits historical connection to the outcome. High quality and tailored data should be representative of the task at", "401393da-6a24-44d2-9b1c-2453ae9b31eb": "hand and errors from data entry or other sources should be measured and limited. Any data used as the target \nof a prediction process should receive particular attention to the quality and validity of the predicted outcome \nor label to ensure the goal of the automated system is appropriately identified and measured. Additionally,", "4c495844-5525-4cab-aca0-e3c7581aa4ad": "justification should be documented for each data attribute and source to explain why it is appropriate to use \nthat data to inform the results of the automated system and why such use will not violate any applicable laws. \nIn cases of high-dimensional and/or derived attributes, such justifications can be provided as overall \ndescriptions of the attribute generation process and appropriateness. \n19", "c306f26c-02dd-4598-9ad5-2efab6ed561b": "SAFE AND EFFECTIVE \nSYSTEMS \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nDerived data sources tracked and reviewed carefully. Data that is derived from other data through \nthe use of algorithms, such as data derived or inferred from prior model outputs, should be identified and \ntracked, e.g., via a specialized type in a data schema. Derived data should be viewed as potentially high-risk \ninputs that may lead to feedback loops, compounded harm, or inaccurate results. Such sources should be care\u00ad", "5e260492-8376-4428-b409-2d6342289682": "fully validated against the risk of collateral consequences. \nData reuse limits in sensitive domains. Data reuse, and especially data reuse in a new context, can result \nin the spreading and scaling of harms. Data from some domains, including criminal justice data and data indi\u00ad", "ac776309-a022-4e73-80b1-43235cdf4a39": "cating adverse outcomes in domains such as finance, employment, and housing, is especially sensitive, and in \nsome cases its reuse is limited by law. Accordingly, such data should be subject to extra oversight to ensure \nsafety and efficacy. Data reuse of sensitive domain data in other contexts (e.g., criminal data reuse for civil legal \nmatters or private sector use) should only occur where use of such data is legally authorized and, after examina\u00ad\ntion, has benefits for those impacted by the system that outweigh identified risks and, as appropriate, reason\u00ad\nable measures have been implemented to mitigate the identified risks. Such data should be clearly labeled to", "2b264d72-b64d-4cd9-be29-ae642ae5b475": "identify contexts for limited reuse based on sensitivity. Where possible, aggregated datasets may be useful for \nreplacing individual-level sensitive data. \nDemonstrate the safety and effectiveness of the system \nIndependent evaluation. Automated systems should be designed to allow for independent evaluation (e.g.,", "c1919033-ef4b-4716-b2ac-4804490699bd": "via application programming interfaces). Independent evaluators, such as researchers, journalists, ethics \nreview boards, inspectors general, and third-party auditors, should be given access to the system and samples \nof associated data, in a manner consistent with privacy, security, law, or regulation (including, e.g., intellectual \nproperty law), in order to perform such evaluations. Mechanisms should be included to ensure that system \naccess for evaluation is: provided in a timely manner to the deployment-ready version of the system; trusted to \nprovide genuine, unfiltered access to the full system; and truly independent such that evaluator access cannot \nbe revoked without reasonable and verified justification.", "bff772c4-5404-4e20-8222-33ec3537be57": "Reporting.12 Entities responsible for the development or use of automated systems should provide \nregularly-updated reports that include: an overview of the system, including how it is embedded in the", "f16e15db-1f21-4726-9763-40a8a6dc2c20": "organization\u2019s business processes or other activities, system goals, any human-run procedures that form a \npart of the system, and specific performance expectations; a description of any data used to train machine \nlearning models or for other purposes, including how data sources were processed and interpreted, a \nsummary of what data might be missing, incomplete, or erroneous, and data relevancy justifications; the \nresults of public consultation such as concerns raised and any decisions made due to these concerns; risk \nidentification and management assessments and any steps taken to mitigate potential harms; the results of \nperformance testing including, but not limited to, accuracy, differential demographic impact, resulting", "4390d731-2f14-4c4f-aaa1-919e1f9a0332": "error rates (overall and per demographic group), and comparisons to previously deployed systems; \nongoing monitoring procedures and regular performance testing reports, including monitoring frequency,", "e1e1be7b-91cb-447f-9005-9404702eaf14": "results, and actions taken; and the procedures for and results from independent evaluations. Reporting \nshould be provided in a plain language and machine-readable manner. \n20", "1adc9709-c6a6-41a8-b150-7caf0d836b02": "SAFE AND EFFECTIVE \nSYSTEMS \nHOW THESE PRINCIPLES CAN MOVE INTO PRACTICE\nReal-life examples of how these principles can become reality, through laws, policies, and practical \ntechnical and sociotechnical approaches to protecting rights, opportunities, and access. \u00ad\u00ad\nExecutive Order 13960 on Promoting the Use of Trustworthy Artificial Intelligence in the \nFederal Government requires that certain federal agencies adhere to nine principles when \ndesigning, developing, acquiring, or using AI for purposes other than national security or \ndefense. These principles\u2014while taking into account the sensitive law enforcement and other contexts in which", "52093311-f2d4-4234-812c-b2d589a6027d": "the federal government may use AI, as opposed to private sector use of AI\u2014require that AI is: (a) lawful and \nrespectful of our Nation\u2019s values; (b) purposeful and performance-driven; (c) accurate, reliable, and effective; (d)", "ed7930bf-9528-4748-8549-518835584165": "safe, secure, and resilient; (e) understandable; (f ) responsible and traceable; (g) regularly monitored; (h) transpar-\nent; and, (i) accountable. The Blueprint for an AI Bill of Rights is consistent with the Executive Order. \nAffected agencies across the federal government have released AI use case inventories13 and are implementing \nplans to bring those AI systems into compliance with the Executive Order or retire them. \nThe law and policy landscape for motor vehicles shows that strong safety regulations\u2014and \nmeasures to address harms when they occur\u2014can enhance innovation in the context of com-\nplex technologies. Cars, like automated digital systems, comprise a complex collection of components.", "f8de058e-1862-4e12-b132-0aafb363dc3b": "The National Highway Traffic Safety Administration,14 through its rigorous standards and independent \nevaluation, helps make sure vehicles on our roads are safe without limiting manufacturers\u2019 ability to", "d3a2c0bd-e970-495f-84f6-94b6a6c34514": "innovate.15 At the same time, rules of the road are implemented locally to impose contextually appropriate \nrequirements on drivers, such as slowing down near schools or playgrounds.16\nFrom large companies to start-ups, industry is providing innovative solutions that allow \norganizations to mitigate risks to the safety and efficacy of AI systems, both before \ndeployment and through monitoring over time.17 These innovative solutions include risk \nassessments, auditing mechanisms, assessment of organizational procedures, dashboards to allow for ongoing \nmonitoring, documentation procedures specific to model assessments, and many other strategies that aim to", "690c57f5-80a0-4731-986f-16b098030aad": "mitigate risks posed by the use of AI to companies\u2019 reputation, legal responsibilities, and other product safety \nand effectiveness concerns. \nThe Office of Management and Budget (OMB) has called for an expansion of opportunities \nfor meaningful stakeholder engagement in the design of programs and services. OMB also", "9554f69c-8ed8-489e-b75b-15d50b2a613d": "points to numerous examples of effective and proactive stakeholder engagement, including the Community-\nBased Participatory Research Program developed by the National Institutes of Health and the participatory \ntechnology assessments developed by the National Oceanic and Atmospheric Administration.18\nThe National Institute of Standards and Technology (NIST) is developing a risk \nmanagement framework to better manage risks posed to individuals, organizations, and \nsociety by AI.19 The NIST AI Risk Management Framework, as mandated by Congress, is intended for \nvoluntary use to help incorporate trustworthiness considerations into the design, development, use, and", "9060fdba-e234-4794-9afb-01a585a090b8": "evaluation of AI products, services, and systems. The NIST framework is being developed through a consensus-\ndriven, open, transparent, and collaborative process that includes workshops and other opportunities to provide \ninput. The NIST framework aims to foster the development of innovative approaches to address", "8acf607f-6f26-4ef3-b9f5-45a10b9ef91b": "characteristics of trustworthiness including accuracy, explainability and interpretability, reliability, privacy, \nrobustness, safety, security (resilience), and mitigation of unintended and/or harmful bias, as well as of \nharmful \nuses. \nThe \nNIST \nframework \nwill \nconsider \nand \nencompass \nprinciples \nsuch \nas \ntransparency, accountability, and fairness during pre-design, design and development, deployment, use, \nand testing and evaluation of AI technologies and systems. It is expected to be released in the winter of 2022-23. \n21", "c500fae5-e08d-499a-8459-ae483ab98017": "SAFE AND EFFECTIVE \nSYSTEMS \nHOW THESE PRINCIPLES CAN MOVE INTO PRACTICE\nReal-life examples of how these principles can become reality, through laws, policies, and practical \ntechnical and sociotechnical approaches to protecting rights, opportunities, and access. \u00ad\nSome U.S government agencies have developed specific frameworks for ethical use of AI \nsystems. The Department of Energy (DOE) has activated the AI Advancement Council that oversees coordina-\ntion and advises on implementation of the DOE AI Strategy and addresses issues and/or escalations on the \nethical use and development of AI systems.20 The Department of Defense has adopted Artificial Intelligence", "0b241eff-f114-4a94-981b-0a8d35ebf737": "Ethical Principles, and tenets for Responsible Artificial Intelligence specifically tailored to its national \nsecurity and defense activities.21 Similarly, the U.S. Intelligence Community (IC) has developed the Principles", "475c60ab-d40e-4a79-aa69-368b1cf12a0e": "of Artificial Intelligence Ethics for the Intelligence Community to guide personnel on whether and how to \ndevelop and use AI in furtherance of the IC's mission, as well as an AI Ethics Framework to help implement \nthese principles.22\nThe National Science Foundation (NSF) funds extensive research to help foster the \ndevelopment of automated systems that adhere to and advance their safety, security and \neffectiveness. Multiple NSF programs support research that directly addresses many of these principles: \nthe National AI Research Institutes23 support research on all aspects of safe, trustworthy, fair, and explainable \nAI algorithms and systems; the Cyber Physical Systems24 program supports research on developing safe", "10447d1e-046b-40db-9761-b4c52af2c271": "autonomous and cyber physical systems with AI components; the Secure and Trustworthy Cyberspace25 \nprogram supports research on cybersecurity and privacy enhancing technologies in automated systems; the", "525ff882-b6fc-471e-a237-2508c911df29": "Formal Methods in the Field26 program supports research on rigorous formal verification and analysis of \nautomated systems and machine learning, and the Designing Accountable Software Systems27 program supports \nresearch on rigorous and reproducible methodologies for developing software systems with legal and regulatory \ncompliance in mind. \nSome state legislatures have placed strong transparency and validity requirements on \nthe use of pretrial risk assessments. The use of algorithmic pretrial risk assessments has been a \ncause of concern for civil rights groups.28 Idaho Code Section 19-1910, enacted in 2019,29 requires that any \npretrial risk assessment, before use in the state, first be \"shown to be free of bias against any class of", "a8b81568-9cb4-4620-839d-6480e10c3ded": "individuals protected from discrimination by state or federal law\", that any locality using a pretrial risk \nassessment must first formally validate the claim of its being free of bias, that \"all documents, records, and", "3f62044a-91fb-43d1-8328-7258d1bb377f": "information used to build or validate the risk assessment shall be open to public inspection,\" and that assertions \nof trade secrets cannot be used \"to quash discovery in a criminal matter by a party to a criminal case.\" \n22", "9dd6783b-aef1-446f-aca5-174fe2733d29": "\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\nALGORITHMIC DISCRIMINATION Protections\nYou should not face discrimination by algorithms \nand systems should be used and designed in an \nequitable \nway. \nAlgorithmic \ndiscrimination \noccurs when \nautomated systems contribute to unjustified different treatment or \nimpacts disfavoring people based on their race, color, ethnicity, \nsex \n(including \npregnancy, \nchildbirth, \nand \nrelated \nmedical \nconditions, \ngender \nidentity, \nintersex \nstatus, \nand \nsexual \norientation), religion, age, national origin, disability, veteran status, \ngenetic infor-mation, or any other classification protected by law. \nDepending on the specific circumstances, such algorithmic \ndiscrimination may violate legal protections. Designers, developers,", "96cc9754-62b9-4888-b353-41a418ee394a": "and deployers of automated systems should take proactive and \ncontinuous measures to protect individuals and communities \nfrom algorithmic discrimination and to use and design systems in \nan equitable way.  This protection should include proactive equity", "311b5744-c4f0-4ad3-b85f-e9ce94e2a4ae": "assessments as part of the system design, use of representative data \nand protection against proxies for demographic features, ensuring \naccessibility for people with disabilities in design and development, \npre-deployment and ongoing disparity testing and mitigation, and \nclear organizational oversight. Independent evaluation and plain \nlanguage reporting in the form of an algorithmic impact assessment, \nincluding disparity testing results and mitigation information, \nshould be performed and made public whenever possible to confirm \nthese protections.\n23", "cc4d0423-7f61-4e50-9f5a-db28947eeaeb": "Algorithmic \nDiscrimination \nProtections \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \nThere is extensive evidence showing that automated systems can produce inequitable outcomes and amplify \nexisting inequity.30 Data that fails to account for existing systemic biases in American society can result in a range of \nconsequences. For example, facial recognition technology that can contribute to wrongful and discriminatory \narrests,31 hiring algorithms that inform discriminatory decisions, and healthcare algorithms that discount", "9d1a63ee-1798-42df-bf1b-9243a354eee2": "the severity of certain diseases in Black Americans. Instances of discriminatory practices built into and \nresulting from AI and other automated systems exist across many industries, areas, and contexts. While automated", "a7db17a0-0844-42e2-bd83-98531aa2146f": "systems have the capacity to drive extraordinary advances and innovations, algorithmic discrimination \nprotections should be built into their design, deployment, and ongoing use. \nMany companies, non-profits, and federal government agencies are already taking steps to ensure the public \nis protected from algorithmic discrimination. Some companies have instituted bias testing as part of their product \nquality assessment and launch procedures, and in some cases this testing has led products to be changed or not \nlaunched, preventing harm to the public. Federal government agencies have been developing standards and guidance \nfor the use of automated systems in order to help prevent bias. Non-profits and companies have developed best", "ec1cc028-c6b5-4ed3-8ead-795e8b203bed": "practices for audits and impact assessments to help identify potential algorithmic discrimination and provide \ntransparency to the public in the mitigation of such biases.", "603b8fca-56e9-45da-a574-61838e07c474": "But there is much more work to do to protect the public from algorithmic discrimination to use and design \nautomated systems in an equitable way. The guardrails protecting the public from discrimination in their daily \nlives should include their digital lives and impacts\u2014basic safeguards against abuse, bias, and discrimination to \nensure that all people are treated fairly when automated systems are used. This includes all dimensions of their \nlives, from hiring to loan approvals, from medical treatment and payment to encounters with the criminal \njustice system. Ensuring equity should also go beyond existing guardrails to consider the holistic impact that", "eeabe14f-572d-4d36-85f1-71cf7a135b3e": "automated systems make on underserved communities and to institute proactive protections that support these \ncommunities. \n\u2022\nAn automated system using nontraditional factors such as educational attainment and employment history as", "ccfb41a6-06a6-4fee-b3c1-b70941cef395": "part of its loan underwriting and pricing model was found to be much more likely to charge an applicant who\nattended a Historically Black College or University (HBCU) higher loan prices for refinancing a student loan\nthan an applicant who did not attend an HBCU. This was found to be true even when controlling for\nother credit-related factors.32\n\u2022\nA hiring tool that learned the features of a company's employees (predominantly men) rejected women appli\u00ad\ncants for spurious and discriminatory reasons; resumes with the word \u201cwomen\u2019s,\u201d such as \u201cwomen\u2019s\nchess club captain,\u201d were penalized in the candidate ranking.33\n\u2022\nA predictive model marketed as being able to predict whether students are likely to drop out of school was", "c495760e-bd11-4d71-9b4d-648374fb9be3": "used by more than 500 universities across the country. The model was found to use race directly as a predictor,\nand also shown to have large disparities by race; Black students were as many as four times as likely as their", "6cbc7310-fad5-4058-9ab8-d9bc441034de": "otherwise similar white peers to be deemed at high risk of dropping out. These risk scores are used by advisors \nto guide students towards or away from majors, and some worry that they are being used to guide\nBlack students away from math and science subjects.34\n\u2022\nA risk assessment tool designed to predict the risk of recidivism for individuals in federal custody showed\nevidence of disparity in prediction. The tool overpredicts the risk of recidivism for some groups of color on the\ngeneral recidivism tools, and underpredicts the risk of recidivism for some groups of color on some of the\nviolent recidivism tools. The Department of Justice is working to reduce these disparities and has", "29ef6af6-d911-464f-850a-2881c349bb97": "publicly released a report detailing its review of the tool.35 \n24", "ba38e80a-f524-42bf-b718-7523d101d31d": "WHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \u00ad\u00ad\u00ad\n\u2022\nAn automated sentiment analyzer, a tool often used by technology platforms to determine whether a state-\nment posted online expresses a positive or negative sentiment, was found to be biased against Jews and gay\npeople. For example, the analyzer marked the statement \u201cI\u2019m a Jew\u201d as representing a negative sentiment,\nwhile \u201cI\u2019m a Christian\u201d was identified as expressing a positive sentiment.36 This could lead to the\npreemptive blocking of social media comments such as: \u201cI\u2019m gay.\u201d A related company with this bias concern", "16896240-a88f-4095-950e-064720eb2ed4": "has made their data public to encourage researchers to help address the issue37 and has released reports\nidentifying and measuring this problem as well as detailing attempts to address it.38\n\u2022", "fce722e6-04a3-4c23-b66d-fa86b3e5ac2a": "\u2022\nSearches for \u201cBlack girls,\u201d \u201cAsian girls,\u201d or \u201cLatina girls\u201d return predominantly39 sexualized content, rather\nthan role models, toys, or activities.40 Some search engines have been working to reduce the prevalence of\nthese results, but the problem remains.41\n\u2022\nAdvertisement delivery systems that predict who is most likely to click on a job advertisement end up deliv-\nering ads in ways that reinforce racial and gender stereotypes, such as overwhelmingly directing supermar-\nket cashier ads to women and jobs with taxi companies to primarily Black people.42\u00ad\n\u2022\nBody scanners, used by TSA at airport checkpoints, require the operator to select a \u201cmale\u201d or \u201cfemale\u201d", "24ca8649-3a2a-4911-9c22-7a26feb8f32c": "scanning setting based on the passenger\u2019s sex, but the setting is chosen based on the operator\u2019s perception of\nthe passenger\u2019s gender identity. These scanners are more likely to flag transgender travelers as requiring\nextra screening done by a person. Transgender travelers have described degrading experiences associated", "56b4723a-5f37-4433-8284-3a2f6af98581": "with these extra screenings.43 TSA has recently announced plans to implement a gender-neutral algorithm44 \nwhile simultaneously enhancing the security effectiveness capabilities of the existing technology. \n\u2022\nThe National Disabled Law Students Association expressed concerns that individuals with disabilities were\nmore likely to be flagged as potentially suspicious by remote proctoring AI systems because of their disabili-\nty-specific access needs such as needing longer breaks or using screen readers or dictation software.45 \n\u2022\nAn algorithm designed to identify patients with high needs for healthcare systematically assigned lower\nscores (indicating that they were not as high need) to Black patients than to those of white patients, even", "60e3c0f6-359c-4e72-aa39-9bc6946a011f": "when those patients had similar numbers of chronic conditions and other markers of health.46 In addition,\nhealthcare clinical algorithms that are used by physicians to guide clinical decisions may include", "bc4b39dd-5dea-44a1-96e2-58bc872d03ab": "sociodemographic variables that adjust or \u201ccorrect\u201d the algorithm\u2019s output on the basis of a patient\u2019s race or\nethnicity, which can lead to race-based health inequities.47\n25\nAlgorithmic \nDiscrimination \nProtections", "84ca0df8-85b1-45a3-8c9e-79b373987623": "WHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nAny automated system should be tested to help ensure it is free from algorithmic discrimination before it can be \nsold or used. Protection against algorithmic discrimination should include designing to ensure equity, broadly \nconstrued.  Some algorithmic discrimination is already prohibited under existing anti-discrimination law. The \nexpectations set out below describe proactive technical and policy steps that can be taken to not only", "5dff4530-1ff6-4a3f-b9e7-3e75aab0fb1c": "reinforce those legal protections but extend beyond them to ensure equity for underserved communities48 \neven in circumstances where a specific legal protection may not be clearly established. These protections", "8e8cf8c6-0d64-4a12-8671-01ab73aabda5": "should be instituted throughout the design, development, and deployment process and are described below \nroughly in the order in which they would be instituted. \nProtect the public from algorithmic discrimination in a proactive and ongoing manner \nProactive assessment of equity in design. Those responsible for the development, use, or oversight of \nautomated systems should conduct proactive equity assessments in the design phase of the technology \nresearch and development or during its acquisition to review potential input data, associated historical \ncontext, accessibility for people with disabilities, and societal goals to identify potential discrimination and", "55480cb7-a3d5-4f14-af37-7ead5662435c": "effects on equity resulting from the introduction of the technology. The assessed groups should be as inclusive \nas possible of the underserved communities mentioned in the equity definition:  Black, Latino, and Indigenous", "2f9ab334-4d57-4956-823b-9eab20ca50ed": "and Native American persons, Asian Americans and Pacific Islanders and other persons of color; members of \nreligious minorities; women, girls, and non-binary people; lesbian, gay, bisexual, transgender, queer, and inter-\nsex (LGBTQI+) persons; older adults; persons with disabilities; persons who live in rural areas; and persons \notherwise adversely affected by persistent poverty or inequality. Assessment could include both qualitative \nand quantitative evaluations of the system. This equity assessment should also be considered a core part of the \ngoals of the consultation conducted as part of the safety and efficacy review. \nRepresentative and robust data. Any data used as part of system development or assessment should be", "c892c84a-441a-4446-8d33-32482d0268bd": "representative of local communities based on the planned deployment setting and should be reviewed for bias \nbased on the historical and societal context of the data. Such data should be sufficiently robust to identify and", "fb52d600-4eb2-4e60-8460-2a0b715b901b": "help to mitigate biases and potential harms. \nGuarding against proxies.  Directly using demographic information in the design, development, or \ndeployment of an automated system (for purposes other than evaluating a system for discrimination or using \na system to counter discrimination) runs a high risk of leading to algorithmic discrimination and should be \navoided. In many cases, attributes that are highly correlated with demographic features, known as proxies, can \ncontribute to algorithmic discrimination. In cases where use of the demographic features themselves would \nlead to illegal algorithmic discrimination, reliance on such proxies in decision-making (such as that facilitated", "ecc7f906-cf45-4cdb-9805-4ca65d930bd3": "by an algorithm) may also be prohibited by law. Proactive testing should be performed to identify proxies by \ntesting for correlation between demographic information and attributes in any data used as part of system", "4c5dc65b-62aa-49c5-aa0c-034a5acea392": "design, development, or use. If a proxy is identified, designers, developers, and deployers should remove the \nproxy; if needed, it may be possible to identify alternative attributes that can be used instead. At a minimum, \norganizations should ensure a proxy feature is not given undue weight and should monitor the system closely \nfor any resulting algorithmic discrimination.   \n26\nAlgorithmic \nDiscrimination \nProtections", "8f8d9ed7-e52a-45fe-b9dc-06dec8ed9b77": "WHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nEnsuring accessibility during design, development, and deployment. Systems should be \ndesigned, developed, and deployed by organizations in ways that ensure accessibility to people with disabili\u00ad\nties. This should include consideration of a wide variety of disabilities, adherence to relevant accessibility \nstandards, and user experience research both before and after deployment to identify and address any accessi\u00ad\nbility barriers to the use or effectiveness of the automated system.", "b0c6c6e4-2da0-49ec-8eba-d0c7e804bc63": "Disparity assessment. Automated systems should be tested using a broad set of measures to assess wheth\u00ad\ner the system components, both in pre-deployment testing and in-context deployment, produce disparities.", "bf1251e9-dc28-4c1c-9027-614b6b041c98": "The demographics of the assessed groups should be as inclusive as possible of race, color, ethnicity, sex \n(including pregnancy, childbirth, and related medical conditions, gender identity, intersex status, and sexual \norientation), religion, age, national origin, disability, veteran status, genetic information, or any other classifi\u00ad\ncation protected by law. The broad set of measures assessed should include demographic performance mea\u00ad\nsures, overall and subgroup parity assessment, and calibration. Demographic data collected for disparity \nassessment should be separated from data used for the automated system and privacy protections should be", "4661cc35-825c-433f-9cb2-5dce09a5221e": "instituted; in some cases it may make sense to perform such assessment using a data sample. For every \ninstance where the deployed automated system leads to different treatment or impacts disfavoring the identi\u00ad\nfied groups, the entity governing, implementing, or using the system should document the disparity and a", "470c75c6-cd81-478b-b24e-7b8e3dd87d24": "justification for any continued use of the system. \nDisparity mitigation. When a disparity assessment identifies a disparity against an assessed group, it may \nbe appropriate to take steps to mitigate or eliminate the disparity. In some cases, mitigation or elimination of \nthe disparity may be required by law. \nDisparities that have the potential to lead to algorithmic \ndiscrimination, cause meaningful harm, or violate equity49 goals should be mitigated. When designing and \nevaluating an automated system, steps should be taken to evaluate multiple models and select the one that \nhas the least adverse impact, modify data input choices, or otherwise identify a system with fewer", "027a71e7-8f08-425c-a75f-21f0d2686848": "disparities. If adequate mitigation of the disparity is not possible, then the use of the automated system \nshould be reconsidered. One of the considerations in whether to use the system should be the validity of any", "7f80c238-3fc8-442d-b4d8-8b6951453847": "target measure; unobservable targets may result in the inappropriate use of proxies. Meeting these \nstandards may require instituting mitigation procedures and other protective measures to address \nalgorithmic discrimination, avoid meaningful harm, and achieve equity goals. \nOngoing monitoring and mitigation. Automated systems should be regularly monitored to assess algo\u00ad\nrithmic discrimination that might arise from unforeseen interactions of the system with inequities not \naccounted for during the pre-deployment testing, changes to the system after deployment, or changes to the \ncontext of use or associated data. Monitoring and disparity assessment should be performed by the entity", "eef2691e-1cc7-48ed-b137-4715e94324d4": "deploying or using the automated system to examine whether the system has led to algorithmic discrimina\u00ad\ntion when deployed. This assessment should be performed regularly and whenever a pattern of unusual", "fdded924-58f7-401a-bec9-ca76d9ec82b3": "results is occurring. It can be performed using a variety of approaches, taking into account whether and how \ndemographic information of impacted people is available, for example via testing with a sample of users or via \nqualitative user experience research. Riskier and higher-impact systems should be monitored and assessed \nmore frequently. Outcomes of this assessment should include additional disparity mitigation, if needed, or \nfallback to earlier procedures in the case that equity standards are no longer met and can't be mitigated, and \nprior mechanisms provide better adherence to equity standards. \n27\nAlgorithmic \nDiscrimination \nProtections", "f0f9e11f-6729-473c-ab75-1c62e99d705a": "WHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nDemonstrate that the system protects against algorithmic discrimination \nIndependent evaluation. As described in the section on Safe and Effective Systems, entities should allow \nindependent evaluation of potential algorithmic discrimination caused by automated systems they use or \noversee. In the case of public sector uses, these independent evaluations should be made public unless law \nenforcement or national security restrictions prevent doing so. Care should be taken to balance individual", "a986561a-360e-48e7-beb9-87037aa7cd47": "privacy with evaluation data access needs; in many cases, policy-based and/or technological innovations and \ncontrols allow access to such data without compromising privacy.", "ec31d62b-7e61-4ed9-b789-1c9702ab5e86": "Reporting. Entities responsible for the development or use of automated systems should provide \nreporting of an appropriately designed algorithmic impact assessment,50 with clear specification of who \nperforms the assessment, who evaluates the system, and how corrective actions are taken (if necessary) in \nresponse to the assessment. This algorithmic impact assessment should include at least: the results of any \nconsultation, design stage equity assessments (potentially including qualitative analysis), accessibility \ndesigns and testing, disparity testing, document any remaining disparities, and detail any mitigation \nimplementation and assessments. This algorithmic impact assessment should be made public whenever", "ead55ff2-d1e6-4be6-8dc6-928bd07db5e8": "possible. Reporting should be provided in a clear and machine-readable manner using plain language to \nallow for more straightforward public accountability. \n28\nAlgorithmic \nDiscrimination \nProtections", "34e252d7-c874-4327-89f3-30eeac1b5ee3": "HOW THESE PRINCIPLES CAN MOVE INTO PRACTICE\nReal-life examples of how these principles can become reality, through laws, policies, and practical \ntechnical and sociotechnical approaches to protecting rights, opportunities, and access. \nThe federal government is working to combat discrimination in mortgage lending. The Depart\u00ad\nment of Justice has launched a nationwide initiative to combat redlining, which includes reviewing how \nlenders who may be avoiding serving communities of color are conducting targeted marketing and advertising.51 \nThis initiative will draw upon strong partnerships across federal agencies, including the Consumer Financial", "e41566f6-9a2d-47ed-b372-d0b820bad2d4": "Protection Bureau and prudential regulators. The Action Plan to Advance Property Appraisal and Valuation \nEquity includes a commitment from the agencies that oversee mortgage lending to include a \nnondiscrimination standard in the proposed rules for Automated Valuation Models.52", "5ef66507-d7c7-40c2-9289-49e5da0ecfe2": "The Equal Employment Opportunity Commission and the Department of Justice have clearly \nlaid out how employers\u2019 use of AI and other automated systems can result in \ndiscrimination against job applicants and employees with disabilities.53 The documents explain \nhow employers\u2019 use of software that relies on algorithmic decision-making may violate existing requirements \nunder Title I of the Americans with Disabilities Act (\u201cADA\u201d). This technical assistance also provides practical \ntips to employers on how to comply with the ADA, and to job applicants and employees who think that their \nrights may have been violated. \nDisparity assessments identified harms to Black patients' healthcare access. A widely", "70d312e2-f894-4c1d-a040-551ad2f77bce": "used healthcare algorithm relied on the cost of each patient\u2019s past medical care to predict future medical needs, \nrecommending early interventions for the patients deemed most at risk. This process discriminated", "e1f0b86a-6aea-46a8-9a60-ccd7898b473e": "against Black patients, who generally have less access to medical care and therefore have generated less cost \nthan white patients with similar illness and need. A landmark study documented this pattern and proposed \npractical ways that were shown to reduce this bias, such as focusing specifically on active chronic health \nconditions or avoidable future costs related to emergency visits and hospitalization.54 \nLarge employers have developed best practices to scrutinize the data and models used \nfor hiring. An industry initiative has developed Algorithmic Bias Safeguards for the Workforce, a structured \nquestionnaire that businesses can use proactively when procuring software to evaluate workers. It covers", "4f92e1d1-c593-412c-94cd-1386429cf49c": "specific technical questions such as the training data used, model training process, biases identified, and \nmitigation steps employed.55 \nStandards organizations have developed guidelines to incorporate accessibility criteria", "3b5de4a3-2641-4153-a259-a68f706b139a": "into technology design processes. The most prevalent in the United States is the Access Board\u2019s Section \n508 regulations,56 which are the technical standards for federal information communication technology (software, \nhardware, and web). Other standards include those issued by the International Organization for \nStandardization,57 and the World Wide Web Consortium Web Content Accessibility Guidelines,58 a globally \nrecognized voluntary consensus standard for web content and other information and communications \ntechnology. \nNIST has released Special Publication 1270, Towards a Standard for Identifying and Managing Bias \nin Artificial Intelligence.59 The special publication: describes the stakes and challenges of bias in artificial", "1e7debda-9c18-4cc9-814b-19b1db54e4b9": "intelligence and provides examples of how and why it can chip away at public trust; identifies three categories \nof bias in AI \u2013 systemic, statistical, and human \u2013 and describes how and where they contribute to harms; and", "8941f80b-a71d-479f-8357-03ad122aa90d": "describes three broad challenges for mitigating bias \u2013 datasets, testing and evaluation, and human factors \u2013 and \nintroduces preliminary guidance for addressing them. Throughout, the special publication takes a socio-\ntechnical perspective to identifying and managing AI bias. \n29\nAlgorithmic \nDiscrimination \nProtections", "5fc30f25-9335-4bfc-b5e5-8b5cae07975b": "You should be protected from abusive data practices via built-in \nprotections and you should have agency over how data about \nyou is used. You should be protected from violations of privacy through \ndesign choices that ensure such protections are included by default, including \nensuring that data collection conforms to reasonable expectations and that \nonly data strictly necessary for the specific context is collected. Designers, de\u00ad\nvelopers, and deployers of automated systems should seek your permission \nand respect your decisions regarding collection, use, access, transfer, and de\u00ad\nletion of your data in appropriate ways and to the greatest extent possible; \nwhere not possible, alternative privacy by design safeguards should be used.", "220d232d-3757-40bd-9588-e757400f2ed5": "Systems should not employ user experience and design decisions that obfus\u00ad\ncate user choice or burden users with defaults that are privacy invasive. Con\u00ad\nsent should only be used to justify collection of data in cases where it can be", "6b0ac03e-f44d-4868-a741-80cb6dc7296b": "appropriately and meaningfully given. Any consent requests should be brief, \nbe understandable in plain language, and give you agency over data collection \nand the specific context of use; current hard-to-understand no\u00ad\ntice-and-choice practices for broad uses of data should be changed. Enhanced \nprotections and restrictions for data and inferences related to sensitive do\u00ad\nmains, including health, work, education, criminal justice, and finance, and \nfor data pertaining to youth should put you first. In sensitive domains, your \ndata and related inferences should only be used for necessary functions, and \nyou should be protected by ethical review and use prohibitions. You and your", "bb65b911-cb4a-4ab2-915d-e9f975f33586": "communities should be free from unchecked surveillance; surveillance tech\u00ad\nnologies should be subject to heightened oversight that includes at least \npre-deployment assessment of their potential harms and scope limits to pro\u00ad\ntect privacy and civil liberties. Continuous surveillance and monitoring", "5fb441cd-74d2-4a60-8a18-528ce7122a5c": "should not be used in education, work, housing, or in other contexts where the \nuse of such surveillance technologies is likely to limit rights, opportunities, or \naccess. Whenever possible, you should have access to reporting that confirms \nyour data decisions have been respected and provides an assessment of the \npotential impact of surveillance technologies on your rights, opportunities, or \naccess. \nDATA PRIVACY\n30", "3e409470-ef0d-43c8-9078-242397bef7ce": "DATA PRIVACY \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \nData privacy is a foundational and cross-cutting principle required for achieving all others in this framework. Surveil\u00ad\nlance and data collection, sharing, use, and reuse now sit at the foundation of business models across many industries, \nwith more and more companies tracking the behavior of the American public, building individual profiles based on \nthis data, and using this granular-level information as input into automated systems that further track, profile, and", "62c7f759-9cb8-4901-b188-1f5a6a3383a1": "impact the American public. Government agencies, particularly law enforcement agencies, also use and help develop \na variety of technologies that enhance and expand surveillance capabilities, which similarly collect data used as input", "e5d65906-f021-4a13-a6c8-1872aee38996": "into other automated systems that directly impact people\u2019s lives. Federal law has not grown to address the expanding \nscale of private data collection, or of the ability of governments at all levels to access that data and leverage the means \nof private collection.  \nMeanwhile, members of the American public are often unable to access their personal data or make critical decisions \nabout its collection and use. Data brokers frequently collect consumer data from numerous sources without \nconsumers\u2019 permission or knowledge.60 Moreover, there is a risk that inaccurate and faulty data can be used to \nmake decisions about their lives, such as whether they will qualify for a loan or get a job. Use of surveillance", "5c96aa32-1661-4120-ad69-d39e8078e14f": "technologies has increased in schools and workplaces, and, when coupled with consequential management and \nevaluation decisions, it is leading to mental health harms such as lowered self-confidence, anxiety, depression, and", "d4b3b7ec-6902-4416-9a54-1256fae020c6": "a reduced ability to use analytical reasoning.61 Documented patterns show that personal data is being aggregated by \ndata brokers to profile communities in harmful ways.62 The impact of all this data harvesting is corrosive, \nbreeding distrust, anxiety, and other mental health problems; chilling speech, protest, and worker organizing; and \nthreatening our democratic process.63 The American public should be protected from these growing risks. \nIncreasingly, some companies are taking these concerns seriously and integrating mechanisms to protect consumer \nprivacy into their products by design and by default, including by minimizing the data they collect, communicating", "bba97538-3a78-4be9-bee1-81cefd7e7bf6": "collection and use clearly, and improving security practices. Federal government surveillance and other collection and \nuse of data is governed by legal protections that help to protect civil liberties and provide for limits on data retention", "c3c68ad8-ef3a-4d32-a617-33b56e18d825": "in some cases. Many states have also enacted consumer data privacy protection regimes to address some of these \nharms. \nHowever, these are not yet standard practices, and the United States lacks a comprehensive statutory or regulatory \nframework governing the rights of the public when it comes to personal data. While a patchwork of laws exists to \nguide the collection and use of personal data in specific contexts, including health, employment, education, and credit, \nit can be unclear how these laws apply in other contexts and in an increasingly automated society. Additional protec\u00ad\ntions would assure the American public that the automated systems they use are not monitoring their activities,", "0581c2b2-5c4d-491e-b8e2-44bf8fae2a05": "collecting information on their lives, or otherwise surveilling them without context-specific consent or legal authori\u00ad\nty. \n31", "430134fc-390d-4594-af75-468053ae0d63": "DATA PRIVACY \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \n\u2022\nAn insurer might collect data from a person's social media presence as part of deciding what life\ninsurance rates they should be offered.64\n\u2022\nA data broker harvested large amounts of personal data and then suffered a breach, exposing hundreds of\nthousands of people to potential identity theft. 65\n\u2022\nA local public housing authority installed a facial recognition system at the entrance to housing complexes to\nassist law enforcement with identifying individuals viewed via camera when police reports are filed, leading", "3e8ab056-45e3-44aa-9ae8-598391fe320f": "the community, both those living in the housing complex and not, to have videos of them sent to the local\npolice department and made available for scanning by its facial recognition software.66\n\u2022", "7820dd1c-b91f-4d5a-9797-8e03b791798e": "\u2022\nCompanies use surveillance software to track employee discussions about union activity and use the\nresulting data to surveil individual employees and surreptitiously intervene in discussions.67\n32", "95e71866-dd41-4c03-8e47-03785df2f0d9": "DATA PRIVACY \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nTraditional terms of service\u2014the block of text that the public is accustomed to clicking through when using a web\u00ad\nsite or digital app\u2014are not an adequate mechanism for protecting privacy. The American public should be protect\u00ad\ned via built-in privacy protections, data minimization, use and collection limitations, and transparency, in addition \nto being entitled to clear mechanisms to control access to and use of their data\u2014including their metadata\u2014in a", "1f185603-4a6b-4da7-9125-cb9f26353814": "proactive, informed, and ongoing way. Any automated system collecting, using, sharing, or storing personal data \nshould meet these expectations. \nProtect privacy by design and by default", "f7553446-3508-4029-a051-79609e731f77": "Protect privacy by design and by default \nPrivacy by design and by default. Automated systems should be designed and built with privacy protect\u00ad\ned by default. Privacy risks should be assessed throughout the development life cycle, including privacy risks \nfrom reidentification, and appropriate technical and policy mitigation measures should be implemented. This \nincludes potential harms to those who are not users of the automated system, but who may be harmed by \ninferred data, purposeful privacy violations, or community surveillance or other community harms. Data \ncollection should be minimized and clearly communicated to the people whose data is collected. Data should", "602e81cb-3dc4-4ab1-a349-1b080c24381d": "only be collected or used for the purposes of training or testing machine learning models if such collection and \nuse is legal and consistent with the expectations of the people whose data is collected. User experience", "ca02d308-3272-408e-933d-6a6d1ed8203d": "research should be conducted to confirm that people understand what data is being collected about them and \nhow it will be used, and that this collection matches their expectations and desires. \nData collection and use-case scope limits. Data collection should be limited in scope, with specific, \nnarrow identified goals, to avoid \"mission creep.\"  Anticipated data collection should be determined to be \nstrictly necessary to the identified goals and should be minimized as much as possible. Data collected based on \nthese identified goals and for a specific context should not be used in a different context without assessing for \nnew privacy risks and implementing appropriate mitigation measures, which may include express consent.", "289b8b06-49a6-45b5-a48c-93c990252809": "Clear timelines for data retention should be established, with data deleted as soon as possible in accordance \nwith legal or policy-based limitations. Determined data retention timelines should be documented and justi\u00ad\nfied.", "835dfd47-b745-430a-83c8-cdb328fde0f0": "fied. \nRisk identification and mitigation. Entities that collect, use, share, or store sensitive data should \nattempt to proactively identify harms and seek to manage them so as to avoid, mitigate, and respond appropri\u00ad\nately to identified risks. Appropriate responses include determining not to process data when the privacy risks \noutweigh the benefits or implementing measures to mitigate acceptable risks. Appropriate responses do not \ninclude sharing or transferring the privacy risks to users via notice or consent requests where users could not \nreasonably be expected to understand the risks without further support. \nPrivacy-preserving security. Entities creating, using, or governing automated systems should follow", "cafbdf81-f1b5-4945-810d-e10e48132be9": "privacy and security best practices designed to ensure data and metadata do not leak beyond the specific \nconsented use case. Best practices could include using privacy-enhancing cryptography or other types of", "1d058472-4335-4e50-80c8-0b02499fa382": "privacy-enhancing technologies or fine-grained permissions and access control mechanisms, along with \nconventional system security protocols. \n33", "2c886e68-248f-44ab-a137-bebe1bbc4b90": "DATA PRIVACY \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nProtect the public from unchecked surveillance \nHeightened oversight of surveillance. Surveillance or monitoring systems should be subject to \nheightened oversight that includes at a minimum assessment of potential harms during design (before deploy\u00ad\nment) and in an ongoing manner, to ensure that the American public\u2019s rights, opportunities, and access are \nprotected. This assessment should be done before deployment and should give special attention to ensure", "02a26c28-7802-4101-a4c9-6f21c83fa025": "there is not algorithmic discrimination, especially based on community membership, when deployed in a \nspecific real-world context. Such assessment should then be reaffirmed in an ongoing manner as long as the \nsystem is in use.", "92f8795c-a8f8-441a-8d0f-a9e11840a3d6": "system is in use. \nLimited and proportionate surveillance. Surveillance should be avoided unless it is strictly necessary \nto achieve a legitimate purpose and it is proportionate to the need. Designers, developers, and deployers of \nsurveillance systems should use the least invasive means of monitoring available and restrict monitoring to the \nminimum number of subjects possible. To the greatest extent possible consistent with law enforcement and \nnational security needs, individuals subject to monitoring should be provided with clear and specific notice \nbefore it occurs and be informed about how the data gathered through surveillance will be used.", "7e9d066f-08d2-4094-ba40-0b4a7e51d990": "Scope limits on surveillance to protect rights and democratic values. Civil liberties and civil \nrights must not be limited by the threat of surveillance or harassment facilitated or aided by an automated \nsystem. Surveillance systems should not be used to monitor the exercise of democratic rights, such as voting,", "04802aba-c172-4119-a321-1b9391d4733d": "privacy, peaceful assembly, speech, or association, in a way that limits the exercise of civil rights or civil liber\u00ad\nties. Information about or algorithmically-determined assumptions related to identity should be carefully \nlimited if used to target or guide surveillance systems in order to avoid algorithmic discrimination; such iden\u00ad\ntity-related information includes group characteristics or affiliations, geographic designations, location-based \nand association-based inferences, social networks, and biometrics. Continuous surveillance and monitoring \nsystems should not be used in physical or digital workplaces (regardless of employment status), public educa\u00ad", "00faaef0-e776-484d-a329-07a7d085de24": "tional institutions, and public accommodations. Continuous surveillance and monitoring systems should not \nbe used in a way that has the effect of limiting access to critical resources or services or suppressing the exer\u00ad\ncise of rights, even where the organization is not under a particular duty to protect those rights.", "cb2cf1b0-d4c1-4deb-a6b3-af1743ecef7f": "Provide the public with mechanisms for appropriate and meaningful consent, access, and \ncontrol over their data \nUse-specific consent. Consent practices should not allow for abusive surveillance practices. Where data \ncollectors or automated systems seek consent, they should seek it for specific, narrow use contexts, for specif\u00ad\nic time durations, and for use by specific entities. Consent should not extend if any of these conditions change; \nconsent should be re-acquired before using data if the use case changes, a time limit elapses, or data is trans\u00ad\nferred to another entity (including being shared or sold). Consent requested should be limited in scope and", "811b47c1-c491-4e11-b1cf-fde37a1d35e9": "should not request consent beyond what is required. Refusal to provide consent should be allowed, without \nadverse effects, to the greatest extent possible based on the needs of the use case. \nBrief and direct consent requests. When seeking consent from users short, plain language consent", "a46adb8f-f78a-466e-8c6d-b4296c849ca8": "requests should be used so that users understand for what use contexts, time span, and entities they are \nproviding data and metadata consent. User experience research should be performed to ensure these consent \nrequests meet performance standards for readability and comprehension. This includes ensuring that consent \nrequests are accessible to users with disabilities and are available in the language(s) and reading level appro\u00ad\npriate for the audience.  User experience design choices that intentionally obfuscate or manipulate user \nchoice (i.e., \u201cdark patterns\u201d) should be not be used. \n34", "a1c3f7a7-f72f-48e4-9364-6583bd972bc0": "DATA PRIVACY \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nData access and correction. People whose data is collected, used, shared, or stored by automated \nsystems should be able to access data and metadata about themselves, know who has access to this data, and \nbe able to correct it if necessary. Entities should receive consent before sharing data with other entities and \nshould keep records of what data is shared and with whom. \nConsent withdrawal and data deletion. Entities should allow (to the extent legally permissible) with\u00ad", "3bc83b38-a0a2-480c-9107-84a200b23a90": "drawal of data access consent, resulting in the deletion of user data, metadata, and the timely removal of \ntheir data from any systems (e.g., machine learning models) derived from that data.68", "8e35abe2-146d-4b6d-a89f-85a1622e77e9": "Automated system support. Entities designing, developing, and deploying automated systems should \nestablish and maintain the capabilities that will allow individuals to use their own automated systems to help \nthem make consent, access, and control decisions in a complex data ecosystem. Capabilities include machine \nreadable data, standardized data formats, metadata or tags for expressing data processing permissions and \npreferences and data provenance and lineage, context of use and access-specific tags, and training models for \nassessing privacy risk. \nDemonstrate that data privacy and user control are protected \nIndependent evaluation. As described in the section on Safe and Effective Systems, entities should allow", "6477776e-d4bc-468e-9eb0-a0344590fb46": "independent evaluation of the claims made regarding data policies. These independent evaluations should be \nmade public whenever possible. Care will need to be taken to balance individual privacy with evaluation data \naccess needs.", "f2f97beb-ab11-4a13-aab0-c1a3801e7fbf": "access needs. \nReporting. When members of the public wish to know what data about them is being used in a system, the \nentity responsible for the development of the system should respond quickly with a report on the data it has \ncollected or stored about them. Such a report should be machine-readable, understandable by most users, and \ninclude, to the greatest extent allowable under law, any data and metadata about them or collected from them, \nwhen and how their data and metadata were collected, the specific ways that data or metadata are being used, \nwho has access to their data and metadata, and what time limitations apply to these data. In cases where a user", "ca9d3ce6-52e5-4793-8b80-15470d1b6649": "login is not available, identity verification may need to be performed before providing such a report to ensure \nuser privacy. Additionally, summary reporting should be proactively made public with general information \nabout how peoples\u2019 data and metadata is used, accessed, and stored. Summary reporting should include the", "31db808a-c9b8-41cd-8ae6-486da8608489": "results of any surveillance pre-deployment assessment, including disparity assessment in the real-world \ndeployment context, the specific identified goals of any data collection, and the assessment done to ensure \nonly the minimum required data is collected. It should also include documentation about the scope limit \nassessments, including data retention timelines and associated justification, and an assessment of the \nimpact of surveillance or data collection on rights, opportunities, and access. Where possible, this \nassessment of the impact of surveillance should be done by an independent party. Reporting should be \nprovided in a clear and machine-readable manner.  \n35", "27e57bb0-1c08-4180-85cb-d66d23396007": "DATA PRIVACY \nEXTRA PROTECTIONS FOR DATA RELATED TO SENSITIVE\nDOMAINS\nSome domains, including health, employment, education, criminal justice, and personal finance, have long been \nsingled out as sensitive domains deserving of enhanced data protections. This is due to the intimate nature of these \ndomains as well as the inability of individuals to opt out of these domains in any meaningful way, and the \nhistorical discrimination that has often accompanied data knowledge.69 Domains understood by the public to be \nsensitive also change over time, including because of technological developments. Tracking and monitoring \ntechnologies, personal tracking devices, and our extensive data footprints are used and misused more than ever", "df5e4bff-4d76-426b-8243-be141247b730": "before; as such, the protections afforded by current legal guidelines may be inadequate. The American public \ndeserves assurances that data related to such sensitive domains is protected and used appropriately and only in", "582b6172-deda-47f4-89fe-fbedf6626275": "narrowly defined contexts with clear benefits to the individual and/or society. \nTo this end, automated systems that collect, use, share, or store data related to these sensitive domains should meet \nadditional expectations. Data and metadata are sensitive if they pertain to an individual in a sensitive domain (defined \nbelow); are generated by technologies used in a sensitive domain; can be used to infer data from a sensitive domain or \nsensitive data about an individual (such as disability-related data, genomic data, biometric data, behavioral data, \ngeolocation data, data related to interaction with the criminal justice system, relationship history and legal status such", "0726c866-76ba-46af-a279-d3a7b89276e2": "as custody and divorce information, and home, work, or school environmental data); or have the reasonable potential \nto be used in ways that are likely to expose individuals to meaningful harm, such as a loss of privacy or financial harm", "22919863-ac88-4830-923d-96448d4e7a87": "due to identity theft. Data and metadata generated by or about those who are not yet legal adults is also sensitive, even \nif not related to a sensitive domain. Such data includes, but is not limited to, numerical, text, image, audio, or video \ndata. \u201cSensitive domains\u201d are those in which activities being conducted can cause material harms, including signifi\u00ad\ncant adverse effects on human rights such as autonomy and dignity, as well as civil liberties and civil rights. Domains \nthat have historically been singled out as deserving of enhanced data protections or where such enhanced protections \nare reasonably expected by the public include, but are not limited to, health, family planning and care, employment,", "d67356ca-c226-4a81-af3a-f58c97f2c835": "education, criminal justice, and personal finance. In the context of this framework, such domains are considered \nsensitive whether or not the specifics of a system context would necessitate coverage under existing law, and domains", "48e5418d-9fcb-4e41-bba9-adabb44736ff": "and data that are considered sensitive are understood to change over time based on societal norms and context. \n36", "c3e89a77-6d74-42ea-8c95-29b74c56146d": "DATA PRIVACY \nEXTRA PROTECTIONS FOR DATA RELATED TO SENSITIVE\nDOMAINS\n\u2022\nContinuous positive airway pressure machines gather data for medical purposes, such as diagnosing sleep\napnea, and send usage data to a patient\u2019s insurance company, which may subsequently deny coverage for the\ndevice based on usage data. Patients were not aware that the data would be used in this way or monitored\nby anyone other than their doctor.70 \n\u2022\nA department store company used predictive analytics applied to collected consumer data to determine that a\nteenage girl was pregnant, and sent maternity clothing ads and other baby-related advertisements to her\nhouse, revealing to her father that she was pregnant.71\n\u2022", "47bde0f7-5a8a-44cb-9b21-2d284bf1feba": "\u2022\nSchool audio surveillance systems monitor student conversations to detect potential \"stress indicators\" as\na warning of potential violence.72 Online proctoring systems claim to detect if a student is cheating on an", "ad61bff8-771e-4a84-b01c-212ea183c0eb": "exam using biometric markers.73 These systems have the potential to limit student freedom to express a range\nof emotions at school and may inappropriately flag students with disabilities who need accommodations or\nuse screen readers or dictation software as cheating.74\n\u2022\nLocation data, acquired from a data broker, can be used to identify people who visit abortion clinics.75\n\u2022\nCompanies collect student data such as demographic information, free or reduced lunch status, whether\nthey've used drugs, or whether they've expressed interest in LGBTQI+ groups, and then use that data to \nforecast student success.76 Parents and education experts have expressed concern about collection of such", "408348ef-38a3-4de3-b1f3-22c4e9aa7158": "sensitive data without express parental consent, the lack of transparency in how such data is being used, and\nthe potential for resulting discriminatory impacts.\n\u2022 Many employers transfer employee data to third party job verification services. This information is then used", "30731cfd-0d5c-4f12-8e21-3a22a58f0b01": "by potential future employers, banks, or landlords. In one case, a former employee alleged that a\ncompany supplied false data about her job title which resulted in a job offer being revoked.77\n37", "12c2ede9-108a-4057-8328-96d31f41307c": "DATA PRIVACY \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \u00ad\u00ad\u00ad\u00ad\u00ad\u00ad\nIn addition to the privacy expectations above for general non-sensitive data, any system collecting, using, shar-\ning, or storing sensitive data should meet the expectations below. Depending on the technological use case and \nbased on an ethical assessment, consent for sensitive data may need to be acquired from a guardian and/or child. \nProvide enhanced protections for data related to sensitive domains", "fabad0c7-5c2e-4821-8bd7-039c4cddfd59": "Necessary functions only. Sensitive data should only be used for functions strictly necessary for that \ndomain or for functions that are required for administrative reasons (e.g., school attendance records), unless", "7c806454-5881-4ab0-8a60-fdbb9b42cb2e": "consent is acquired, if appropriate, and the additional expectations in this section are met. Consent for non-\nnecessary functions should be optional, i.e., should not be required, incentivized, or coerced in order to \nreceive opportunities or access to services. In cases where data is provided to an entity (e.g., health insurance \ncompany) in order to facilitate payment for such a need, that data should only be used for that purpose. \nEthical review and use prohibitions. Any use of sensitive data or decision process based in part on sensi-\ntive data that might limit rights, opportunities, or access, whether the decision is automated or not, should go", "3448d00b-754c-4d34-8ea3-e6ccd31b4e8a": "through a thorough ethical review and monitoring, both in advance and by periodic review (e.g., via an indepen-\ndent ethics committee or similarly robust process). In some cases, this ethical review may determine that data \nshould not be used or shared for specific uses even with consent. Some novel uses of automated systems in this", "76fb387d-2fba-450e-9fb4-e8bbe63f306a": "context, where the algorithm is dynamically developing and where the science behind the use case is not well \nestablished, may also count as human subject experimentation, and require special review under organizational \ncompliance bodies applying medical, scientific, and academic human subject experimentation ethics rules and \ngovernance procedures. \nData quality. In sensitive domains, entities should be especially careful to maintain the quality of data to \navoid adverse consequences arising from decision-making based on flawed or inaccurate data. Such care is \nnecessary in a fragmented, complex data ecosystem and for datasets that have limited access such as for fraud", "8c1427f1-545d-4fe7-a656-9cb5a91f3c24": "prevention and law enforcement. It should be not left solely to individuals to carry the burden of reviewing and \ncorrecting data. Entities should conduct regular, independent audits and take prompt corrective measures to \nmaintain accurate, timely, and complete data.", "c642e842-06e9-4526-9466-3da15fd1a631": "maintain accurate, timely, and complete data. \nLimit access to sensitive data and derived data. Sensitive data and derived data should not be sold, \nshared, or made public as part of data brokerage or other agreements. Sensitive data includes data that can be \nused to infer sensitive information; even systems that are not directly marketed as sensitive domain technologies \nare expected to keep sensitive data private. Access to such data should be limited based on necessity and based \non a principle of local control, such that those individuals closest to the data subject have more access while \nthose who are less proximate do not (e.g., a teacher has access to their students\u2019 daily progress data while a \nsuperintendent does not).", "f2ef7556-455a-4cfa-b8ec-c36eabbb529a": "Reporting. In addition to the reporting on data privacy (as listed above for non-sensitive data), entities devel-\noping technologies related to a sensitive domain and those collecting, using, storing, or sharing sensitive data", "eb19e38f-c333-425b-8c94-ccc6a3f3b35c": "should, whenever appropriate, regularly provide public reports describing: any data security lapses or breaches \nthat resulted in sensitive data leaks; the number, type, and outcomes of ethical pre-reviews undertaken; a \ndescription of any data sold, shared, or made public, and how that data was assessed to determine it did not pres-\nent a sensitive data risk; and ongoing risk identification and management procedures, and any mitigation added \nbased on these procedures. Reporting should be provided in a clear and machine-readable manner. \n38", "909121a0-809a-4703-997b-534ec295bfe2": "DATA PRIVACY \nHOW THESE PRINCIPLES CAN MOVE INTO PRACTICE\nReal-life examples of how these principles can become reality, through laws, policies, and practical \ntechnical and sociotechnical approaches to protecting rights, opportunities, and access. \nThe Privacy Act of 1974 requires privacy protections for personal information in federal \nrecords systems, including limits on data retention, and also provides individuals a general \nright to access and correct their data. Among other things, the Privacy Act limits the storage of individual \ninformation in federal systems of records, illustrating the principle of limiting the scope of data retention. Under", "8832388e-f791-4346-85ab-5c50265f977b": "the Privacy Act, federal agencies may only retain data about an individual that is \u201crelevant and necessary\u201d to \naccomplish an agency\u2019s statutory purpose or to comply with an Executive Order of the President. The law allows", "5cb384b0-7012-438f-a9be-5f10428e5e18": "for individuals to be able to access any of their individual information stored in a federal system of records, if not \nincluded under one of the systems of records exempted pursuant to the Privacy Act. In these cases, federal agen\u00ad\ncies must provide a method for an individual to determine if their personal information is stored in a particular \nsystem of records, and must provide procedures for an individual to contest the contents of a record about them. \nFurther, the Privacy Act allows for a cause of action for an individual to seek legal relief if a federal agency does not \ncomply with the Privacy Act\u2019s requirements. Among other things, a court may order a federal agency to amend or", "7a369c62-5f27-4181-92d1-8b0f59b4ccec": "correct an individual\u2019s information in its records or award monetary damages if an inaccurate, irrelevant, untimely, \nor incomplete record results in an adverse determination about an individual\u2019s \u201cqualifications, character, rights, \u2026 \nopportunities\u2026, or benefits.\u201d", "4b97b7b3-e790-43e5-ab36-febac372cf09": "opportunities\u2026, or benefits.\u201d \nNIST\u2019s Privacy Framework provides a comprehensive, detailed and actionable approach for \norganizations to manage privacy risks. The NIST Framework gives organizations ways to identify and \ncommunicate their privacy risks and goals to support ethical decision-making in system, product, and service \ndesign or deployment, as well as the measures they are taking to demonstrate compliance with applicable laws \nor regulations. It has been voluntarily adopted by organizations across many different sectors around the world.78\nA school board\u2019s attempt to surveil public school students\u2014undertaken without \nadequate community input\u2014sparked a state-wide biometrics moratorium.79 Reacting to a plan in", "34a84df8-0355-4e2b-8480-289f6449b6b2": "the city of Lockport, New York, the state\u2019s legislature banned the use of facial recognition systems and other \n\u201cbiometric identifying technology\u201d in schools until July 1, 2022.80 The law additionally requires that a report on", "3523be37-e363-42c7-939f-daa70e3a3f76": "the privacy, civil rights, and civil liberties implications of the use of such technologies be issued before \nbiometric identification technologies can be used in New York schools. \nFederal law requires employers, and any consultants they may retain, to report the costs \nof surveilling employees in the context of a labor dispute, providing a transparency \nmechanism to help protect worker organizing. Employers engaging in workplace surveillance \"where \nan object there-of, directly or indirectly, is [\u2026] to obtain information concerning the activities of employees or a \nlabor organization in connection with a labor dispute\" must report expenditures relating to this surveillance to", "8aef759e-75d9-4b21-ad82-aa48190a3094": "the Department of Labor Office of Labor-Management Standards, and consultants who employers retain for \nthese purposes must also file reports regarding their activities.81\nPrivacy choices on smartphones show that when technologies are well designed, privacy", "0030999d-3f51-4c92-8843-acdfec24b24d": "and data agency can be meaningful and not overwhelming. These choices\u2014such as contextual, timely \nalerts about location tracking\u2014are brief, direct, and use-specific. Many of the expectations listed here for \nprivacy by design and use-specific consent mirror those distributed to developers as best practices when \ndeveloping for smart phone devices,82 such as being transparent about how user data will be used, asking for app \npermissions during their use so that the use-context will be clear to users, and ensuring that the app will still \nwork if users deny (or later revoke) some permissions. \n39", "2882a36b-aa0e-4fb5-a523-b1df08eff13c": "You should know that an automated system is being used, \nand understand how and why it contributes to outcomes \nthat impact you. Designers, developers, and deployers of automat\u00ad\ned systems should provide generally accessible plain language docu\u00ad\nmentation including clear descriptions of the overall system func\u00ad\ntioning and the role automation plays, notice that such systems are in \nuse, the individual or organization responsible for the system, and ex\u00ad\nplanations of outcomes that are clear, timely, and accessible. Such \nnotice should be kept up-to-date and people impacted by the system \nshould be notified of significant use case or key functionality chang\u00ad\nes. You should know how and why an outcome impacting you was de\u00ad", "0c3242a1-26c6-4995-b0bb-c8ce7fe4b62e": "termined by an automated system, including when the automated \nsystem is not the sole input determining the outcome. Automated \nsystems should provide explanations that are technically valid, \nmeaningful and useful to you and to any operators or others who", "ab6f96c5-e62c-49c9-9ef3-40e3d52262a5": "need to understand the system, and calibrated to the level of risk \nbased on the context. Reporting that includes summary information \nabout these automated systems in plain language and assessments of \nthe clarity and quality of the notice and explanations should be made \npublic whenever possible.   \nNOTICE AND EXPLANATION\n40", "3d9ea148-1da7-4794-a0be-d46127db5fe1": "NOTICE & \nEXPLANATION \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \nAutomated systems now determine opportunities, from employment to credit, and directly shape the American \npublic\u2019s experiences, from the courtroom to online classrooms, in ways that profoundly impact people\u2019s lives. But this \nexpansive impact is not always visible. An applicant might not know whether a person rejected their resume or a \nhiring algorithm moved them to the bottom of the list. A defendant in the courtroom might not know if a judge deny\u00ad", "2efaeb1b-fc8f-481d-a0f9-7197de12900f": "ing their bail is informed by an automated system that labeled them \u201chigh risk.\u201d From correcting errors to contesting \ndecisions, people are often denied the knowledge they need to address the impact of automated systems on their lives.", "4e4dee20-014c-47df-ba83-83dfabf81a87": "Notice and explanations also serve an important safety and efficacy purpose, allowing experts to verify the reasonable\u00ad\nness of a recommendation before enacting it. \nIn order to guard against potential harms, the American public needs to know if an automated system is being used. \nClear, brief, and understandable notice is a prerequisite for achieving the other protections in this framework. Like\u00ad\nwise, the public is often unable to ascertain how or why an automated system has made a decision or contributed to a \nparticular outcome. The decision-making processes of automated systems tend to be opaque, complex, and, therefore, \nunaccountable, whether by design or by omission. These factors can make explanations both more challenging and", "aa897bbf-b49c-4240-84ae-a95909d0fa2a": "more important, and should not be used as a pretext to avoid explaining important decisions to the people impacted \nby those choices. In the context of automated systems, clear and valid explanations should be recognized as a baseline \nrequirement.", "7ca0feb2-1180-4329-9b5c-2cf8a01d3d4e": "requirement. \nProviding notice has long been a standard practice, and in many cases is a legal requirement, when, for example, \nmaking a video recording of someone (outside of a law enforcement or national security context). In some cases, such \nas credit, lenders are required to provide notice and explanation to consumers. Techniques used to automate the \nprocess of explaining such systems are under active research and improvement and such explanations can take many \nforms. Innovative companies and researchers are rising to the challenge and creating and deploying explanatory \nsystems that can help the public better understand decisions that impact them.", "ba84c47f-3661-4aba-adc6-70437c689443": "While notice and explanation requirements are already in place in some sectors or situations, the American public \ndeserve to know consistently and across sectors if an automated system is being used in a way that impacts their rights,", "6633a03a-588f-4a42-aa2e-f51003b14b90": "opportunities, or access. This knowledge should provide confidence in how the public is being treated, and trust in the \nvalidity and reasonable use of automated systems. \n\u2022\nA lawyer representing an older client with disabilities who had been cut off from Medicaid-funded home\nhealth-care assistance couldn't determine why, especially since the decision went against historical access\npractices. In a court hearing, the lawyer learned from a witness that the state in which the older client\nlived had recently adopted a new algorithm to determine eligibility.83 The lack of a timely explanation made it\nharder to understand and contest the decision.\n\u2022", "096b7785-5989-4767-bce6-b1eeb5bfd57a": "\u2022\nA formal child welfare investigation is opened against a parent based on an algorithm and without the parent\never being notified that data was being collected and used as part of an algorithmic child maltreatment\nrisk assessment.84 The lack of notice or an explanation makes it harder for those performing child", "9e3e68e9-f19a-4928-9365-ecebd6c30a32": "maltreatment assessments to validate the risk assessment and denies parents knowledge that could help them\ncontest a decision.\n41", "0fd8917c-9fad-4fbe-aa0b-bd2a1aa43d13": "NOTICE & \nEXPLANATION \nWHY THIS PRINCIPLE IS IMPORTANT\nThis section provides a brief summary of the problems which the principle seeks to address and protect \nagainst, including illustrative examples. \n\u2022\nA predictive policing system claimed to identify individuals at greatest risk to commit or become the victim of\ngun violence (based on automated analysis of social ties to gang members, criminal histories, previous experi\u00ad\nences of gun violence, and other factors) and led to individuals being placed on a watch list with no\nexplanation or public transparency regarding how the system came to its conclusions.85 Both police and\nthe public deserve to understand why and how such a system is making these determinations.\n\u2022", "c72caf6f-8d32-466f-9c7b-bb7eee55afdc": "\u2022\nA system awarding benefits changed its criteria invisibly. Individuals were denied benefits due to data entry\nerrors and other system flaws. These flaws were only revealed when an explanation of the system", "e9cdd7c4-47e9-48da-841a-4eaeb30c120c": "was demanded and produced.86 The lack of an explanation made it harder for errors to be corrected in a\ntimely manner.\n42", "f489cf15-d0fd-4932-a311-d09b9242bcbd": "NOTICE & \nEXPLANATION \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nAn automated system should provide demonstrably clear, timely, understandable, and accessible notice of use, and \nexplanations as to how and why a decision was made or an action was taken by the system. These expectations are \nexplained below. \nProvide clear, timely, understandable, and accessible notice of use and explanations \u00ad\nGenerally accessible plain language documentation. The entity responsible for using the automated", "5b780d10-f70b-40a8-98bc-23297874b66f": "system should ensure that documentation describing the overall system (including any human components) is \npublic and easy to find. The documentation should describe, in plain language, how the system works and how", "c7c50a83-277d-4f4d-a42a-0b1b38a75afe": "any automated component is used to determine an action or decision. It should also include expectations about \nreporting described throughout this framework, such as the algorithmic impact assessments described as \npart of Algorithmic Discrimination Protections. \nAccountable. Notices should clearly identify the entity responsible for designing each component of the \nsystem and the entity using it. \nTimely and up-to-date. Users should receive notice of the use of automated systems in advance of using or \nwhile being impacted by the technology. An explanation should be available with the decision itself, or soon \nthereafter. Notice should be kept up-to-date and people impacted by the system should be notified of use case", "24f63b0c-8ac8-48e0-b100-9f65d5a70587": "or key functionality changes. \nBrief and clear. Notices and explanations should be assessed, such as by research on users\u2019 experiences, \nincluding user testing, to ensure that the people using or impacted by the automated system are able to easily", "40ea1712-0fc0-493a-a073-75a0a4289c3b": "find notices and explanations, read them quickly, and understand and act on them. This includes ensuring that \nnotices and explanations are accessible to users with disabilities and are available in the language(s) and read-\ning level appropriate for the audience. Notices and explanations may need to be available in multiple forms, \n(e.g., on paper, on a physical sign, or online), in order to meet these expectations and to be accessible to the \nAmerican public. \nProvide explanations as to how and why a decision was made or an action was taken by an \nautomated system \nTailored to the purpose. Explanations should be tailored to the specific purpose for which the user is", "74a10716-4134-4d7b-9539-cd94739f136a": "expected to use the explanation, and should clearly state that purpose. An informational explanation might \ndiffer from an explanation provided to allow for the possibility of recourse, an appeal, or one provided in the", "ba49c935-b7a3-44a5-912c-19413a2ce79a": "context of a dispute or contestation process. For the purposes of this framework, 'explanation' should be \nconstrued broadly. An explanation need not be a plain-language statement about causality but could consist of \nany mechanism that allows the recipient to build the necessary understanding and intuitions to achieve the \nstated purpose. Tailoring should be assessed (e.g., via user experience research). \nTailored to the target of the explanation. Explanations should be targeted to specific audiences and \nclearly state that audience. An explanation provided to the subject of a decision might differ from one provided \nto an advocate, or to a domain expert or decision maker. Tailoring should be assessed (e.g., via user experience", "4ceeb4cb-5b7d-414b-bbc8-9663d18f5300": "research). \n43", "7f9e8779-4fa0-4991-9d60-c20792d2aaf7": "NOTICE & \nEXPLANATION \nWHAT SHOULD BE EXPECTED OF AUTOMATED SYSTEMS\nThe expectations for automated systems are meant to serve as a blueprint for the development of additional \ntechnical standards and practices that are tailored for particular sectors and contexts. \nTailored to the level of risk. An assessment should be done to determine the level of risk of the auto\u00ad\nmated system. In settings where the consequences are high as determined by a risk assessment, or extensive \noversight is expected (e.g., in criminal justice or some public sector settings), explanatory mechanisms should \nbe built into the system design so that the system\u2019s full behavior can be explained in advance (i.e., only fully", "4068a74b-d721-4727-8ae8-63dd3f46945a": "transparent models should be used), rather than as an after-the-decision interpretation. In other settings, the \nextent of explanation provided should be tailored to the risk level.", "2aea1a16-7ceb-41c4-ba11-87cf884f870f": "Valid. The explanation provided by a system should accurately reflect the factors and the influences that led \nto a particular decision, and should be meaningful for the particular customization based on purpose, target, \nand level of risk. While approximation and simplification may be necessary for the system to succeed based on \nthe explanatory purpose and target of the explanation, or to account for the risk of fraud or other concerns \nrelated to revealing decision-making information, such simplifications should be done in a scientifically \nsupportable way. Where appropriate based on the explanatory system, error ranges for the explanation should", "4c0a2dfd-94c9-46d0-a6cb-ecbd7609047e": "be calculated and included in the explanation, with the choice of presentation of such information balanced \nwith usability and overall interface complexity concerns. \nDemonstrate protections for notice and explanation \nReporting. Summary reporting should document the determinations made based on the above consider\u00ad", "1efa7d9d-12a8-41a4-8eb8-8af7a265bffd": "ations, including: the responsible entities for accountability purposes; the goal and use cases for the system, \nidentified users, and impacted populations; the assessment of notice clarity and timeliness; the assessment of \nthe explanation's validity and accessibility; the assessment of the level of risk; and the account and assessment \nof how explanations are tailored, including to the purpose, the recipient of the explanation, and the level of \nrisk. Individualized profile information should be made readily available to the greatest extent possible that \nincludes explanations for any system impacts or inferences. Reporting should be provided in a clear plain \nlanguage and machine-readable manner. \n44", "31b4cd77-4539-4f36-aa0f-937186f380f3": "NOTICE & \nEXPLANATION \nHOW THESE PRINCIPLES CAN MOVE INTO PRACTICE\nReal-life examples of how these principles can become reality, through laws, policies, and practical \ntechnical and sociotechnical approaches to protecting rights, opportunities, and access. \u00ad\u00ad\u00ad\u00ad\u00ad\nPeople in Illinois are given written notice by the private sector if their biometric informa-\ntion is used. The Biometric Information Privacy Act enacted by the state contains a number of provisions \nconcerning the use of individual biometric data and identifiers. Included among them is a provision that no private \nentity may \"collect, capture, purchase, receive through trade, or otherwise obtain\" such information about an", "190dd893-b53b-4700-b35a-b8b55b49b24b": "individual, unless written notice is provided to that individual or their legally appointed representative. 87\nMajor technology companies are piloting new ways to communicate with the public about", "c72b45ed-b8f4-4508-9ce9-fe13f94d6c50": "their automated technologies. For example, a collection of non-profit organizations and companies have \nworked together to develop a framework that defines operational approaches to transparency for machine \nlearning systems.88 This framework, and others like it,89 inform the public about the use of these tools, going \nbeyond simple notice to include reporting elements such as safety evaluations, disparity assessments, and \nexplanations of how the systems work. \nLenders are required by federal law to notify consumers about certain decisions made about \nthem. Both the Fair Credit Reporting Act and the Equal Credit Opportunity Act require in certain circumstances", "2b8b77aa-d83f-46b6-a43d-918c3308993c": "that consumers who are denied credit receive \"adverse action\" notices. Anyone who relies on the information in a \ncredit report to deny a consumer credit must, under the Fair Credit Reporting Act, provide an \"adverse action\"", "ddbc86d0-8442-4129-9315-83e68bab4f84": "notice to the consumer, which includes \"notice of the reasons a creditor took adverse action on the application \nor on an existing credit account.\"90 In addition, under the risk-based pricing rule,91 lenders must either inform \nborrowers of their credit score, or else tell consumers when \"they are getting worse terms because of \ninformation in their credit report.\" The CFPB has also asserted that \"[t]he law gives every applicant the right to \na specific explanation if their application for credit was denied, and that right is not diminished simply because \na company uses a complex algorithm that it doesn't understand.\"92 Such explanations illustrate a shared value \nthat certain decisions need to be explained.", "96d2545b-bdd9-48d4-82ea-d929ec34dad6": "A California law requires that warehouse employees are provided with notice and explana-\ntion about quotas, potentially facilitated by automated systems, that apply to them. Warehous-", "8851b71f-d5dd-441b-860f-f0c452766707": "ing employers in California that use quota systems (often facilitated by algorithmic monitoring systems) are \nrequired to provide employees with a written description of each quota that applies to the employee, including \n\u201cquantified number of tasks to be performed or materials to be produced or handled, within the defined \ntime period, and any potential adverse employment action that could result from failure to meet the quota.\u201d93\nAcross the federal government, agencies are conducting and supporting research on explain-\nable AI systems. The NIST is conducting fundamental research on the explainability of AI systems. A multidis-\nciplinary team of researchers aims to develop measurement methods and best practices to support the", "3d1c79a7-2e49-490e-ba05-42769aa54db1": "implementation of core tenets of explainable AI.94 The Defense Advanced Research Projects Agency has a \nprogram on Explainable Artificial Intelligence that aims to create a suite of machine learning techniques that", "999cc9e5-a704-47c7-a5bc-cc862491a41f": "produce more explainable models, while maintaining a high level of learning performance (prediction \naccuracy), and enable human users to understand, appropriately trust, and effectively manage the emerging \ngeneration of artificially intelligent partners.95 The National Science Foundation\u2019s program on Fairness in \nArtificial Intelligence also includes a specific interest in research foundations for explainable AI.96\n45"}}